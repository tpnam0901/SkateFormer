[ Tue Dec  2 14:56:55 2025 ] using warm up, epoch: 25
[ Tue Dec  2 15:04:51 2025 ] Parameters:
{'work_dir': './work_dir8/ntu/cs/SkateFormer_j/', 'model_saved_name': './work_dir8/ntu/cs/SkateFormer_j/runs', 'config': './config/train/ntu_cs/SkateFormer_j.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 0, 'train_feeder_args': {'data_path': './data/ntu/random_split_predefined8/NTU60_CS.npz', 'split': 'train', 'debug': False, 'window_size': 64, 'p_interval': [0.5, 1], 'aug_method': 'a123489', 'intra_p': 0.5, 'inter_p': 0.2, 'thres': 64, 'uniform': True, 'partition': True}, 'test_feeder_args': {'data_path': './data/ntu/random_split_predefined8/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'thres': 64, 'uniform': True, 'partition': True, 'debug': False}, 'model': 'model.SkateFormer.SkateFormer_', 'model_args': {'num_classes': 60, 'num_people': 2, 'num_points': 24, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 8], 'type_2_size': [8, 12], 'type_3_size': [8, 8], 'type_4_size': [8, 12], 'mlp_ratio': 4.0, 'index_t': True}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 32, 'test_batch_size': 32, 'start_epoch': 0, 'num_epoch': 500, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Tue Dec  2 15:04:51 2025 ] # Parameters: 3616083
[ Tue Dec  2 15:04:51 2025 ] Training epoch: 1
[ Tue Dec  2 15:12:36 2025 ] 	Mean training loss: 4.0329.  Mean training acc: 3.25%.
[ Tue Dec  2 15:12:36 2025 ] 	Learning Rate: 0.0000
[ Tue Dec  2 15:12:36 2025 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Dec  2 15:12:36 2025 ] Training epoch: 2
[ Tue Dec  2 15:14:52 2025 ] 	Mean training loss: 3.8194.  Mean training acc: 6.31%.
[ Tue Dec  2 15:14:52 2025 ] 	Learning Rate: 0.0001
[ Tue Dec  2 15:14:52 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:14:52 2025 ] Training epoch: 3
[ Tue Dec  2 15:17:07 2025 ] 	Mean training loss: 3.6225.  Mean training acc: 8.60%.
[ Tue Dec  2 15:17:07 2025 ] 	Learning Rate: 0.0001
[ Tue Dec  2 15:17:07 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:17:07 2025 ] Training epoch: 4
[ Tue Dec  2 15:19:23 2025 ] 	Mean training loss: 3.3982.  Mean training acc: 13.32%.
[ Tue Dec  2 15:19:23 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:19:23 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:19:23 2025 ] Training epoch: 5
[ Tue Dec  2 15:21:39 2025 ] 	Mean training loss: 3.1253.  Mean training acc: 20.13%.
[ Tue Dec  2 15:21:39 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:21:39 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:21:39 2025 ] Training epoch: 6
[ Tue Dec  2 15:23:54 2025 ] 	Mean training loss: 2.9204.  Mean training acc: 25.78%.
[ Tue Dec  2 15:23:54 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:23:54 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:23:54 2025 ] Training epoch: 7
[ Tue Dec  2 15:26:10 2025 ] 	Mean training loss: 2.7675.  Mean training acc: 31.35%.
[ Tue Dec  2 15:26:10 2025 ] 	Learning Rate: 0.0003
[ Tue Dec  2 15:26:10 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:26:10 2025 ] Training epoch: 8
[ Tue Dec  2 15:28:26 2025 ] 	Mean training loss: 2.6602.  Mean training acc: 34.78%.
[ Tue Dec  2 15:28:26 2025 ] 	Learning Rate: 0.0003
[ Tue Dec  2 15:28:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:28:26 2025 ] Training epoch: 9
[ Tue Dec  2 15:30:41 2025 ] 	Mean training loss: 2.5950.  Mean training acc: 36.93%.
[ Tue Dec  2 15:30:41 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:30:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:30:41 2025 ] Training epoch: 10
[ Tue Dec  2 15:32:57 2025 ] 	Mean training loss: 2.5117.  Mean training acc: 39.35%.
[ Tue Dec  2 15:32:57 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:32:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:32:57 2025 ] Training epoch: 11
[ Tue Dec  2 15:35:12 2025 ] 	Mean training loss: 2.4655.  Mean training acc: 41.30%.
[ Tue Dec  2 15:35:12 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:35:12 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:35:12 2025 ] Training epoch: 12
[ Tue Dec  2 15:37:28 2025 ] 	Mean training loss: 2.4069.  Mean training acc: 42.60%.
[ Tue Dec  2 15:37:28 2025 ] 	Learning Rate: 0.0005
[ Tue Dec  2 15:37:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:37:28 2025 ] Training epoch: 13
[ Tue Dec  2 15:39:44 2025 ] 	Mean training loss: 2.3476.  Mean training acc: 45.59%.
[ Tue Dec  2 15:39:44 2025 ] 	Learning Rate: 0.0005
[ Tue Dec  2 15:39:44 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:39:44 2025 ] Training epoch: 14
[ Tue Dec  2 15:41:59 2025 ] 	Mean training loss: 2.3053.  Mean training acc: 46.95%.
[ Tue Dec  2 15:41:59 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 15:41:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:41:59 2025 ] Training epoch: 15
[ Tue Dec  2 15:44:15 2025 ] 	Mean training loss: 2.2688.  Mean training acc: 48.04%.
[ Tue Dec  2 15:44:15 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 15:44:15 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:44:15 2025 ] Training epoch: 16
[ Tue Dec  2 15:46:30 2025 ] 	Mean training loss: 2.2616.  Mean training acc: 47.72%.
[ Tue Dec  2 15:46:30 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 15:46:30 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:46:30 2025 ] Training epoch: 17
[ Tue Dec  2 15:48:46 2025 ] 	Mean training loss: 2.2133.  Mean training acc: 49.20%.
[ Tue Dec  2 15:48:46 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 15:48:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:48:46 2025 ] Training epoch: 18
[ Tue Dec  2 15:51:02 2025 ] 	Mean training loss: 2.1814.  Mean training acc: 50.47%.
[ Tue Dec  2 15:51:02 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 15:51:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:51:02 2025 ] Training epoch: 19
[ Tue Dec  2 15:53:17 2025 ] 	Mean training loss: 2.1474.  Mean training acc: 51.68%.
[ Tue Dec  2 15:53:17 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 15:53:17 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:53:17 2025 ] Training epoch: 20
[ Tue Dec  2 15:55:33 2025 ] 	Mean training loss: 2.1506.  Mean training acc: 52.24%.
[ Tue Dec  2 15:55:33 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 15:55:33 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:55:33 2025 ] Training epoch: 21
[ Tue Dec  2 15:57:49 2025 ] 	Mean training loss: 2.1279.  Mean training acc: 52.39%.
[ Tue Dec  2 15:57:49 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 15:57:49 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:57:49 2025 ] Training epoch: 22
[ Tue Dec  2 16:00:04 2025 ] 	Mean training loss: 2.0875.  Mean training acc: 53.78%.
[ Tue Dec  2 16:00:04 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 16:00:04 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:00:04 2025 ] Training epoch: 23
[ Tue Dec  2 16:02:20 2025 ] 	Mean training loss: 2.1022.  Mean training acc: 52.68%.
[ Tue Dec  2 16:02:20 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 16:02:20 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:02:20 2025 ] Training epoch: 24
[ Tue Dec  2 16:04:36 2025 ] 	Mean training loss: 2.0623.  Mean training acc: 55.05%.
[ Tue Dec  2 16:04:36 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:04:36 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:04:36 2025 ] Training epoch: 25
[ Tue Dec  2 16:06:51 2025 ] 	Mean training loss: 2.0581.  Mean training acc: 54.87%.
[ Tue Dec  2 16:06:51 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:06:51 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:06:51 2025 ] Training epoch: 26
[ Tue Dec  2 16:09:07 2025 ] 	Mean training loss: 2.0442.  Mean training acc: 55.75%.
[ Tue Dec  2 16:09:07 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:09:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:09:07 2025 ] Training epoch: 27
[ Tue Dec  2 16:11:23 2025 ] 	Mean training loss: 2.0007.  Mean training acc: 56.61%.
[ Tue Dec  2 16:11:23 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:11:23 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:11:23 2025 ] Training epoch: 28
[ Tue Dec  2 16:13:38 2025 ] 	Mean training loss: 1.9661.  Mean training acc: 57.54%.
[ Tue Dec  2 16:13:38 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:13:38 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:13:38 2025 ] Training epoch: 29
[ Tue Dec  2 16:15:54 2025 ] 	Mean training loss: 1.9520.  Mean training acc: 59.21%.
[ Tue Dec  2 16:15:54 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:15:54 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:15:54 2025 ] Training epoch: 30
[ Tue Dec  2 16:18:10 2025 ] 	Mean training loss: 1.9259.  Mean training acc: 59.43%.
[ Tue Dec  2 16:18:10 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:18:10 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:18:10 2025 ] Training epoch: 31
[ Tue Dec  2 16:20:25 2025 ] 	Mean training loss: 1.9028.  Mean training acc: 60.24%.
[ Tue Dec  2 16:20:25 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:20:25 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:20:25 2025 ] Training epoch: 32
[ Tue Dec  2 16:22:41 2025 ] 	Mean training loss: 1.8878.  Mean training acc: 60.88%.
[ Tue Dec  2 16:22:41 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:22:41 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:22:41 2025 ] Training epoch: 33
[ Tue Dec  2 16:24:57 2025 ] 	Mean training loss: 1.8791.  Mean training acc: 61.08%.
[ Tue Dec  2 16:24:57 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:24:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:24:57 2025 ] Training epoch: 34
[ Tue Dec  2 16:27:12 2025 ] 	Mean training loss: 1.8387.  Mean training acc: 62.27%.
[ Tue Dec  2 16:27:12 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:27:12 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:27:12 2025 ] Training epoch: 35
[ Tue Dec  2 16:29:28 2025 ] 	Mean training loss: 1.8384.  Mean training acc: 62.88%.
[ Tue Dec  2 16:29:28 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:29:28 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:29:28 2025 ] Training epoch: 36
[ Tue Dec  2 16:31:44 2025 ] 	Mean training loss: 1.8234.  Mean training acc: 63.07%.
[ Tue Dec  2 16:31:44 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:31:44 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:31:44 2025 ] Training epoch: 37
[ Tue Dec  2 16:33:59 2025 ] 	Mean training loss: 1.8131.  Mean training acc: 63.88%.
[ Tue Dec  2 16:33:59 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:33:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:33:59 2025 ] Training epoch: 38
[ Tue Dec  2 16:36:15 2025 ] 	Mean training loss: 1.7802.  Mean training acc: 64.41%.
[ Tue Dec  2 16:36:15 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:36:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:36:15 2025 ] Training epoch: 39
[ Tue Dec  2 16:38:31 2025 ] 	Mean training loss: 1.7620.  Mean training acc: 64.68%.
[ Tue Dec  2 16:38:31 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:38:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:38:31 2025 ] Training epoch: 40
[ Tue Dec  2 16:40:46 2025 ] 	Mean training loss: 1.7366.  Mean training acc: 65.33%.
[ Tue Dec  2 16:40:46 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:40:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:40:46 2025 ] Training epoch: 41
[ Tue Dec  2 16:43:02 2025 ] 	Mean training loss: 1.7327.  Mean training acc: 65.75%.
[ Tue Dec  2 16:43:02 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:43:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:43:02 2025 ] Training epoch: 42
[ Tue Dec  2 16:45:18 2025 ] 	Mean training loss: 1.7137.  Mean training acc: 66.16%.
[ Tue Dec  2 16:45:18 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:45:18 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:45:18 2025 ] Training epoch: 43
[ Tue Dec  2 16:47:33 2025 ] 	Mean training loss: 1.7276.  Mean training acc: 66.03%.
[ Tue Dec  2 16:47:33 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:47:33 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:47:33 2025 ] Training epoch: 44
[ Tue Dec  2 16:49:49 2025 ] 	Mean training loss: 1.6997.  Mean training acc: 67.24%.
[ Tue Dec  2 16:49:49 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:49:49 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:49:49 2025 ] Training epoch: 45
[ Tue Dec  2 16:52:05 2025 ] 	Mean training loss: 1.6742.  Mean training acc: 67.95%.
[ Tue Dec  2 16:52:05 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:52:05 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:52:05 2025 ] Training epoch: 46
[ Tue Dec  2 16:54:20 2025 ] 	Mean training loss: 1.6691.  Mean training acc: 67.90%.
[ Tue Dec  2 16:54:20 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:54:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:54:21 2025 ] Training epoch: 47
[ Tue Dec  2 16:56:36 2025 ] 	Mean training loss: 1.6582.  Mean training acc: 68.55%.
[ Tue Dec  2 16:56:36 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:56:36 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:56:36 2025 ] Training epoch: 48
[ Tue Dec  2 16:58:52 2025 ] 	Mean training loss: 1.6342.  Mean training acc: 68.79%.
[ Tue Dec  2 16:58:52 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:58:52 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:58:52 2025 ] Training epoch: 49
[ Tue Dec  2 17:01:07 2025 ] 	Mean training loss: 1.6361.  Mean training acc: 69.30%.
[ Tue Dec  2 17:01:07 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:01:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:01:07 2025 ] Training epoch: 50
[ Tue Dec  2 17:03:23 2025 ] 	Mean training loss: 1.6261.  Mean training acc: 69.67%.
[ Tue Dec  2 17:03:23 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:03:23 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:03:23 2025 ] Training epoch: 51
[ Tue Dec  2 17:05:39 2025 ] 	Mean training loss: 1.6156.  Mean training acc: 69.53%.
[ Tue Dec  2 17:05:39 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:05:39 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:05:39 2025 ] Training epoch: 52
[ Tue Dec  2 17:07:55 2025 ] 	Mean training loss: 1.6098.  Mean training acc: 70.32%.
[ Tue Dec  2 17:07:55 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:07:55 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:07:55 2025 ] Training epoch: 53
[ Tue Dec  2 17:10:10 2025 ] 	Mean training loss: 1.5858.  Mean training acc: 71.24%.
[ Tue Dec  2 17:10:10 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:10:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:10:10 2025 ] Training epoch: 54
[ Tue Dec  2 17:12:26 2025 ] 	Mean training loss: 1.5831.  Mean training acc: 71.38%.
[ Tue Dec  2 17:12:26 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:12:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:12:26 2025 ] Training epoch: 55
[ Tue Dec  2 17:14:41 2025 ] 	Mean training loss: 1.5691.  Mean training acc: 71.76%.
[ Tue Dec  2 17:14:41 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:14:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:14:41 2025 ] Training epoch: 56
[ Tue Dec  2 17:16:57 2025 ] 	Mean training loss: 1.5647.  Mean training acc: 71.43%.
[ Tue Dec  2 17:16:57 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:16:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:16:57 2025 ] Training epoch: 57
[ Tue Dec  2 17:19:13 2025 ] 	Mean training loss: 1.5506.  Mean training acc: 72.50%.
[ Tue Dec  2 17:19:13 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:19:13 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:19:13 2025 ] Training epoch: 58
[ Tue Dec  2 17:21:28 2025 ] 	Mean training loss: 1.5435.  Mean training acc: 72.36%.
[ Tue Dec  2 17:21:28 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:21:28 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:21:28 2025 ] Training epoch: 59
[ Tue Dec  2 17:23:44 2025 ] 	Mean training loss: 1.5429.  Mean training acc: 72.93%.
[ Tue Dec  2 17:23:44 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:23:44 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:23:44 2025 ] Training epoch: 60
[ Tue Dec  2 17:26:00 2025 ] 	Mean training loss: 1.5262.  Mean training acc: 73.20%.
[ Tue Dec  2 17:26:00 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:26:00 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:26:00 2025 ] Training epoch: 61
[ Tue Dec  2 17:28:16 2025 ] 	Mean training loss: 1.5385.  Mean training acc: 72.90%.
[ Tue Dec  2 17:28:16 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:28:16 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:28:16 2025 ] Training epoch: 62
[ Tue Dec  2 17:30:31 2025 ] 	Mean training loss: 1.5083.  Mean training acc: 73.75%.
[ Tue Dec  2 17:30:31 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:30:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:30:31 2025 ] Training epoch: 63
[ Tue Dec  2 17:32:47 2025 ] 	Mean training loss: 1.5157.  Mean training acc: 74.06%.
[ Tue Dec  2 17:32:47 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:32:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:32:47 2025 ] Training epoch: 64
[ Tue Dec  2 17:35:03 2025 ] 	Mean training loss: 1.5038.  Mean training acc: 73.33%.
[ Tue Dec  2 17:35:03 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:35:03 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:35:03 2025 ] Training epoch: 65
[ Tue Dec  2 17:37:18 2025 ] 	Mean training loss: 1.4916.  Mean training acc: 74.07%.
[ Tue Dec  2 17:37:18 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:37:18 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:37:18 2025 ] Training epoch: 66
[ Tue Dec  2 17:39:34 2025 ] 	Mean training loss: 1.4892.  Mean training acc: 74.64%.
[ Tue Dec  2 17:39:34 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:39:34 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:39:34 2025 ] Training epoch: 67
[ Tue Dec  2 17:41:50 2025 ] 	Mean training loss: 1.4841.  Mean training acc: 74.81%.
[ Tue Dec  2 17:41:50 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:41:50 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:41:50 2025 ] Training epoch: 68
[ Tue Dec  2 17:44:05 2025 ] 	Mean training loss: 1.4745.  Mean training acc: 75.17%.
[ Tue Dec  2 17:44:05 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:44:05 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:44:05 2025 ] Training epoch: 69
[ Tue Dec  2 17:46:21 2025 ] 	Mean training loss: 1.4839.  Mean training acc: 74.39%.
[ Tue Dec  2 17:46:21 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:46:21 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:46:21 2025 ] Training epoch: 70
[ Tue Dec  2 17:48:37 2025 ] 	Mean training loss: 1.4698.  Mean training acc: 75.27%.
[ Tue Dec  2 17:48:37 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:48:37 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:48:37 2025 ] Training epoch: 71
[ Tue Dec  2 17:50:52 2025 ] 	Mean training loss: 1.4587.  Mean training acc: 75.62%.
[ Tue Dec  2 17:50:52 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:50:52 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:50:52 2025 ] Training epoch: 72
[ Tue Dec  2 17:53:08 2025 ] 	Mean training loss: 1.4610.  Mean training acc: 75.23%.
[ Tue Dec  2 17:53:08 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:53:08 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:53:08 2025 ] Training epoch: 73
[ Tue Dec  2 17:55:24 2025 ] 	Mean training loss: 1.4604.  Mean training acc: 75.51%.
[ Tue Dec  2 17:55:24 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 17:55:24 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:55:24 2025 ] Training epoch: 74
[ Tue Dec  2 17:57:39 2025 ] 	Mean training loss: 1.4549.  Mean training acc: 75.80%.
[ Tue Dec  2 17:57:39 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 17:57:39 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:57:39 2025 ] Training epoch: 75
[ Tue Dec  2 17:59:55 2025 ] 	Mean training loss: 1.4365.  Mean training acc: 76.03%.
[ Tue Dec  2 17:59:55 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 17:59:55 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:59:55 2025 ] Training epoch: 76
[ Tue Dec  2 18:02:11 2025 ] 	Mean training loss: 1.4228.  Mean training acc: 76.51%.
[ Tue Dec  2 18:02:11 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:02:11 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:02:11 2025 ] Training epoch: 77
[ Tue Dec  2 18:04:26 2025 ] 	Mean training loss: 1.4360.  Mean training acc: 76.72%.
[ Tue Dec  2 18:04:26 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:04:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:04:26 2025 ] Training epoch: 78
[ Tue Dec  2 18:06:42 2025 ] 	Mean training loss: 1.4228.  Mean training acc: 76.40%.
[ Tue Dec  2 18:06:42 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:06:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:06:42 2025 ] Training epoch: 79
[ Tue Dec  2 18:08:58 2025 ] 	Mean training loss: 1.4038.  Mean training acc: 77.49%.
[ Tue Dec  2 18:08:58 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:08:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:08:58 2025 ] Training epoch: 80
[ Tue Dec  2 18:11:13 2025 ] 	Mean training loss: 1.4220.  Mean training acc: 76.96%.
[ Tue Dec  2 18:11:13 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:11:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:11:13 2025 ] Training epoch: 81
[ Tue Dec  2 18:13:29 2025 ] 	Mean training loss: 1.4125.  Mean training acc: 77.26%.
[ Tue Dec  2 18:13:29 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:13:29 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:13:29 2025 ] Training epoch: 82
[ Tue Dec  2 18:15:45 2025 ] 	Mean training loss: 1.4116.  Mean training acc: 76.84%.
[ Tue Dec  2 18:15:45 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:15:45 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:15:45 2025 ] Training epoch: 83
[ Tue Dec  2 18:18:00 2025 ] 	Mean training loss: 1.4179.  Mean training acc: 77.42%.
[ Tue Dec  2 18:18:00 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:18:00 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:18:00 2025 ] Training epoch: 84
[ Tue Dec  2 18:20:16 2025 ] 	Mean training loss: 1.4047.  Mean training acc: 77.27%.
[ Tue Dec  2 18:20:16 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:20:16 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:20:16 2025 ] Training epoch: 85
[ Tue Dec  2 18:22:32 2025 ] 	Mean training loss: 1.3947.  Mean training acc: 77.70%.
[ Tue Dec  2 18:22:32 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:22:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:22:32 2025 ] Training epoch: 86
[ Tue Dec  2 18:24:47 2025 ] 	Mean training loss: 1.3851.  Mean training acc: 78.19%.
[ Tue Dec  2 18:24:47 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:24:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:24:47 2025 ] Training epoch: 87
[ Tue Dec  2 18:27:03 2025 ] 	Mean training loss: 1.3847.  Mean training acc: 77.86%.
[ Tue Dec  2 18:27:03 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:27:03 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:27:03 2025 ] Training epoch: 88
[ Tue Dec  2 18:29:19 2025 ] 	Mean training loss: 1.3857.  Mean training acc: 77.96%.
[ Tue Dec  2 18:29:19 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:29:19 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:29:19 2025 ] Training epoch: 89
[ Tue Dec  2 18:31:34 2025 ] 	Mean training loss: 1.3870.  Mean training acc: 78.12%.
[ Tue Dec  2 18:31:34 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:31:34 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:31:34 2025 ] Training epoch: 90
[ Tue Dec  2 18:33:50 2025 ] 	Mean training loss: 1.3755.  Mean training acc: 78.74%.
[ Tue Dec  2 18:33:50 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:33:50 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:33:50 2025 ] Training epoch: 91
[ Tue Dec  2 18:36:06 2025 ] 	Mean training loss: 1.3646.  Mean training acc: 78.62%.
[ Tue Dec  2 18:36:06 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:36:06 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:36:06 2025 ] Training epoch: 92
[ Tue Dec  2 18:38:21 2025 ] 	Mean training loss: 1.3733.  Mean training acc: 78.93%.
[ Tue Dec  2 18:38:21 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:38:21 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:38:21 2025 ] Training epoch: 93
[ Tue Dec  2 18:40:37 2025 ] 	Mean training loss: 1.3566.  Mean training acc: 79.64%.
[ Tue Dec  2 18:40:37 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:40:37 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:40:37 2025 ] Training epoch: 94
[ Tue Dec  2 18:42:53 2025 ] 	Mean training loss: 1.3509.  Mean training acc: 79.20%.
[ Tue Dec  2 18:42:53 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:42:53 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:42:53 2025 ] Training epoch: 95
[ Tue Dec  2 18:45:08 2025 ] 	Mean training loss: 1.3561.  Mean training acc: 78.85%.
[ Tue Dec  2 18:45:08 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:45:08 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:45:08 2025 ] Training epoch: 96
[ Tue Dec  2 18:47:24 2025 ] 	Mean training loss: 1.3517.  Mean training acc: 79.21%.
[ Tue Dec  2 18:47:24 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:47:24 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:47:24 2025 ] Training epoch: 97
[ Tue Dec  2 18:49:40 2025 ] 	Mean training loss: 1.3520.  Mean training acc: 79.26%.
[ Tue Dec  2 18:49:40 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:49:40 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:49:40 2025 ] Training epoch: 98
[ Tue Dec  2 18:51:55 2025 ] 	Mean training loss: 1.3651.  Mean training acc: 78.85%.
[ Tue Dec  2 18:51:55 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:51:55 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:51:55 2025 ] Training epoch: 99
[ Tue Dec  2 18:54:11 2025 ] 	Mean training loss: 1.3520.  Mean training acc: 79.40%.
[ Tue Dec  2 18:54:11 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:54:11 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:54:11 2025 ] Training epoch: 100
[ Tue Dec  2 18:56:26 2025 ] 	Mean training loss: 1.3384.  Mean training acc: 79.80%.
[ Tue Dec  2 18:56:26 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:56:26 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:56:26 2025 ] Training epoch: 101
[ Tue Dec  2 18:58:42 2025 ] 	Mean training loss: 1.3410.  Mean training acc: 79.08%.
[ Tue Dec  2 18:58:42 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:58:42 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:58:42 2025 ] Training epoch: 102
[ Tue Dec  2 19:00:58 2025 ] 	Mean training loss: 1.3315.  Mean training acc: 80.08%.
[ Tue Dec  2 19:00:58 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:00:58 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:00:58 2025 ] Training epoch: 103
[ Tue Dec  2 19:03:13 2025 ] 	Mean training loss: 1.3207.  Mean training acc: 80.46%.
[ Tue Dec  2 19:03:13 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:03:13 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:03:13 2025 ] Training epoch: 104
[ Tue Dec  2 19:05:29 2025 ] 	Mean training loss: 1.3136.  Mean training acc: 80.78%.
[ Tue Dec  2 19:05:29 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:05:29 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:05:29 2025 ] Training epoch: 105
[ Tue Dec  2 19:07:45 2025 ] 	Mean training loss: 1.3101.  Mean training acc: 80.84%.
[ Tue Dec  2 19:07:45 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:07:45 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:07:45 2025 ] Training epoch: 106
[ Tue Dec  2 19:10:00 2025 ] 	Mean training loss: 1.3204.  Mean training acc: 80.04%.
[ Tue Dec  2 19:10:00 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:10:00 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:10:00 2025 ] Training epoch: 107
[ Tue Dec  2 19:12:16 2025 ] 	Mean training loss: 1.3190.  Mean training acc: 80.41%.
[ Tue Dec  2 19:12:16 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:12:16 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:12:16 2025 ] Training epoch: 108
[ Tue Dec  2 19:14:32 2025 ] 	Mean training loss: 1.3255.  Mean training acc: 80.10%.
[ Tue Dec  2 19:14:32 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:14:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:14:32 2025 ] Training epoch: 109
[ Tue Dec  2 19:16:47 2025 ] 	Mean training loss: 1.3163.  Mean training acc: 81.17%.
[ Tue Dec  2 19:16:47 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:16:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:16:47 2025 ] Training epoch: 110
[ Tue Dec  2 19:19:03 2025 ] 	Mean training loss: 1.3178.  Mean training acc: 80.68%.
[ Tue Dec  2 19:19:03 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:19:03 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:19:03 2025 ] Training epoch: 111
[ Tue Dec  2 19:21:19 2025 ] 	Mean training loss: 1.3047.  Mean training acc: 81.49%.
[ Tue Dec  2 19:21:19 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:21:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:21:19 2025 ] Training epoch: 112
[ Tue Dec  2 19:23:34 2025 ] 	Mean training loss: 1.3077.  Mean training acc: 80.94%.
[ Tue Dec  2 19:23:34 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:23:34 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:23:34 2025 ] Training epoch: 113
[ Tue Dec  2 19:25:50 2025 ] 	Mean training loss: 1.3053.  Mean training acc: 80.75%.
[ Tue Dec  2 19:25:50 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:25:50 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:25:50 2025 ] Training epoch: 114
[ Tue Dec  2 19:28:06 2025 ] 	Mean training loss: 1.2876.  Mean training acc: 81.94%.
[ Tue Dec  2 19:28:06 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:28:06 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:28:06 2025 ] Training epoch: 115
[ Tue Dec  2 19:30:22 2025 ] 	Mean training loss: 1.3018.  Mean training acc: 81.85%.
[ Tue Dec  2 19:30:22 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:30:22 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:30:22 2025 ] Training epoch: 116
[ Tue Dec  2 19:32:37 2025 ] 	Mean training loss: 1.2954.  Mean training acc: 81.51%.
[ Tue Dec  2 19:32:37 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:32:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:32:37 2025 ] Training epoch: 117
[ Tue Dec  2 19:34:53 2025 ] 	Mean training loss: 1.2831.  Mean training acc: 81.63%.
[ Tue Dec  2 19:34:53 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:34:53 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:34:53 2025 ] Training epoch: 118
[ Tue Dec  2 19:37:09 2025 ] 	Mean training loss: 1.2887.  Mean training acc: 81.72%.
[ Tue Dec  2 19:37:09 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:37:09 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:37:09 2025 ] Training epoch: 119
[ Tue Dec  2 19:39:24 2025 ] 	Mean training loss: 1.2770.  Mean training acc: 82.13%.
[ Tue Dec  2 19:39:24 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:39:24 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:39:24 2025 ] Training epoch: 120
[ Tue Dec  2 19:41:40 2025 ] 	Mean training loss: 1.2930.  Mean training acc: 81.48%.
[ Tue Dec  2 19:41:40 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:41:40 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:41:40 2025 ] Training epoch: 121
[ Tue Dec  2 19:43:55 2025 ] 	Mean training loss: 1.2871.  Mean training acc: 81.94%.
[ Tue Dec  2 19:43:55 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:43:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:43:55 2025 ] Training epoch: 122
[ Tue Dec  2 19:46:11 2025 ] 	Mean training loss: 1.2907.  Mean training acc: 81.58%.
[ Tue Dec  2 19:46:11 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:46:11 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:46:11 2025 ] Training epoch: 123
[ Tue Dec  2 19:48:27 2025 ] 	Mean training loss: 1.2759.  Mean training acc: 82.16%.
[ Tue Dec  2 19:48:27 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:48:27 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:48:27 2025 ] Training epoch: 124
[ Tue Dec  2 19:50:42 2025 ] 	Mean training loss: 1.2831.  Mean training acc: 81.79%.
[ Tue Dec  2 19:50:42 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:50:42 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:50:42 2025 ] Training epoch: 125
[ Tue Dec  2 19:52:58 2025 ] 	Mean training loss: 1.2718.  Mean training acc: 82.03%.
[ Tue Dec  2 19:52:58 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:52:58 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:52:58 2025 ] Training epoch: 126
[ Tue Dec  2 19:55:14 2025 ] 	Mean training loss: 1.2905.  Mean training acc: 81.49%.
[ Tue Dec  2 19:55:14 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:55:14 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:55:14 2025 ] Training epoch: 127
[ Tue Dec  2 19:57:29 2025 ] 	Mean training loss: 1.2587.  Mean training acc: 82.63%.
[ Tue Dec  2 19:57:29 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:57:29 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:57:29 2025 ] Training epoch: 128
[ Tue Dec  2 19:59:45 2025 ] 	Mean training loss: 1.2567.  Mean training acc: 83.04%.
[ Tue Dec  2 19:59:45 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 19:59:45 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:59:45 2025 ] Training epoch: 129
[ Tue Dec  2 20:02:00 2025 ] 	Mean training loss: 1.2535.  Mean training acc: 83.23%.
[ Tue Dec  2 20:02:00 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:02:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:02:00 2025 ] Training epoch: 130
[ Tue Dec  2 20:04:16 2025 ] 	Mean training loss: 1.2430.  Mean training acc: 83.47%.
[ Tue Dec  2 20:04:16 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:04:16 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:04:16 2025 ] Training epoch: 131
[ Tue Dec  2 20:06:32 2025 ] 	Mean training loss: 1.2617.  Mean training acc: 82.32%.
[ Tue Dec  2 20:06:32 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:06:32 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:06:32 2025 ] Training epoch: 132
[ Tue Dec  2 20:08:47 2025 ] 	Mean training loss: 1.2501.  Mean training acc: 82.61%.
[ Tue Dec  2 20:08:47 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:08:47 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:08:47 2025 ] Training epoch: 133
[ Tue Dec  2 20:11:03 2025 ] 	Mean training loss: 1.2532.  Mean training acc: 83.04%.
[ Tue Dec  2 20:11:03 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:11:03 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:11:03 2025 ] Training epoch: 134
[ Tue Dec  2 20:13:19 2025 ] 	Mean training loss: 1.2519.  Mean training acc: 82.70%.
[ Tue Dec  2 20:13:19 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:13:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:13:19 2025 ] Training epoch: 135
[ Tue Dec  2 20:15:35 2025 ] 	Mean training loss: 1.2446.  Mean training acc: 83.23%.
[ Tue Dec  2 20:15:35 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:15:35 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:15:35 2025 ] Training epoch: 136
[ Tue Dec  2 20:17:50 2025 ] 	Mean training loss: 1.2676.  Mean training acc: 81.65%.
[ Tue Dec  2 20:17:50 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:17:50 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:17:50 2025 ] Training epoch: 137
[ Tue Dec  2 20:20:06 2025 ] 	Mean training loss: 1.2364.  Mean training acc: 83.62%.
[ Tue Dec  2 20:20:06 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:20:06 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:20:06 2025 ] Training epoch: 138
[ Tue Dec  2 20:22:21 2025 ] 	Mean training loss: 1.2487.  Mean training acc: 83.37%.
[ Tue Dec  2 20:22:21 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:22:21 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 20:22:21 2025 ] Training epoch: 139
[ Tue Dec  2 20:24:37 2025 ] 	Mean training loss: 1.2437.  Mean training acc: 83.15%.
[ Tue Dec  2 20:24:37 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:24:37 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:24:37 2025 ] Training epoch: 140
[ Tue Dec  2 20:26:53 2025 ] 	Mean training loss: 1.2261.  Mean training acc: 83.72%.
[ Tue Dec  2 20:26:53 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:26:53 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:26:53 2025 ] Training epoch: 141
[ Tue Dec  2 20:29:08 2025 ] 	Mean training loss: 1.2348.  Mean training acc: 83.48%.
[ Tue Dec  2 20:29:08 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:29:08 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:29:08 2025 ] Training epoch: 142
[ Tue Dec  2 20:31:24 2025 ] 	Mean training loss: 1.2346.  Mean training acc: 83.62%.
[ Tue Dec  2 20:31:24 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:31:24 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:31:24 2025 ] Training epoch: 143
[ Tue Dec  2 20:33:40 2025 ] 	Mean training loss: 1.2197.  Mean training acc: 83.88%.
[ Tue Dec  2 20:33:40 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:33:40 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:33:40 2025 ] Training epoch: 144
[ Tue Dec  2 20:35:55 2025 ] 	Mean training loss: 1.2369.  Mean training acc: 83.25%.
[ Tue Dec  2 20:35:55 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:35:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:35:55 2025 ] Training epoch: 145
[ Tue Dec  2 20:38:11 2025 ] 	Mean training loss: 1.2225.  Mean training acc: 83.95%.
[ Tue Dec  2 20:38:11 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:38:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:38:11 2025 ] Training epoch: 146
[ Tue Dec  2 20:40:26 2025 ] 	Mean training loss: 1.2183.  Mean training acc: 83.53%.
[ Tue Dec  2 20:40:26 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:40:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:40:26 2025 ] Training epoch: 147
[ Tue Dec  2 20:42:42 2025 ] 	Mean training loss: 1.2009.  Mean training acc: 84.74%.
[ Tue Dec  2 20:42:42 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:42:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:42:42 2025 ] Training epoch: 148
[ Tue Dec  2 20:44:58 2025 ] 	Mean training loss: 1.2178.  Mean training acc: 83.99%.
[ Tue Dec  2 20:44:58 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:44:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:44:58 2025 ] Training epoch: 149
[ Tue Dec  2 20:47:13 2025 ] 	Mean training loss: 1.2107.  Mean training acc: 84.23%.
[ Tue Dec  2 20:47:13 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:47:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:47:13 2025 ] Training epoch: 150
[ Tue Dec  2 20:49:29 2025 ] 	Mean training loss: 1.2267.  Mean training acc: 83.53%.
[ Tue Dec  2 20:49:29 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:49:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:49:29 2025 ] Training epoch: 151
[ Tue Dec  2 20:51:44 2025 ] 	Mean training loss: 1.2125.  Mean training acc: 84.45%.
[ Tue Dec  2 20:51:44 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:51:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:51:44 2025 ] Training epoch: 152
[ Tue Dec  2 20:54:00 2025 ] 	Mean training loss: 1.2067.  Mean training acc: 84.94%.
[ Tue Dec  2 20:54:00 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:54:00 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:54:00 2025 ] Training epoch: 153
[ Tue Dec  2 20:56:16 2025 ] 	Mean training loss: 1.1979.  Mean training acc: 85.05%.
[ Tue Dec  2 20:56:16 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:56:16 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:56:16 2025 ] Training epoch: 154
[ Tue Dec  2 20:58:31 2025 ] 	Mean training loss: 1.2034.  Mean training acc: 84.66%.
[ Tue Dec  2 20:58:31 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 20:58:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:58:31 2025 ] Training epoch: 155
[ Tue Dec  2 21:00:47 2025 ] 	Mean training loss: 1.2045.  Mean training acc: 84.52%.
[ Tue Dec  2 21:00:47 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:00:47 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:00:47 2025 ] Training epoch: 156
[ Tue Dec  2 21:03:03 2025 ] 	Mean training loss: 1.1956.  Mean training acc: 84.80%.
[ Tue Dec  2 21:03:03 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:03:03 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:03:03 2025 ] Training epoch: 157
[ Tue Dec  2 21:05:18 2025 ] 	Mean training loss: 1.2045.  Mean training acc: 84.89%.
[ Tue Dec  2 21:05:18 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:05:18 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:05:18 2025 ] Training epoch: 158
[ Tue Dec  2 21:07:34 2025 ] 	Mean training loss: 1.1920.  Mean training acc: 85.01%.
[ Tue Dec  2 21:07:34 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:07:34 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:07:34 2025 ] Training epoch: 159
[ Tue Dec  2 21:09:50 2025 ] 	Mean training loss: 1.1941.  Mean training acc: 84.82%.
[ Tue Dec  2 21:09:50 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:09:50 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:09:50 2025 ] Training epoch: 160
[ Tue Dec  2 21:12:06 2025 ] 	Mean training loss: 1.1960.  Mean training acc: 84.86%.
[ Tue Dec  2 21:12:06 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:12:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:12:06 2025 ] Training epoch: 161
[ Tue Dec  2 21:14:21 2025 ] 	Mean training loss: 1.1895.  Mean training acc: 85.68%.
[ Tue Dec  2 21:14:21 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:14:21 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:14:21 2025 ] Training epoch: 162
[ Tue Dec  2 21:16:37 2025 ] 	Mean training loss: 1.1860.  Mean training acc: 85.28%.
[ Tue Dec  2 21:16:37 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:16:37 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:16:37 2025 ] Training epoch: 163
[ Tue Dec  2 21:18:53 2025 ] 	Mean training loss: 1.1817.  Mean training acc: 85.84%.
[ Tue Dec  2 21:18:53 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:18:53 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:18:53 2025 ] Training epoch: 164
[ Tue Dec  2 21:21:08 2025 ] 	Mean training loss: 1.1793.  Mean training acc: 85.59%.
[ Tue Dec  2 21:21:08 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:21:08 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:21:08 2025 ] Training epoch: 165
[ Tue Dec  2 21:23:24 2025 ] 	Mean training loss: 1.1815.  Mean training acc: 85.55%.
[ Tue Dec  2 21:23:24 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:23:24 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:23:24 2025 ] Training epoch: 166
[ Tue Dec  2 21:25:40 2025 ] 	Mean training loss: 1.1794.  Mean training acc: 85.65%.
[ Tue Dec  2 21:25:40 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:25:40 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:25:40 2025 ] Training epoch: 167
[ Tue Dec  2 21:27:55 2025 ] 	Mean training loss: 1.1809.  Mean training acc: 85.56%.
[ Tue Dec  2 21:27:55 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:27:55 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:27:55 2025 ] Training epoch: 168
[ Tue Dec  2 21:30:11 2025 ] 	Mean training loss: 1.1872.  Mean training acc: 85.37%.
[ Tue Dec  2 21:30:11 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:30:11 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:30:11 2025 ] Training epoch: 169
[ Tue Dec  2 21:32:26 2025 ] 	Mean training loss: 1.1798.  Mean training acc: 85.64%.
[ Tue Dec  2 21:32:26 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:32:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:32:26 2025 ] Training epoch: 170
[ Tue Dec  2 21:34:42 2025 ] 	Mean training loss: 1.1835.  Mean training acc: 85.46%.
[ Tue Dec  2 21:34:42 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:34:42 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:34:42 2025 ] Training epoch: 171
[ Tue Dec  2 21:36:58 2025 ] 	Mean training loss: 1.1763.  Mean training acc: 85.47%.
[ Tue Dec  2 21:36:58 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:36:58 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:36:58 2025 ] Training epoch: 172
[ Tue Dec  2 21:39:13 2025 ] 	Mean training loss: 1.1630.  Mean training acc: 86.10%.
[ Tue Dec  2 21:39:13 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:39:13 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:39:13 2025 ] Training epoch: 173
[ Tue Dec  2 21:41:29 2025 ] 	Mean training loss: 1.1753.  Mean training acc: 85.46%.
[ Tue Dec  2 21:41:29 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:41:29 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:41:29 2025 ] Training epoch: 174
[ Tue Dec  2 21:43:45 2025 ] 	Mean training loss: 1.1741.  Mean training acc: 85.56%.
[ Tue Dec  2 21:43:45 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:43:45 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:43:45 2025 ] Training epoch: 175
[ Tue Dec  2 21:46:00 2025 ] 	Mean training loss: 1.1717.  Mean training acc: 85.61%.
[ Tue Dec  2 21:46:00 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:46:00 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:46:00 2025 ] Training epoch: 176
[ Tue Dec  2 21:48:16 2025 ] 	Mean training loss: 1.1690.  Mean training acc: 85.71%.
[ Tue Dec  2 21:48:16 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:48:16 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:48:16 2025 ] Training epoch: 177
[ Tue Dec  2 21:50:31 2025 ] 	Mean training loss: 1.1603.  Mean training acc: 86.15%.
[ Tue Dec  2 21:50:31 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:50:31 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:50:31 2025 ] Training epoch: 178
[ Tue Dec  2 21:52:47 2025 ] 	Mean training loss: 1.1590.  Mean training acc: 86.57%.
[ Tue Dec  2 21:52:47 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:52:47 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:52:47 2025 ] Training epoch: 179
[ Tue Dec  2 21:55:03 2025 ] 	Mean training loss: 1.1556.  Mean training acc: 86.43%.
[ Tue Dec  2 21:55:03 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:55:03 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:55:03 2025 ] Training epoch: 180
[ Tue Dec  2 21:57:18 2025 ] 	Mean training loss: 1.1621.  Mean training acc: 85.96%.
[ Tue Dec  2 21:57:18 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:57:18 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:57:18 2025 ] Training epoch: 181
[ Tue Dec  2 21:59:34 2025 ] 	Mean training loss: 1.1562.  Mean training acc: 86.57%.
[ Tue Dec  2 21:59:34 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 21:59:34 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:59:34 2025 ] Training epoch: 182
[ Tue Dec  2 22:01:50 2025 ] 	Mean training loss: 1.1512.  Mean training acc: 86.45%.
[ Tue Dec  2 22:01:50 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:01:50 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:01:50 2025 ] Training epoch: 183
[ Tue Dec  2 22:04:05 2025 ] 	Mean training loss: 1.1578.  Mean training acc: 86.34%.
[ Tue Dec  2 22:04:05 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:04:05 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:04:05 2025 ] Training epoch: 184
[ Tue Dec  2 22:06:21 2025 ] 	Mean training loss: 1.1537.  Mean training acc: 86.59%.
[ Tue Dec  2 22:06:21 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:06:21 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:06:21 2025 ] Training epoch: 185
[ Tue Dec  2 22:08:36 2025 ] 	Mean training loss: 1.1422.  Mean training acc: 87.05%.
[ Tue Dec  2 22:08:36 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:08:36 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:08:36 2025 ] Training epoch: 186
[ Tue Dec  2 22:10:52 2025 ] 	Mean training loss: 1.1477.  Mean training acc: 86.70%.
[ Tue Dec  2 22:10:52 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:10:52 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:10:52 2025 ] Training epoch: 187
[ Tue Dec  2 22:13:08 2025 ] 	Mean training loss: 1.1386.  Mean training acc: 87.26%.
[ Tue Dec  2 22:13:08 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:13:08 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:13:08 2025 ] Training epoch: 188
[ Tue Dec  2 22:15:23 2025 ] 	Mean training loss: 1.1500.  Mean training acc: 86.72%.
[ Tue Dec  2 22:15:23 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:15:23 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:15:23 2025 ] Training epoch: 189
[ Tue Dec  2 22:17:39 2025 ] 	Mean training loss: 1.1377.  Mean training acc: 86.65%.
[ Tue Dec  2 22:17:39 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:17:39 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:17:39 2025 ] Training epoch: 190
[ Tue Dec  2 22:19:55 2025 ] 	Mean training loss: 1.1295.  Mean training acc: 87.14%.
[ Tue Dec  2 22:19:55 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:19:55 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:19:55 2025 ] Training epoch: 191
[ Tue Dec  2 22:22:10 2025 ] 	Mean training loss: 1.1372.  Mean training acc: 87.24%.
[ Tue Dec  2 22:22:10 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:22:10 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:22:10 2025 ] Training epoch: 192
[ Tue Dec  2 22:24:26 2025 ] 	Mean training loss: 1.1536.  Mean training acc: 86.36%.
[ Tue Dec  2 22:24:26 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:24:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:24:26 2025 ] Training epoch: 193
[ Tue Dec  2 22:26:42 2025 ] 	Mean training loss: 1.1402.  Mean training acc: 87.09%.
[ Tue Dec  2 22:26:42 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:26:42 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:26:42 2025 ] Training epoch: 194
[ Tue Dec  2 22:28:57 2025 ] 	Mean training loss: 1.1167.  Mean training acc: 88.09%.
[ Tue Dec  2 22:28:57 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:28:57 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:28:57 2025 ] Training epoch: 195
[ Tue Dec  2 22:31:13 2025 ] 	Mean training loss: 1.1321.  Mean training acc: 87.33%.
[ Tue Dec  2 22:31:13 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:31:13 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:31:13 2025 ] Training epoch: 196
[ Tue Dec  2 22:33:28 2025 ] 	Mean training loss: 1.1247.  Mean training acc: 87.30%.
[ Tue Dec  2 22:33:28 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:33:28 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:33:28 2025 ] Training epoch: 197
[ Tue Dec  2 22:35:44 2025 ] 	Mean training loss: 1.1310.  Mean training acc: 87.53%.
[ Tue Dec  2 22:35:44 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:35:44 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:35:44 2025 ] Training epoch: 198
[ Tue Dec  2 22:38:00 2025 ] 	Mean training loss: 1.1293.  Mean training acc: 87.26%.
[ Tue Dec  2 22:38:00 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:38:00 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:38:00 2025 ] Training epoch: 199
[ Tue Dec  2 22:40:15 2025 ] 	Mean training loss: 1.1214.  Mean training acc: 87.87%.
[ Tue Dec  2 22:40:15 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:40:15 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:40:15 2025 ] Training epoch: 200
[ Tue Dec  2 22:42:31 2025 ] 	Mean training loss: 1.1161.  Mean training acc: 88.18%.
[ Tue Dec  2 22:42:31 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:42:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:42:31 2025 ] Training epoch: 201
[ Tue Dec  2 22:44:46 2025 ] 	Mean training loss: 1.1189.  Mean training acc: 87.96%.
[ Tue Dec  2 22:44:46 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:44:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:44:46 2025 ] Training epoch: 202
[ Tue Dec  2 22:47:02 2025 ] 	Mean training loss: 1.1136.  Mean training acc: 87.81%.
[ Tue Dec  2 22:47:02 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 22:47:02 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:47:02 2025 ] Training epoch: 203
[ Tue Dec  2 22:49:18 2025 ] 	Mean training loss: 1.1223.  Mean training acc: 87.60%.
[ Tue Dec  2 22:49:18 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 22:49:18 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:49:18 2025 ] Training epoch: 204
[ Tue Dec  2 22:51:34 2025 ] 	Mean training loss: 1.1070.  Mean training acc: 88.18%.
[ Tue Dec  2 22:51:34 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 22:51:34 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:51:34 2025 ] Training epoch: 205
[ Tue Dec  2 22:53:49 2025 ] 	Mean training loss: 1.1137.  Mean training acc: 88.16%.
[ Tue Dec  2 22:53:49 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 22:53:49 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:53:49 2025 ] Training epoch: 206
[ Tue Dec  2 22:56:05 2025 ] 	Mean training loss: 1.1114.  Mean training acc: 88.19%.
[ Tue Dec  2 22:56:05 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 22:56:05 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:56:05 2025 ] Training epoch: 207
[ Tue Dec  2 22:58:20 2025 ] 	Mean training loss: 1.1131.  Mean training acc: 87.95%.
[ Tue Dec  2 22:58:20 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 22:58:20 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:58:20 2025 ] Training epoch: 208
[ Tue Dec  2 23:00:36 2025 ] 	Mean training loss: 1.0965.  Mean training acc: 88.66%.
[ Tue Dec  2 23:00:36 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:00:36 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:00:36 2025 ] Training epoch: 209
[ Tue Dec  2 23:02:52 2025 ] 	Mean training loss: 1.1084.  Mean training acc: 88.14%.
[ Tue Dec  2 23:02:52 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:02:52 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:02:52 2025 ] Training epoch: 210
[ Tue Dec  2 23:05:07 2025 ] 	Mean training loss: 1.1073.  Mean training acc: 88.14%.
[ Tue Dec  2 23:05:07 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:05:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:05:07 2025 ] Training epoch: 211
[ Tue Dec  2 23:07:23 2025 ] 	Mean training loss: 1.0970.  Mean training acc: 88.84%.
[ Tue Dec  2 23:07:23 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:07:23 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:07:23 2025 ] Training epoch: 212
[ Tue Dec  2 23:09:39 2025 ] 	Mean training loss: 1.1021.  Mean training acc: 88.46%.
[ Tue Dec  2 23:09:39 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:09:39 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:09:39 2025 ] Training epoch: 213
[ Tue Dec  2 23:11:54 2025 ] 	Mean training loss: 1.1014.  Mean training acc: 88.46%.
[ Tue Dec  2 23:11:54 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:11:54 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:11:54 2025 ] Training epoch: 214
[ Tue Dec  2 23:14:10 2025 ] 	Mean training loss: 1.1109.  Mean training acc: 88.11%.
[ Tue Dec  2 23:14:10 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:14:10 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:14:10 2025 ] Training epoch: 215
[ Tue Dec  2 23:16:25 2025 ] 	Mean training loss: 1.1104.  Mean training acc: 88.11%.
[ Tue Dec  2 23:16:25 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:16:25 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:16:25 2025 ] Training epoch: 216
[ Tue Dec  2 23:18:41 2025 ] 	Mean training loss: 1.0970.  Mean training acc: 88.55%.
[ Tue Dec  2 23:18:41 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:18:41 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:18:41 2025 ] Training epoch: 217
[ Tue Dec  2 23:20:57 2025 ] 	Mean training loss: 1.0955.  Mean training acc: 88.75%.
[ Tue Dec  2 23:20:57 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:20:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:20:57 2025 ] Training epoch: 218
[ Tue Dec  2 23:23:12 2025 ] 	Mean training loss: 1.0787.  Mean training acc: 89.06%.
[ Tue Dec  2 23:23:12 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:23:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:23:12 2025 ] Training epoch: 219
[ Tue Dec  2 23:25:28 2025 ] 	Mean training loss: 1.0884.  Mean training acc: 89.20%.
[ Tue Dec  2 23:25:28 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:25:28 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:25:28 2025 ] Training epoch: 220
[ Tue Dec  2 23:27:43 2025 ] 	Mean training loss: 1.0816.  Mean training acc: 89.04%.
[ Tue Dec  2 23:27:43 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:27:43 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:27:43 2025 ] Training epoch: 221
[ Tue Dec  2 23:29:59 2025 ] 	Mean training loss: 1.0809.  Mean training acc: 89.03%.
[ Tue Dec  2 23:29:59 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:29:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:29:59 2025 ] Training epoch: 222
[ Tue Dec  2 23:32:15 2025 ] 	Mean training loss: 1.0822.  Mean training acc: 89.18%.
[ Tue Dec  2 23:32:15 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:32:15 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:32:15 2025 ] Training epoch: 223
[ Tue Dec  2 23:34:30 2025 ] 	Mean training loss: 1.0754.  Mean training acc: 89.34%.
[ Tue Dec  2 23:34:30 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:34:30 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:34:30 2025 ] Training epoch: 224
[ Tue Dec  2 23:36:46 2025 ] 	Mean training loss: 1.0811.  Mean training acc: 89.12%.
[ Tue Dec  2 23:36:46 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:36:46 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:36:46 2025 ] Training epoch: 225
[ Tue Dec  2 23:39:01 2025 ] 	Mean training loss: 1.0776.  Mean training acc: 89.11%.
[ Tue Dec  2 23:39:01 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:39:01 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:39:01 2025 ] Training epoch: 226
[ Tue Dec  2 23:41:17 2025 ] 	Mean training loss: 1.0724.  Mean training acc: 89.34%.
[ Tue Dec  2 23:41:17 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:41:17 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:41:17 2025 ] Training epoch: 227
[ Tue Dec  2 23:43:33 2025 ] 	Mean training loss: 1.0742.  Mean training acc: 89.72%.
[ Tue Dec  2 23:43:33 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:43:33 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:43:33 2025 ] Training epoch: 228
[ Tue Dec  2 23:45:48 2025 ] 	Mean training loss: 1.0757.  Mean training acc: 89.20%.
[ Tue Dec  2 23:45:48 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:45:48 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:45:48 2025 ] Training epoch: 229
[ Tue Dec  2 23:48:04 2025 ] 	Mean training loss: 1.0594.  Mean training acc: 90.06%.
[ Tue Dec  2 23:48:04 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:48:04 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:48:04 2025 ] Training epoch: 230
[ Tue Dec  2 23:50:20 2025 ] 	Mean training loss: 1.0714.  Mean training acc: 89.32%.
[ Tue Dec  2 23:50:20 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:50:20 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:50:20 2025 ] Training epoch: 231
[ Tue Dec  2 23:52:35 2025 ] 	Mean training loss: 1.0724.  Mean training acc: 89.25%.
[ Tue Dec  2 23:52:35 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:52:35 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:52:35 2025 ] Training epoch: 232
[ Tue Dec  2 23:54:51 2025 ] 	Mean training loss: 1.0701.  Mean training acc: 89.73%.
[ Tue Dec  2 23:54:51 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:54:51 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:54:51 2025 ] Training epoch: 233
[ Tue Dec  2 23:57:06 2025 ] 	Mean training loss: 1.0709.  Mean training acc: 89.34%.
[ Tue Dec  2 23:57:06 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:57:06 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:57:06 2025 ] Training epoch: 234
[ Tue Dec  2 23:59:22 2025 ] 	Mean training loss: 1.0707.  Mean training acc: 89.50%.
[ Tue Dec  2 23:59:22 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 23:59:22 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:59:22 2025 ] Training epoch: 235
[ Wed Dec  3 00:01:37 2025 ] 	Mean training loss: 1.0599.  Mean training acc: 89.64%.
[ Wed Dec  3 00:01:37 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 00:01:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:01:37 2025 ] Training epoch: 236
[ Wed Dec  3 00:03:53 2025 ] 	Mean training loss: 1.0614.  Mean training acc: 90.00%.
[ Wed Dec  3 00:03:53 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:03:53 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:03:53 2025 ] Training epoch: 237
[ Wed Dec  3 00:06:08 2025 ] 	Mean training loss: 1.0541.  Mean training acc: 90.04%.
[ Wed Dec  3 00:06:08 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:06:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:06:08 2025 ] Training epoch: 238
[ Wed Dec  3 00:08:24 2025 ] 	Mean training loss: 1.0579.  Mean training acc: 89.77%.
[ Wed Dec  3 00:08:24 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:08:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:08:24 2025 ] Training epoch: 239
[ Wed Dec  3 00:10:39 2025 ] 	Mean training loss: 1.0632.  Mean training acc: 89.48%.
[ Wed Dec  3 00:10:39 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:10:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:10:39 2025 ] Training epoch: 240
[ Wed Dec  3 00:12:55 2025 ] 	Mean training loss: 1.0580.  Mean training acc: 89.96%.
[ Wed Dec  3 00:12:55 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:12:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:12:55 2025 ] Training epoch: 241
[ Wed Dec  3 00:15:11 2025 ] 	Mean training loss: 1.0561.  Mean training acc: 90.04%.
[ Wed Dec  3 00:15:11 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:15:11 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:15:11 2025 ] Training epoch: 242
[ Wed Dec  3 00:17:26 2025 ] 	Mean training loss: 1.0485.  Mean training acc: 90.51%.
[ Wed Dec  3 00:17:26 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:17:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:17:26 2025 ] Training epoch: 243
[ Wed Dec  3 00:19:42 2025 ] 	Mean training loss: 1.0537.  Mean training acc: 90.08%.
[ Wed Dec  3 00:19:42 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:19:42 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:19:42 2025 ] Training epoch: 244
[ Wed Dec  3 00:21:58 2025 ] 	Mean training loss: 1.0500.  Mean training acc: 90.37%.
[ Wed Dec  3 00:21:58 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:21:58 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:21:58 2025 ] Training epoch: 245
[ Wed Dec  3 00:24:13 2025 ] 	Mean training loss: 1.0522.  Mean training acc: 90.14%.
[ Wed Dec  3 00:24:13 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:24:13 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:24:13 2025 ] Training epoch: 246
[ Wed Dec  3 00:26:29 2025 ] 	Mean training loss: 1.0414.  Mean training acc: 90.48%.
[ Wed Dec  3 00:26:29 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:26:29 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:26:29 2025 ] Training epoch: 247
[ Wed Dec  3 00:28:44 2025 ] 	Mean training loss: 1.0466.  Mean training acc: 90.69%.
[ Wed Dec  3 00:28:44 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:28:44 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:28:44 2025 ] Training epoch: 248
[ Wed Dec  3 00:31:00 2025 ] 	Mean training loss: 1.0297.  Mean training acc: 91.03%.
[ Wed Dec  3 00:31:00 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:31:00 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:31:00 2025 ] Training epoch: 249
[ Wed Dec  3 00:33:16 2025 ] 	Mean training loss: 1.0415.  Mean training acc: 90.54%.
[ Wed Dec  3 00:33:16 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:33:16 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:33:16 2025 ] Training epoch: 250
[ Wed Dec  3 00:35:31 2025 ] 	Mean training loss: 1.0279.  Mean training acc: 91.36%.
[ Wed Dec  3 00:35:31 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:35:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:35:31 2025 ] Training epoch: 251
[ Wed Dec  3 00:37:47 2025 ] 	Mean training loss: 1.0424.  Mean training acc: 90.79%.
[ Wed Dec  3 00:37:47 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:37:47 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:37:47 2025 ] Training epoch: 252
[ Wed Dec  3 00:40:03 2025 ] 	Mean training loss: 1.0487.  Mean training acc: 89.94%.
[ Wed Dec  3 00:40:03 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:40:03 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:40:03 2025 ] Training epoch: 253
[ Wed Dec  3 00:42:18 2025 ] 	Mean training loss: 1.0450.  Mean training acc: 90.22%.
[ Wed Dec  3 00:42:18 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:42:18 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:42:18 2025 ] Training epoch: 254
[ Wed Dec  3 00:44:34 2025 ] 	Mean training loss: 1.0319.  Mean training acc: 90.65%.
[ Wed Dec  3 00:44:34 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:44:34 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:44:34 2025 ] Training epoch: 255
[ Wed Dec  3 00:46:50 2025 ] 	Mean training loss: 1.0365.  Mean training acc: 90.87%.
[ Wed Dec  3 00:46:50 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:46:50 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:46:50 2025 ] Training epoch: 256
[ Wed Dec  3 00:49:05 2025 ] 	Mean training loss: 1.0326.  Mean training acc: 90.79%.
[ Wed Dec  3 00:49:05 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:49:05 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:49:05 2025 ] Training epoch: 257
[ Wed Dec  3 00:51:21 2025 ] 	Mean training loss: 1.0365.  Mean training acc: 90.87%.
[ Wed Dec  3 00:51:21 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:51:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:51:21 2025 ] Training epoch: 258
[ Wed Dec  3 00:53:36 2025 ] 	Mean training loss: 1.0291.  Mean training acc: 91.40%.
[ Wed Dec  3 00:53:36 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:53:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:53:36 2025 ] Training epoch: 259
[ Wed Dec  3 00:55:52 2025 ] 	Mean training loss: 1.0259.  Mean training acc: 91.20%.
[ Wed Dec  3 00:55:52 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:55:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:55:52 2025 ] Training epoch: 260
[ Wed Dec  3 00:58:08 2025 ] 	Mean training loss: 1.0323.  Mean training acc: 90.71%.
[ Wed Dec  3 00:58:08 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 00:58:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:58:08 2025 ] Training epoch: 261
[ Wed Dec  3 01:00:23 2025 ] 	Mean training loss: 1.0214.  Mean training acc: 91.21%.
[ Wed Dec  3 01:00:23 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 01:00:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:00:23 2025 ] Training epoch: 262
[ Wed Dec  3 01:02:39 2025 ] 	Mean training loss: 1.0198.  Mean training acc: 90.99%.
[ Wed Dec  3 01:02:39 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 01:02:39 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:02:39 2025 ] Training epoch: 263
[ Wed Dec  3 01:04:55 2025 ] 	Mean training loss: 1.0148.  Mean training acc: 91.62%.
[ Wed Dec  3 01:04:55 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 01:04:55 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:04:55 2025 ] Training epoch: 264
[ Wed Dec  3 01:07:10 2025 ] 	Mean training loss: 1.0218.  Mean training acc: 91.29%.
[ Wed Dec  3 01:07:10 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 01:07:10 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:07:10 2025 ] Training epoch: 265
[ Wed Dec  3 01:09:26 2025 ] 	Mean training loss: 1.0062.  Mean training acc: 91.93%.
[ Wed Dec  3 01:09:26 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 01:09:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:09:26 2025 ] Training epoch: 266
[ Wed Dec  3 01:11:42 2025 ] 	Mean training loss: 1.0193.  Mean training acc: 91.34%.
[ Wed Dec  3 01:11:42 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 01:11:42 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:11:42 2025 ] Training epoch: 267
[ Wed Dec  3 01:13:57 2025 ] 	Mean training loss: 1.0069.  Mean training acc: 91.89%.
[ Wed Dec  3 01:13:57 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 01:13:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:13:57 2025 ] Training epoch: 268
[ Wed Dec  3 01:16:13 2025 ] 	Mean training loss: 1.0063.  Mean training acc: 91.88%.
[ Wed Dec  3 01:16:13 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:16:13 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:16:13 2025 ] Training epoch: 269
[ Wed Dec  3 01:18:29 2025 ] 	Mean training loss: 1.0102.  Mean training acc: 91.48%.
[ Wed Dec  3 01:18:29 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:18:29 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:18:29 2025 ] Training epoch: 270
[ Wed Dec  3 01:20:44 2025 ] 	Mean training loss: 1.0032.  Mean training acc: 92.27%.
[ Wed Dec  3 01:20:44 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:20:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:20:44 2025 ] Training epoch: 271
[ Wed Dec  3 01:23:00 2025 ] 	Mean training loss: 1.0106.  Mean training acc: 91.79%.
[ Wed Dec  3 01:23:00 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:23:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:23:00 2025 ] Training epoch: 272
[ Wed Dec  3 01:25:16 2025 ] 	Mean training loss: 1.0092.  Mean training acc: 91.75%.
[ Wed Dec  3 01:25:16 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:25:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:25:16 2025 ] Training epoch: 273
[ Wed Dec  3 01:27:31 2025 ] 	Mean training loss: 1.0046.  Mean training acc: 91.99%.
[ Wed Dec  3 01:27:31 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:27:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:27:31 2025 ] Training epoch: 274
[ Wed Dec  3 01:29:47 2025 ] 	Mean training loss: 1.0009.  Mean training acc: 91.71%.
[ Wed Dec  3 01:29:47 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:29:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:29:47 2025 ] Training epoch: 275
[ Wed Dec  3 01:32:03 2025 ] 	Mean training loss: 1.0034.  Mean training acc: 92.17%.
[ Wed Dec  3 01:32:03 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:32:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:32:03 2025 ] Training epoch: 276
[ Wed Dec  3 01:34:18 2025 ] 	Mean training loss: 1.0067.  Mean training acc: 92.03%.
[ Wed Dec  3 01:34:18 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:34:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:34:18 2025 ] Training epoch: 277
[ Wed Dec  3 01:36:34 2025 ] 	Mean training loss: 0.9969.  Mean training acc: 91.75%.
[ Wed Dec  3 01:36:34 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:36:34 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:36:34 2025 ] Training epoch: 278
[ Wed Dec  3 01:38:49 2025 ] 	Mean training loss: 1.0058.  Mean training acc: 91.43%.
[ Wed Dec  3 01:38:49 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:38:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:38:49 2025 ] Training epoch: 279
[ Wed Dec  3 01:41:05 2025 ] 	Mean training loss: 0.9906.  Mean training acc: 91.98%.
[ Wed Dec  3 01:41:05 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:41:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:41:05 2025 ] Training epoch: 280
[ Wed Dec  3 01:43:20 2025 ] 	Mean training loss: 0.9861.  Mean training acc: 92.39%.
[ Wed Dec  3 01:43:20 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:43:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:43:20 2025 ] Training epoch: 281
[ Wed Dec  3 01:45:36 2025 ] 	Mean training loss: 0.9854.  Mean training acc: 92.24%.
[ Wed Dec  3 01:45:36 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:45:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:45:36 2025 ] Training epoch: 282
[ Wed Dec  3 01:47:52 2025 ] 	Mean training loss: 0.9960.  Mean training acc: 91.90%.
[ Wed Dec  3 01:47:52 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:47:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:47:52 2025 ] Training epoch: 283
[ Wed Dec  3 01:50:07 2025 ] 	Mean training loss: 0.9864.  Mean training acc: 92.49%.
[ Wed Dec  3 01:50:07 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:50:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:50:07 2025 ] Training epoch: 284
[ Wed Dec  3 01:52:23 2025 ] 	Mean training loss: 0.9894.  Mean training acc: 92.54%.
[ Wed Dec  3 01:52:23 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:52:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:52:23 2025 ] Training epoch: 285
[ Wed Dec  3 01:54:38 2025 ] 	Mean training loss: 0.9858.  Mean training acc: 92.41%.
[ Wed Dec  3 01:54:38 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:54:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:54:38 2025 ] Training epoch: 286
[ Wed Dec  3 01:56:54 2025 ] 	Mean training loss: 0.9832.  Mean training acc: 92.61%.
[ Wed Dec  3 01:56:54 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:56:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:56:54 2025 ] Training epoch: 287
[ Wed Dec  3 01:59:10 2025 ] 	Mean training loss: 0.9833.  Mean training acc: 92.39%.
[ Wed Dec  3 01:59:10 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 01:59:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:59:10 2025 ] Training epoch: 288
[ Wed Dec  3 02:01:25 2025 ] 	Mean training loss: 0.9865.  Mean training acc: 92.59%.
[ Wed Dec  3 02:01:25 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:01:25 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:01:25 2025 ] Training epoch: 289
[ Wed Dec  3 02:03:41 2025 ] 	Mean training loss: 0.9786.  Mean training acc: 92.69%.
[ Wed Dec  3 02:03:41 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:03:41 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:03:41 2025 ] Training epoch: 290
[ Wed Dec  3 02:05:57 2025 ] 	Mean training loss: 0.9850.  Mean training acc: 92.51%.
[ Wed Dec  3 02:05:57 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:05:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:05:57 2025 ] Training epoch: 291
[ Wed Dec  3 02:08:12 2025 ] 	Mean training loss: 0.9631.  Mean training acc: 93.33%.
[ Wed Dec  3 02:08:12 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:08:12 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:08:12 2025 ] Training epoch: 292
[ Wed Dec  3 02:10:28 2025 ] 	Mean training loss: 0.9790.  Mean training acc: 92.86%.
[ Wed Dec  3 02:10:28 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:10:28 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:10:28 2025 ] Training epoch: 293
[ Wed Dec  3 02:12:44 2025 ] 	Mean training loss: 0.9864.  Mean training acc: 92.49%.
[ Wed Dec  3 02:12:44 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:12:44 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:12:44 2025 ] Training epoch: 294
[ Wed Dec  3 02:14:59 2025 ] 	Mean training loss: 0.9665.  Mean training acc: 93.28%.
[ Wed Dec  3 02:14:59 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:14:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:14:59 2025 ] Training epoch: 295
[ Wed Dec  3 02:17:15 2025 ] 	Mean training loss: 0.9630.  Mean training acc: 93.44%.
[ Wed Dec  3 02:17:15 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:17:15 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:17:15 2025 ] Training epoch: 296
[ Wed Dec  3 02:19:31 2025 ] 	Mean training loss: 0.9675.  Mean training acc: 93.29%.
[ Wed Dec  3 02:19:31 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:19:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:19:31 2025 ] Training epoch: 297
[ Wed Dec  3 02:21:46 2025 ] 	Mean training loss: 0.9710.  Mean training acc: 93.12%.
[ Wed Dec  3 02:21:46 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:21:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:21:46 2025 ] Training epoch: 298
[ Wed Dec  3 02:24:02 2025 ] 	Mean training loss: 0.9738.  Mean training acc: 92.76%.
[ Wed Dec  3 02:24:02 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:24:02 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:24:02 2025 ] Training epoch: 299
[ Wed Dec  3 02:26:17 2025 ] 	Mean training loss: 0.9609.  Mean training acc: 93.29%.
[ Wed Dec  3 02:26:17 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:26:17 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:26:17 2025 ] Training epoch: 300
[ Wed Dec  3 02:28:33 2025 ] 	Mean training loss: 0.9651.  Mean training acc: 93.01%.
[ Wed Dec  3 02:28:33 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 02:28:33 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:28:33 2025 ] Training epoch: 301
[ Wed Dec  3 02:30:49 2025 ] 	Mean training loss: 0.9647.  Mean training acc: 93.39%.
[ Wed Dec  3 02:30:49 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:30:49 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:30:49 2025 ] Training epoch: 302
[ Wed Dec  3 02:33:05 2025 ] 	Mean training loss: 0.9589.  Mean training acc: 93.42%.
[ Wed Dec  3 02:33:05 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:33:05 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:33:05 2025 ] Training epoch: 303
[ Wed Dec  3 02:35:20 2025 ] 	Mean training loss: 0.9614.  Mean training acc: 93.27%.
[ Wed Dec  3 02:35:20 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:35:20 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:35:20 2025 ] Training epoch: 304
[ Wed Dec  3 02:37:36 2025 ] 	Mean training loss: 0.9530.  Mean training acc: 93.67%.
[ Wed Dec  3 02:37:36 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:37:36 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:37:36 2025 ] Training epoch: 305
[ Wed Dec  3 02:39:52 2025 ] 	Mean training loss: 0.9567.  Mean training acc: 93.61%.
[ Wed Dec  3 02:39:52 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:39:52 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:39:52 2025 ] Training epoch: 306
[ Wed Dec  3 02:42:07 2025 ] 	Mean training loss: 0.9656.  Mean training acc: 93.02%.
[ Wed Dec  3 02:42:07 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:42:07 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:42:07 2025 ] Training epoch: 307
[ Wed Dec  3 02:44:23 2025 ] 	Mean training loss: 0.9549.  Mean training acc: 93.58%.
[ Wed Dec  3 02:44:23 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:44:23 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:44:23 2025 ] Training epoch: 308
[ Wed Dec  3 02:46:39 2025 ] 	Mean training loss: 0.9590.  Mean training acc: 93.28%.
[ Wed Dec  3 02:46:39 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:46:39 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:46:39 2025 ] Training epoch: 309
[ Wed Dec  3 02:48:54 2025 ] 	Mean training loss: 0.9495.  Mean training acc: 94.02%.
[ Wed Dec  3 02:48:54 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:48:54 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:48:54 2025 ] Training epoch: 310
[ Wed Dec  3 02:51:10 2025 ] 	Mean training loss: 0.9512.  Mean training acc: 93.51%.
[ Wed Dec  3 02:51:10 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:51:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:51:10 2025 ] Training epoch: 311
[ Wed Dec  3 02:53:25 2025 ] 	Mean training loss: 0.9509.  Mean training acc: 93.37%.
[ Wed Dec  3 02:53:25 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:53:25 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:53:25 2025 ] Training epoch: 312
[ Wed Dec  3 02:55:41 2025 ] 	Mean training loss: 0.9478.  Mean training acc: 93.81%.
[ Wed Dec  3 02:55:41 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:55:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:55:41 2025 ] Training epoch: 313
[ Wed Dec  3 02:57:57 2025 ] 	Mean training loss: 0.9402.  Mean training acc: 94.15%.
[ Wed Dec  3 02:57:57 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 02:57:57 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:57:57 2025 ] Training epoch: 314
[ Wed Dec  3 03:00:12 2025 ] 	Mean training loss: 0.9377.  Mean training acc: 94.13%.
[ Wed Dec  3 03:00:12 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:00:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:00:12 2025 ] Training epoch: 315
[ Wed Dec  3 03:02:28 2025 ] 	Mean training loss: 0.9448.  Mean training acc: 93.98%.
[ Wed Dec  3 03:02:28 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:02:28 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:02:28 2025 ] Training epoch: 316
[ Wed Dec  3 03:04:44 2025 ] 	Mean training loss: 0.9451.  Mean training acc: 93.94%.
[ Wed Dec  3 03:04:44 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:04:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:04:44 2025 ] Training epoch: 317
[ Wed Dec  3 03:06:59 2025 ] 	Mean training loss: 0.9386.  Mean training acc: 94.02%.
[ Wed Dec  3 03:06:59 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:06:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:06:59 2025 ] Training epoch: 318
[ Wed Dec  3 03:09:15 2025 ] 	Mean training loss: 0.9385.  Mean training acc: 93.95%.
[ Wed Dec  3 03:09:15 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:09:15 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:09:15 2025 ] Training epoch: 319
[ Wed Dec  3 03:11:31 2025 ] 	Mean training loss: 0.9444.  Mean training acc: 93.60%.
[ Wed Dec  3 03:11:31 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:11:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:11:31 2025 ] Training epoch: 320
[ Wed Dec  3 03:13:46 2025 ] 	Mean training loss: 0.9328.  Mean training acc: 94.07%.
[ Wed Dec  3 03:13:46 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:13:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:13:46 2025 ] Training epoch: 321
[ Wed Dec  3 03:16:02 2025 ] 	Mean training loss: 0.9186.  Mean training acc: 94.85%.
[ Wed Dec  3 03:16:02 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:16:02 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:16:02 2025 ] Training epoch: 322
[ Wed Dec  3 03:18:18 2025 ] 	Mean training loss: 0.9362.  Mean training acc: 94.16%.
[ Wed Dec  3 03:18:18 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:18:18 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:18:18 2025 ] Training epoch: 323
[ Wed Dec  3 03:20:33 2025 ] 	Mean training loss: 0.9236.  Mean training acc: 94.66%.
[ Wed Dec  3 03:20:33 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:20:33 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:20:33 2025 ] Training epoch: 324
[ Wed Dec  3 03:22:49 2025 ] 	Mean training loss: 0.9348.  Mean training acc: 93.95%.
[ Wed Dec  3 03:22:49 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:22:49 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:22:49 2025 ] Training epoch: 325
[ Wed Dec  3 03:25:04 2025 ] 	Mean training loss: 0.9353.  Mean training acc: 94.32%.
[ Wed Dec  3 03:25:04 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:25:04 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:25:04 2025 ] Training epoch: 326
[ Wed Dec  3 03:27:20 2025 ] 	Mean training loss: 0.9264.  Mean training acc: 94.46%.
[ Wed Dec  3 03:27:20 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:27:20 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:27:20 2025 ] Training epoch: 327
[ Wed Dec  3 03:29:36 2025 ] 	Mean training loss: 0.9296.  Mean training acc: 94.54%.
[ Wed Dec  3 03:29:36 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:29:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:29:36 2025 ] Training epoch: 328
[ Wed Dec  3 03:31:52 2025 ] 	Mean training loss: 0.9273.  Mean training acc: 94.36%.
[ Wed Dec  3 03:31:52 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:31:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:31:52 2025 ] Training epoch: 329
[ Wed Dec  3 03:34:07 2025 ] 	Mean training loss: 0.9368.  Mean training acc: 93.90%.
[ Wed Dec  3 03:34:07 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:34:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:34:07 2025 ] Training epoch: 330
[ Wed Dec  3 03:36:23 2025 ] 	Mean training loss: 0.9221.  Mean training acc: 94.69%.
[ Wed Dec  3 03:36:23 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:36:23 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:36:23 2025 ] Training epoch: 331
[ Wed Dec  3 03:38:39 2025 ] 	Mean training loss: 0.9267.  Mean training acc: 94.38%.
[ Wed Dec  3 03:38:39 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:38:39 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:38:39 2025 ] Training epoch: 332
[ Wed Dec  3 03:40:54 2025 ] 	Mean training loss: 0.9203.  Mean training acc: 94.39%.
[ Wed Dec  3 03:40:54 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:40:54 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:40:54 2025 ] Training epoch: 333
[ Wed Dec  3 03:43:10 2025 ] 	Mean training loss: 0.9208.  Mean training acc: 94.60%.
[ Wed Dec  3 03:43:10 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:43:10 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:43:10 2025 ] Training epoch: 334
[ Wed Dec  3 03:45:26 2025 ] 	Mean training loss: 0.9142.  Mean training acc: 94.66%.
[ Wed Dec  3 03:45:26 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:45:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:45:26 2025 ] Training epoch: 335
[ Wed Dec  3 03:47:41 2025 ] 	Mean training loss: 0.9224.  Mean training acc: 94.50%.
[ Wed Dec  3 03:47:41 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:47:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:47:41 2025 ] Training epoch: 336
[ Wed Dec  3 03:49:57 2025 ] 	Mean training loss: 0.9165.  Mean training acc: 94.97%.
[ Wed Dec  3 03:49:57 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 03:49:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:49:57 2025 ] Training epoch: 337
[ Wed Dec  3 03:52:13 2025 ] 	Mean training loss: 0.9150.  Mean training acc: 94.73%.
[ Wed Dec  3 03:52:13 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 03:52:13 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:52:13 2025 ] Training epoch: 338
[ Wed Dec  3 03:54:28 2025 ] 	Mean training loss: 0.9103.  Mean training acc: 95.09%.
[ Wed Dec  3 03:54:28 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 03:54:28 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:54:28 2025 ] Training epoch: 339
[ Wed Dec  3 03:56:44 2025 ] 	Mean training loss: 0.9143.  Mean training acc: 94.91%.
[ Wed Dec  3 03:56:44 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 03:56:44 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:56:44 2025 ] Training epoch: 340
[ Wed Dec  3 03:58:59 2025 ] 	Mean training loss: 0.9059.  Mean training acc: 95.24%.
[ Wed Dec  3 03:58:59 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 03:58:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:58:59 2025 ] Training epoch: 341
[ Wed Dec  3 04:01:15 2025 ] 	Mean training loss: 0.9072.  Mean training acc: 95.18%.
[ Wed Dec  3 04:01:15 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:01:15 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:01:15 2025 ] Training epoch: 342
[ Wed Dec  3 04:03:31 2025 ] 	Mean training loss: 0.9007.  Mean training acc: 95.27%.
[ Wed Dec  3 04:03:31 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:03:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:03:31 2025 ] Training epoch: 343
[ Wed Dec  3 04:05:46 2025 ] 	Mean training loss: 0.9176.  Mean training acc: 94.89%.
[ Wed Dec  3 04:05:46 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:05:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:05:46 2025 ] Training epoch: 344
[ Wed Dec  3 04:08:02 2025 ] 	Mean training loss: 0.9094.  Mean training acc: 95.10%.
[ Wed Dec  3 04:08:02 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:08:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:08:02 2025 ] Training epoch: 345
[ Wed Dec  3 04:10:18 2025 ] 	Mean training loss: 0.9048.  Mean training acc: 95.29%.
[ Wed Dec  3 04:10:18 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:10:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:10:18 2025 ] Training epoch: 346
[ Wed Dec  3 04:12:33 2025 ] 	Mean training loss: 0.9027.  Mean training acc: 95.01%.
[ Wed Dec  3 04:12:33 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:12:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:12:33 2025 ] Training epoch: 347
[ Wed Dec  3 04:14:49 2025 ] 	Mean training loss: 0.9105.  Mean training acc: 94.91%.
[ Wed Dec  3 04:14:49 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:14:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:14:49 2025 ] Training epoch: 348
[ Wed Dec  3 04:17:05 2025 ] 	Mean training loss: 0.8984.  Mean training acc: 95.24%.
[ Wed Dec  3 04:17:05 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:17:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:17:05 2025 ] Training epoch: 349
[ Wed Dec  3 04:19:20 2025 ] 	Mean training loss: 0.8939.  Mean training acc: 95.57%.
[ Wed Dec  3 04:19:20 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:19:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:19:20 2025 ] Training epoch: 350
[ Wed Dec  3 04:21:36 2025 ] 	Mean training loss: 0.8937.  Mean training acc: 95.70%.
[ Wed Dec  3 04:21:36 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:21:36 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:21:36 2025 ] Training epoch: 351
[ Wed Dec  3 04:23:52 2025 ] 	Mean training loss: 0.8968.  Mean training acc: 95.51%.
[ Wed Dec  3 04:23:52 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:23:52 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:23:52 2025 ] Training epoch: 352
[ Wed Dec  3 04:26:07 2025 ] 	Mean training loss: 0.8966.  Mean training acc: 95.46%.
[ Wed Dec  3 04:26:07 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:26:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:26:07 2025 ] Training epoch: 353
[ Wed Dec  3 04:28:23 2025 ] 	Mean training loss: 0.8916.  Mean training acc: 95.48%.
[ Wed Dec  3 04:28:23 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:28:23 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:28:23 2025 ] Training epoch: 354
[ Wed Dec  3 04:30:39 2025 ] 	Mean training loss: 0.9021.  Mean training acc: 95.34%.
[ Wed Dec  3 04:30:39 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:30:39 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:30:39 2025 ] Training epoch: 355
[ Wed Dec  3 04:32:54 2025 ] 	Mean training loss: 0.8878.  Mean training acc: 95.84%.
[ Wed Dec  3 04:32:54 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:32:54 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:32:54 2025 ] Training epoch: 356
[ Wed Dec  3 04:35:10 2025 ] 	Mean training loss: 0.8935.  Mean training acc: 95.48%.
[ Wed Dec  3 04:35:10 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:35:10 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:35:10 2025 ] Training epoch: 357
[ Wed Dec  3 04:37:26 2025 ] 	Mean training loss: 0.8831.  Mean training acc: 95.85%.
[ Wed Dec  3 04:37:26 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:37:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:37:26 2025 ] Training epoch: 358
[ Wed Dec  3 04:39:41 2025 ] 	Mean training loss: 0.8817.  Mean training acc: 96.05%.
[ Wed Dec  3 04:39:41 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:39:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:39:41 2025 ] Training epoch: 359
[ Wed Dec  3 04:41:57 2025 ] 	Mean training loss: 0.8943.  Mean training acc: 95.66%.
[ Wed Dec  3 04:41:57 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:41:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:41:57 2025 ] Training epoch: 360
[ Wed Dec  3 04:44:12 2025 ] 	Mean training loss: 0.8876.  Mean training acc: 95.71%.
[ Wed Dec  3 04:44:12 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:44:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:44:12 2025 ] Training epoch: 361
[ Wed Dec  3 04:46:28 2025 ] 	Mean training loss: 0.8832.  Mean training acc: 95.97%.
[ Wed Dec  3 04:46:28 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:46:28 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:46:28 2025 ] Training epoch: 362
[ Wed Dec  3 04:48:44 2025 ] 	Mean training loss: 0.8781.  Mean training acc: 96.08%.
[ Wed Dec  3 04:48:44 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:48:44 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:48:44 2025 ] Training epoch: 363
[ Wed Dec  3 04:50:59 2025 ] 	Mean training loss: 0.8786.  Mean training acc: 96.12%.
[ Wed Dec  3 04:50:59 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:50:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:50:59 2025 ] Training epoch: 364
[ Wed Dec  3 04:53:15 2025 ] 	Mean training loss: 0.8815.  Mean training acc: 95.83%.
[ Wed Dec  3 04:53:15 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:53:15 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:53:15 2025 ] Training epoch: 365
[ Wed Dec  3 04:55:30 2025 ] 	Mean training loss: 0.8769.  Mean training acc: 96.03%.
[ Wed Dec  3 04:55:30 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:55:30 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:55:30 2025 ] Training epoch: 366
[ Wed Dec  3 04:57:46 2025 ] 	Mean training loss: 0.8774.  Mean training acc: 95.96%.
[ Wed Dec  3 04:57:46 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 04:57:46 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:57:46 2025 ] Training epoch: 367
[ Wed Dec  3 05:00:02 2025 ] 	Mean training loss: 0.8767.  Mean training acc: 96.11%.
[ Wed Dec  3 05:00:02 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:00:02 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:00:02 2025 ] Training epoch: 368
[ Wed Dec  3 05:02:17 2025 ] 	Mean training loss: 0.8810.  Mean training acc: 95.89%.
[ Wed Dec  3 05:02:17 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:02:17 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:02:17 2025 ] Training epoch: 369
[ Wed Dec  3 05:04:33 2025 ] 	Mean training loss: 0.8747.  Mean training acc: 96.24%.
[ Wed Dec  3 05:04:33 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:04:33 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:04:33 2025 ] Training epoch: 370
[ Wed Dec  3 05:06:49 2025 ] 	Mean training loss: 0.8718.  Mean training acc: 96.28%.
[ Wed Dec  3 05:06:49 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:06:49 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:06:49 2025 ] Training epoch: 371
[ Wed Dec  3 05:09:05 2025 ] 	Mean training loss: 0.8885.  Mean training acc: 95.60%.
[ Wed Dec  3 05:09:05 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:09:05 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:09:05 2025 ] Training epoch: 372
[ Wed Dec  3 05:11:20 2025 ] 	Mean training loss: 0.8784.  Mean training acc: 96.14%.
[ Wed Dec  3 05:11:20 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:11:20 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:11:20 2025 ] Training epoch: 373
[ Wed Dec  3 05:13:36 2025 ] 	Mean training loss: 0.8684.  Mean training acc: 96.48%.
[ Wed Dec  3 05:13:36 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:13:36 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:13:36 2025 ] Training epoch: 374
[ Wed Dec  3 05:15:51 2025 ] 	Mean training loss: 0.8691.  Mean training acc: 96.30%.
[ Wed Dec  3 05:15:51 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:15:51 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:15:51 2025 ] Training epoch: 375
[ Wed Dec  3 05:18:07 2025 ] 	Mean training loss: 0.8785.  Mean training acc: 95.98%.
[ Wed Dec  3 05:18:07 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:18:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:18:07 2025 ] Training epoch: 376
[ Wed Dec  3 05:20:23 2025 ] 	Mean training loss: 0.8757.  Mean training acc: 96.19%.
[ Wed Dec  3 05:20:23 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:20:23 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:20:23 2025 ] Training epoch: 377
[ Wed Dec  3 05:22:38 2025 ] 	Mean training loss: 0.8700.  Mean training acc: 96.43%.
[ Wed Dec  3 05:22:38 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 05:22:38 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:22:38 2025 ] Training epoch: 378
[ Wed Dec  3 05:24:54 2025 ] 	Mean training loss: 0.8654.  Mean training acc: 96.45%.
[ Wed Dec  3 05:24:54 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:24:54 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:24:54 2025 ] Training epoch: 379
[ Wed Dec  3 05:27:09 2025 ] 	Mean training loss: 0.8751.  Mean training acc: 96.20%.
[ Wed Dec  3 05:27:09 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:27:09 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:27:09 2025 ] Training epoch: 380
[ Wed Dec  3 05:29:25 2025 ] 	Mean training loss: 0.8743.  Mean training acc: 96.10%.
[ Wed Dec  3 05:29:25 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:29:25 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:29:25 2025 ] Training epoch: 381
[ Wed Dec  3 05:31:41 2025 ] 	Mean training loss: 0.8640.  Mean training acc: 96.40%.
[ Wed Dec  3 05:31:41 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:31:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:31:41 2025 ] Training epoch: 382
[ Wed Dec  3 05:33:56 2025 ] 	Mean training loss: 0.8607.  Mean training acc: 96.48%.
[ Wed Dec  3 05:33:56 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:33:56 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:33:56 2025 ] Training epoch: 383
[ Wed Dec  3 05:36:12 2025 ] 	Mean training loss: 0.8586.  Mean training acc: 96.75%.
[ Wed Dec  3 05:36:12 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:36:12 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:36:12 2025 ] Training epoch: 384
[ Wed Dec  3 05:38:27 2025 ] 	Mean training loss: 0.8585.  Mean training acc: 96.66%.
[ Wed Dec  3 05:38:27 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:38:27 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:38:27 2025 ] Training epoch: 385
[ Wed Dec  3 05:40:43 2025 ] 	Mean training loss: 0.8553.  Mean training acc: 96.75%.
[ Wed Dec  3 05:40:43 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:40:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:40:43 2025 ] Training epoch: 386
[ Wed Dec  3 05:42:59 2025 ] 	Mean training loss: 0.8546.  Mean training acc: 97.02%.
[ Wed Dec  3 05:42:59 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:42:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:42:59 2025 ] Training epoch: 387
[ Wed Dec  3 05:45:14 2025 ] 	Mean training loss: 0.8487.  Mean training acc: 96.94%.
[ Wed Dec  3 05:45:14 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:45:14 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:45:14 2025 ] Training epoch: 388
[ Wed Dec  3 05:47:30 2025 ] 	Mean training loss: 0.8600.  Mean training acc: 96.43%.
[ Wed Dec  3 05:47:30 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:47:30 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:47:30 2025 ] Training epoch: 389
[ Wed Dec  3 05:49:46 2025 ] 	Mean training loss: 0.8529.  Mean training acc: 96.65%.
[ Wed Dec  3 05:49:46 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:49:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:49:46 2025 ] Training epoch: 390
[ Wed Dec  3 05:52:01 2025 ] 	Mean training loss: 0.8530.  Mean training acc: 96.67%.
[ Wed Dec  3 05:52:01 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:52:01 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:52:01 2025 ] Training epoch: 391
[ Wed Dec  3 05:54:17 2025 ] 	Mean training loss: 0.8527.  Mean training acc: 96.90%.
[ Wed Dec  3 05:54:17 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:54:17 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:54:17 2025 ] Training epoch: 392
[ Wed Dec  3 05:56:33 2025 ] 	Mean training loss: 0.8566.  Mean training acc: 96.65%.
[ Wed Dec  3 05:56:33 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:56:33 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:56:33 2025 ] Training epoch: 393
[ Wed Dec  3 05:58:48 2025 ] 	Mean training loss: 0.8516.  Mean training acc: 96.85%.
[ Wed Dec  3 05:58:48 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 05:58:48 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:58:48 2025 ] Training epoch: 394
[ Wed Dec  3 06:01:04 2025 ] 	Mean training loss: 0.8445.  Mean training acc: 97.12%.
[ Wed Dec  3 06:01:04 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:01:04 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:01:04 2025 ] Training epoch: 395
[ Wed Dec  3 06:03:20 2025 ] 	Mean training loss: 0.8440.  Mean training acc: 96.94%.
[ Wed Dec  3 06:03:20 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:03:20 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:03:20 2025 ] Training epoch: 396
[ Wed Dec  3 06:05:35 2025 ] 	Mean training loss: 0.8427.  Mean training acc: 97.21%.
[ Wed Dec  3 06:05:35 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:05:35 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:05:35 2025 ] Training epoch: 397
[ Wed Dec  3 06:07:51 2025 ] 	Mean training loss: 0.8480.  Mean training acc: 96.75%.
[ Wed Dec  3 06:07:51 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:07:51 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:07:51 2025 ] Training epoch: 398
[ Wed Dec  3 06:10:07 2025 ] 	Mean training loss: 0.8488.  Mean training acc: 96.91%.
[ Wed Dec  3 06:10:07 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:10:07 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:10:07 2025 ] Training epoch: 399
[ Wed Dec  3 06:12:22 2025 ] 	Mean training loss: 0.8494.  Mean training acc: 96.91%.
[ Wed Dec  3 06:12:22 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:12:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:12:22 2025 ] Training epoch: 400
[ Wed Dec  3 06:14:38 2025 ] 	Mean training loss: 0.8484.  Mean training acc: 96.79%.
[ Wed Dec  3 06:14:38 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:14:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:14:38 2025 ] Training epoch: 401
[ Wed Dec  3 06:16:54 2025 ] 	Mean training loss: 0.8457.  Mean training acc: 96.85%.
[ Wed Dec  3 06:16:54 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:16:54 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:16:54 2025 ] Training epoch: 402
[ Wed Dec  3 06:19:09 2025 ] 	Mean training loss: 0.8375.  Mean training acc: 97.45%.
[ Wed Dec  3 06:19:09 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:19:09 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:19:09 2025 ] Training epoch: 403
[ Wed Dec  3 06:21:25 2025 ] 	Mean training loss: 0.8382.  Mean training acc: 97.37%.
[ Wed Dec  3 06:21:25 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:21:25 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:21:25 2025 ] Training epoch: 404
[ Wed Dec  3 06:23:41 2025 ] 	Mean training loss: 0.8461.  Mean training acc: 96.73%.
[ Wed Dec  3 06:23:41 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:23:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:23:41 2025 ] Training epoch: 405
[ Wed Dec  3 06:25:56 2025 ] 	Mean training loss: 0.8338.  Mean training acc: 97.53%.
[ Wed Dec  3 06:25:56 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:25:56 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:25:56 2025 ] Training epoch: 406
[ Wed Dec  3 06:28:12 2025 ] 	Mean training loss: 0.8442.  Mean training acc: 96.89%.
[ Wed Dec  3 06:28:12 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:28:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:28:12 2025 ] Training epoch: 407
[ Wed Dec  3 06:30:28 2025 ] 	Mean training loss: 0.8347.  Mean training acc: 97.41%.
[ Wed Dec  3 06:30:28 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:30:28 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:30:28 2025 ] Training epoch: 408
[ Wed Dec  3 06:32:43 2025 ] 	Mean training loss: 0.8381.  Mean training acc: 97.05%.
[ Wed Dec  3 06:32:43 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:32:43 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:32:43 2025 ] Training epoch: 409
[ Wed Dec  3 06:34:59 2025 ] 	Mean training loss: 0.8383.  Mean training acc: 97.16%.
[ Wed Dec  3 06:34:59 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:34:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:34:59 2025 ] Training epoch: 410
[ Wed Dec  3 06:37:14 2025 ] 	Mean training loss: 0.8362.  Mean training acc: 97.22%.
[ Wed Dec  3 06:37:14 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:37:14 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:37:14 2025 ] Training epoch: 411
[ Wed Dec  3 06:39:30 2025 ] 	Mean training loss: 0.8363.  Mean training acc: 97.35%.
[ Wed Dec  3 06:39:30 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:39:30 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:39:30 2025 ] Training epoch: 412
[ Wed Dec  3 06:41:46 2025 ] 	Mean training loss: 0.8338.  Mean training acc: 97.45%.
[ Wed Dec  3 06:41:46 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:41:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:41:46 2025 ] Training epoch: 413
[ Wed Dec  3 06:44:01 2025 ] 	Mean training loss: 0.8326.  Mean training acc: 97.41%.
[ Wed Dec  3 06:44:01 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:44:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:44:01 2025 ] Training epoch: 414
[ Wed Dec  3 06:46:17 2025 ] 	Mean training loss: 0.8350.  Mean training acc: 97.13%.
[ Wed Dec  3 06:46:17 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:46:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:46:17 2025 ] Training epoch: 415
[ Wed Dec  3 06:48:33 2025 ] 	Mean training loss: 0.8335.  Mean training acc: 97.32%.
[ Wed Dec  3 06:48:33 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:48:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:48:33 2025 ] Training epoch: 416
[ Wed Dec  3 06:50:48 2025 ] 	Mean training loss: 0.8342.  Mean training acc: 97.33%.
[ Wed Dec  3 06:50:48 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:50:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:50:48 2025 ] Training epoch: 417
[ Wed Dec  3 06:53:04 2025 ] 	Mean training loss: 0.8259.  Mean training acc: 97.53%.
[ Wed Dec  3 06:53:04 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:53:04 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:53:04 2025 ] Training epoch: 418
[ Wed Dec  3 06:55:20 2025 ] 	Mean training loss: 0.8295.  Mean training acc: 97.54%.
[ Wed Dec  3 06:55:20 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:55:20 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:55:20 2025 ] Training epoch: 419
[ Wed Dec  3 06:57:35 2025 ] 	Mean training loss: 0.8233.  Mean training acc: 97.69%.
[ Wed Dec  3 06:57:35 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:57:35 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:57:35 2025 ] Training epoch: 420
[ Wed Dec  3 06:59:51 2025 ] 	Mean training loss: 0.8309.  Mean training acc: 97.83%.
[ Wed Dec  3 06:59:51 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 06:59:51 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:59:51 2025 ] Training epoch: 421
[ Wed Dec  3 07:02:07 2025 ] 	Mean training loss: 0.8332.  Mean training acc: 97.36%.
[ Wed Dec  3 07:02:07 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:02:07 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:02:07 2025 ] Training epoch: 422
[ Wed Dec  3 07:04:22 2025 ] 	Mean training loss: 0.8257.  Mean training acc: 97.60%.
[ Wed Dec  3 07:04:22 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:04:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:04:22 2025 ] Training epoch: 423
[ Wed Dec  3 07:06:38 2025 ] 	Mean training loss: 0.8226.  Mean training acc: 97.59%.
[ Wed Dec  3 07:06:38 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:06:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:06:38 2025 ] Training epoch: 424
[ Wed Dec  3 07:08:54 2025 ] 	Mean training loss: 0.8178.  Mean training acc: 97.81%.
[ Wed Dec  3 07:08:54 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:08:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:08:54 2025 ] Training epoch: 425
[ Wed Dec  3 07:11:09 2025 ] 	Mean training loss: 0.8213.  Mean training acc: 97.70%.
[ Wed Dec  3 07:11:09 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:11:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:11:09 2025 ] Training epoch: 426
[ Wed Dec  3 07:13:25 2025 ] 	Mean training loss: 0.8236.  Mean training acc: 97.73%.
[ Wed Dec  3 07:13:25 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:13:25 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:13:25 2025 ] Training epoch: 427
[ Wed Dec  3 07:15:41 2025 ] 	Mean training loss: 0.8224.  Mean training acc: 97.72%.
[ Wed Dec  3 07:15:41 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:15:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:15:41 2025 ] Training epoch: 428
[ Wed Dec  3 07:17:56 2025 ] 	Mean training loss: 0.8248.  Mean training acc: 97.50%.
[ Wed Dec  3 07:17:56 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:17:56 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:17:56 2025 ] Training epoch: 429
[ Wed Dec  3 07:20:12 2025 ] 	Mean training loss: 0.8145.  Mean training acc: 97.92%.
[ Wed Dec  3 07:20:12 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:20:12 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:20:12 2025 ] Training epoch: 430
[ Wed Dec  3 07:22:28 2025 ] 	Mean training loss: 0.8244.  Mean training acc: 97.74%.
[ Wed Dec  3 07:22:28 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:22:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:22:28 2025 ] Training epoch: 431
[ Wed Dec  3 07:24:43 2025 ] 	Mean training loss: 0.8259.  Mean training acc: 97.59%.
[ Wed Dec  3 07:24:43 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:24:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:24:43 2025 ] Training epoch: 432
[ Wed Dec  3 07:26:59 2025 ] 	Mean training loss: 0.8126.  Mean training acc: 98.11%.
[ Wed Dec  3 07:26:59 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:26:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:26:59 2025 ] Training epoch: 433
[ Wed Dec  3 07:29:15 2025 ] 	Mean training loss: 0.8168.  Mean training acc: 97.82%.
[ Wed Dec  3 07:29:15 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:29:15 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:29:15 2025 ] Training epoch: 434
[ Wed Dec  3 07:31:31 2025 ] 	Mean training loss: 0.8143.  Mean training acc: 97.90%.
[ Wed Dec  3 07:31:31 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:31:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:31:31 2025 ] Training epoch: 435
[ Wed Dec  3 07:33:46 2025 ] 	Mean training loss: 0.8223.  Mean training acc: 97.70%.
[ Wed Dec  3 07:33:46 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 07:33:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:33:46 2025 ] Training epoch: 436
[ Wed Dec  3 07:36:02 2025 ] 	Mean training loss: 0.8147.  Mean training acc: 97.92%.
[ Wed Dec  3 07:36:02 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:36:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:36:02 2025 ] Training epoch: 437
[ Wed Dec  3 07:38:18 2025 ] 	Mean training loss: 0.8156.  Mean training acc: 97.78%.
[ Wed Dec  3 07:38:18 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:38:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:38:18 2025 ] Training epoch: 438
[ Wed Dec  3 07:40:33 2025 ] 	Mean training loss: 0.8128.  Mean training acc: 98.00%.
[ Wed Dec  3 07:40:33 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:40:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:40:33 2025 ] Training epoch: 439
[ Wed Dec  3 07:42:49 2025 ] 	Mean training loss: 0.8174.  Mean training acc: 97.91%.
[ Wed Dec  3 07:42:49 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:42:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:42:49 2025 ] Training epoch: 440
[ Wed Dec  3 07:45:05 2025 ] 	Mean training loss: 0.8147.  Mean training acc: 97.98%.
[ Wed Dec  3 07:45:05 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:45:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:45:05 2025 ] Training epoch: 441
[ Wed Dec  3 07:47:20 2025 ] 	Mean training loss: 0.8074.  Mean training acc: 98.27%.
[ Wed Dec  3 07:47:20 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:47:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:47:20 2025 ] Training epoch: 442
[ Wed Dec  3 07:49:36 2025 ] 	Mean training loss: 0.8130.  Mean training acc: 98.04%.
[ Wed Dec  3 07:49:36 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:49:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:49:36 2025 ] Training epoch: 443
[ Wed Dec  3 07:51:51 2025 ] 	Mean training loss: 0.8106.  Mean training acc: 98.09%.
[ Wed Dec  3 07:51:51 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:51:51 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:51:51 2025 ] Training epoch: 444
[ Wed Dec  3 07:54:07 2025 ] 	Mean training loss: 0.8107.  Mean training acc: 98.12%.
[ Wed Dec  3 07:54:07 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:54:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:54:07 2025 ] Training epoch: 445
[ Wed Dec  3 07:56:23 2025 ] 	Mean training loss: 0.8152.  Mean training acc: 97.78%.
[ Wed Dec  3 07:56:23 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:56:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:56:23 2025 ] Training epoch: 446
[ Wed Dec  3 07:58:39 2025 ] 	Mean training loss: 0.8076.  Mean training acc: 98.20%.
[ Wed Dec  3 07:58:39 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 07:58:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:58:39 2025 ] Training epoch: 447
[ Wed Dec  3 08:00:54 2025 ] 	Mean training loss: 0.8098.  Mean training acc: 98.18%.
[ Wed Dec  3 08:00:54 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:00:54 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 08:00:54 2025 ] Training epoch: 448
[ Wed Dec  3 08:03:10 2025 ] 	Mean training loss: 0.8050.  Mean training acc: 98.23%.
[ Wed Dec  3 08:03:10 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:03:10 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 08:03:10 2025 ] Training epoch: 449
[ Wed Dec  3 08:05:26 2025 ] 	Mean training loss: 0.8099.  Mean training acc: 98.16%.
[ Wed Dec  3 08:05:26 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:05:26 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 08:05:26 2025 ] Training epoch: 450
[ Wed Dec  3 08:07:41 2025 ] 	Mean training loss: 0.8050.  Mean training acc: 98.30%.
[ Wed Dec  3 08:07:41 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:07:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 08:07:41 2025 ] Eval epoch: 450
[ Wed Dec  3 08:12:38 2025 ] 	Mean test loss of 1523 batches: 1.35227239789418.
[ Wed Dec  3 08:12:38 2025 ] 	Top1: 80.51%
[ Wed Dec  3 08:12:39 2025 ] 	Top5: 95.27%
[ Wed Dec  3 08:12:39 2025 ] Training epoch: 451
[ Wed Dec  3 08:14:54 2025 ] 	Mean training loss: 0.8141.  Mean training acc: 97.90%.
[ Wed Dec  3 08:14:54 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:14:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:14:54 2025 ] Eval epoch: 451
[ Wed Dec  3 08:19:51 2025 ] 	Mean test loss of 1523 batches: 1.3548340858868368.
[ Wed Dec  3 08:19:51 2025 ] 	Top1: 80.47%
[ Wed Dec  3 08:19:51 2025 ] 	Top5: 95.13%
[ Wed Dec  3 08:19:51 2025 ] Training epoch: 452
[ Wed Dec  3 08:22:07 2025 ] 	Mean training loss: 0.8066.  Mean training acc: 98.30%.
[ Wed Dec  3 08:22:07 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:22:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:22:07 2025 ] Eval epoch: 452
[ Wed Dec  3 08:27:03 2025 ] 	Mean test loss of 1523 batches: 1.3475852664254326.
[ Wed Dec  3 08:27:03 2025 ] 	Top1: 80.50%
[ Wed Dec  3 08:27:03 2025 ] 	Top5: 95.37%
[ Wed Dec  3 08:27:04 2025 ] Training epoch: 453
[ Wed Dec  3 08:29:19 2025 ] 	Mean training loss: 0.8091.  Mean training acc: 98.29%.
[ Wed Dec  3 08:29:19 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:29:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:29:19 2025 ] Eval epoch: 453
[ Wed Dec  3 08:34:15 2025 ] 	Mean test loss of 1523 batches: 1.3494334598551905.
[ Wed Dec  3 08:34:15 2025 ] 	Top1: 80.74%
[ Wed Dec  3 08:34:15 2025 ] 	Top5: 95.26%
[ Wed Dec  3 08:34:15 2025 ] Training epoch: 454
[ Wed Dec  3 08:36:31 2025 ] 	Mean training loss: 0.8074.  Mean training acc: 98.28%.
[ Wed Dec  3 08:36:31 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:36:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:36:31 2025 ] Eval epoch: 454
[ Wed Dec  3 08:41:28 2025 ] 	Mean test loss of 1523 batches: 1.3438241381591978.
[ Wed Dec  3 08:41:28 2025 ] 	Top1: 80.78%
[ Wed Dec  3 08:41:28 2025 ] 	Top5: 95.17%
[ Wed Dec  3 08:41:29 2025 ] Training epoch: 455
[ Wed Dec  3 08:43:44 2025 ] 	Mean training loss: 0.8079.  Mean training acc: 98.10%.
[ Wed Dec  3 08:43:44 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:43:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:43:44 2025 ] Eval epoch: 455
[ Wed Dec  3 08:48:40 2025 ] 	Mean test loss of 1523 batches: 1.349914698990567.
[ Wed Dec  3 08:48:40 2025 ] 	Top1: 80.53%
[ Wed Dec  3 08:48:41 2025 ] 	Top5: 95.33%
[ Wed Dec  3 08:48:41 2025 ] Training epoch: 456
[ Wed Dec  3 08:50:56 2025 ] 	Mean training loss: 0.8078.  Mean training acc: 98.25%.
[ Wed Dec  3 08:50:56 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:50:56 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:50:56 2025 ] Eval epoch: 456
[ Wed Dec  3 08:55:53 2025 ] 	Mean test loss of 1523 batches: 1.3460937852305326.
[ Wed Dec  3 08:55:53 2025 ] 	Top1: 80.61%
[ Wed Dec  3 08:55:53 2025 ] 	Top5: 95.31%
[ Wed Dec  3 08:55:53 2025 ] Training epoch: 457
[ Wed Dec  3 08:58:09 2025 ] 	Mean training loss: 0.7952.  Mean training acc: 98.60%.
[ Wed Dec  3 08:58:09 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 08:58:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:58:09 2025 ] Eval epoch: 457
[ Wed Dec  3 09:03:05 2025 ] 	Mean test loss of 1523 batches: 1.3563476226788482.
[ Wed Dec  3 09:03:05 2025 ] 	Top1: 80.58%
[ Wed Dec  3 09:03:05 2025 ] 	Top5: 95.21%
[ Wed Dec  3 09:03:06 2025 ] Training epoch: 458
[ Wed Dec  3 09:05:21 2025 ] 	Mean training loss: 0.8052.  Mean training acc: 98.20%.
[ Wed Dec  3 09:05:21 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 09:05:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:05:21 2025 ] Eval epoch: 458
[ Wed Dec  3 09:10:18 2025 ] 	Mean test loss of 1523 batches: 1.3525248743637721.
[ Wed Dec  3 09:10:18 2025 ] 	Top1: 80.47%
[ Wed Dec  3 09:10:18 2025 ] 	Top5: 95.23%
[ Wed Dec  3 09:10:18 2025 ] Training epoch: 459
[ Wed Dec  3 09:12:34 2025 ] 	Mean training loss: 0.8024.  Mean training acc: 98.24%.
[ Wed Dec  3 09:12:34 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 09:12:34 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:12:34 2025 ] Eval epoch: 459
[ Wed Dec  3 09:17:30 2025 ] 	Mean test loss of 1523 batches: 1.3476327008427715.
[ Wed Dec  3 09:17:30 2025 ] 	Top1: 80.79%
[ Wed Dec  3 09:17:30 2025 ] 	Top5: 95.25%
[ Wed Dec  3 09:17:30 2025 ] Training epoch: 460
[ Wed Dec  3 09:19:46 2025 ] 	Mean training loss: 0.8083.  Mean training acc: 98.06%.
[ Wed Dec  3 09:19:46 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 09:19:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:19:46 2025 ] Eval epoch: 460
[ Wed Dec  3 09:24:43 2025 ] 	Mean test loss of 1523 batches: 1.3395767993075396.
[ Wed Dec  3 09:24:43 2025 ] 	Top1: 80.86%
[ Wed Dec  3 09:24:43 2025 ] 	Top5: 95.38%
[ Wed Dec  3 09:24:43 2025 ] Training epoch: 461
[ Wed Dec  3 09:26:59 2025 ] 	Mean training loss: 0.7980.  Mean training acc: 98.41%.
[ Wed Dec  3 09:26:59 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 09:26:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 09:26:59 2025 ] Eval epoch: 461
[ Wed Dec  3 09:31:55 2025 ] 	Mean test loss of 1523 batches: 1.348260069316105.
[ Wed Dec  3 09:31:55 2025 ] 	Top1: 80.75%
[ Wed Dec  3 09:31:55 2025 ] 	Top5: 95.32%
[ Wed Dec  3 09:31:56 2025 ] Training epoch: 462
[ Wed Dec  3 09:34:11 2025 ] 	Mean training loss: 0.8016.  Mean training acc: 98.20%.
[ Wed Dec  3 09:34:11 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 09:34:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:34:11 2025 ] Eval epoch: 462
[ Wed Dec  3 09:39:08 2025 ] 	Mean test loss of 1523 batches: 1.3510811291317053.
[ Wed Dec  3 09:39:08 2025 ] 	Top1: 80.62%
[ Wed Dec  3 09:39:08 2025 ] 	Top5: 95.25%
[ Wed Dec  3 09:39:08 2025 ] Training epoch: 463
[ Wed Dec  3 09:41:24 2025 ] 	Mean training loss: 0.8040.  Mean training acc: 98.37%.
[ Wed Dec  3 09:41:24 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 09:41:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:41:24 2025 ] Eval epoch: 463
[ Wed Dec  3 09:46:20 2025 ] 	Mean test loss of 1523 batches: 1.3470926483994006.
[ Wed Dec  3 09:46:20 2025 ] 	Top1: 80.73%
[ Wed Dec  3 09:46:20 2025 ] 	Top5: 95.29%
[ Wed Dec  3 09:46:20 2025 ] Training epoch: 464
[ Wed Dec  3 09:48:36 2025 ] 	Mean training loss: 0.8015.  Mean training acc: 98.29%.
[ Wed Dec  3 09:48:36 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 09:48:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:48:36 2025 ] Eval epoch: 464
[ Wed Dec  3 09:53:32 2025 ] 	Mean test loss of 1523 batches: 1.3470948601896169.
[ Wed Dec  3 09:53:32 2025 ] 	Top1: 80.53%
[ Wed Dec  3 09:53:33 2025 ] 	Top5: 95.24%
[ Wed Dec  3 09:53:33 2025 ] Training epoch: 465
[ Wed Dec  3 09:55:48 2025 ] 	Mean training loss: 0.7949.  Mean training acc: 98.51%.
[ Wed Dec  3 09:55:48 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 09:55:48 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 09:55:48 2025 ] Eval epoch: 465
[ Wed Dec  3 10:00:43 2025 ] 	Mean test loss of 1523 batches: 1.3510713870793052.
[ Wed Dec  3 10:00:44 2025 ] 	Top1: 80.70%
[ Wed Dec  3 10:00:44 2025 ] 	Top5: 95.27%
[ Wed Dec  3 10:00:44 2025 ] Training epoch: 466
[ Wed Dec  3 10:02:59 2025 ] 	Mean training loss: 0.7995.  Mean training acc: 98.39%.
[ Wed Dec  3 10:02:59 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 10:02:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:02:59 2025 ] Eval epoch: 466
[ Wed Dec  3 10:07:56 2025 ] 	Mean test loss of 1523 batches: 1.345240667354724.
[ Wed Dec  3 10:07:56 2025 ] 	Top1: 80.68%
[ Wed Dec  3 10:07:56 2025 ] 	Top5: 95.33%
[ Wed Dec  3 10:07:57 2025 ] Training epoch: 467
[ Wed Dec  3 10:10:12 2025 ] 	Mean training loss: 0.8029.  Mean training acc: 98.05%.
[ Wed Dec  3 10:10:12 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 10:10:12 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:10:12 2025 ] Eval epoch: 467
[ Wed Dec  3 10:15:09 2025 ] 	Mean test loss of 1523 batches: 1.3486601323652487.
[ Wed Dec  3 10:15:09 2025 ] 	Top1: 80.63%
[ Wed Dec  3 10:15:09 2025 ] 	Top5: 95.33%
[ Wed Dec  3 10:15:09 2025 ] Training epoch: 468
[ Wed Dec  3 10:17:25 2025 ] 	Mean training loss: 0.8043.  Mean training acc: 98.25%.
[ Wed Dec  3 10:17:25 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 10:17:25 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:17:25 2025 ] Eval epoch: 468
[ Wed Dec  3 10:22:21 2025 ] 	Mean test loss of 1523 batches: 1.3484930381208209.
[ Wed Dec  3 10:22:21 2025 ] 	Top1: 80.73%
[ Wed Dec  3 10:22:21 2025 ] 	Top5: 95.26%
[ Wed Dec  3 10:22:21 2025 ] Training epoch: 469
[ Wed Dec  3 10:24:37 2025 ] 	Mean training loss: 0.7971.  Mean training acc: 98.37%.
[ Wed Dec  3 10:24:37 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 10:24:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:24:37 2025 ] Eval epoch: 469
[ Wed Dec  3 10:29:33 2025 ] 	Mean test loss of 1523 batches: 1.3491701886439433.
[ Wed Dec  3 10:29:33 2025 ] 	Top1: 80.76%
[ Wed Dec  3 10:29:33 2025 ] 	Top5: 95.19%
[ Wed Dec  3 10:29:33 2025 ] Training epoch: 470
[ Wed Dec  3 10:31:49 2025 ] 	Mean training loss: 0.8013.  Mean training acc: 98.24%.
[ Wed Dec  3 10:31:49 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 10:31:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:31:49 2025 ] Eval epoch: 470
[ Wed Dec  3 10:36:46 2025 ] 	Mean test loss of 1523 batches: 1.3423014287876598.
[ Wed Dec  3 10:36:46 2025 ] 	Top1: 80.87%
[ Wed Dec  3 10:36:46 2025 ] 	Top5: 95.28%
[ Wed Dec  3 10:36:46 2025 ] Training epoch: 471
[ Wed Dec  3 10:39:02 2025 ] 	Mean training loss: 0.7993.  Mean training acc: 98.30%.
[ Wed Dec  3 10:39:02 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 10:39:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:39:02 2025 ] Eval epoch: 471
[ Wed Dec  3 10:43:58 2025 ] 	Mean test loss of 1523 batches: 1.3567135307793545.
[ Wed Dec  3 10:43:58 2025 ] 	Top1: 80.56%
[ Wed Dec  3 10:43:58 2025 ] 	Top5: 95.17%
[ Wed Dec  3 10:43:58 2025 ] Training epoch: 472
[ Wed Dec  3 10:46:14 2025 ] 	Mean training loss: 0.8049.  Mean training acc: 98.18%.
[ Wed Dec  3 10:46:14 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 10:46:14 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:46:14 2025 ] Eval epoch: 472
[ Wed Dec  3 10:51:10 2025 ] 	Mean test loss of 1523 batches: 1.3482586506629413.
[ Wed Dec  3 10:51:10 2025 ] 	Top1: 80.76%
[ Wed Dec  3 10:51:10 2025 ] 	Top5: 95.34%
[ Wed Dec  3 10:51:10 2025 ] Training epoch: 473
[ Wed Dec  3 10:53:26 2025 ] 	Mean training loss: 0.7930.  Mean training acc: 98.57%.
[ Wed Dec  3 10:53:26 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 10:53:26 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 10:53:26 2025 ] Eval epoch: 473
[ Wed Dec  3 10:58:23 2025 ] 	Mean test loss of 1523 batches: 1.3489432484009356.
[ Wed Dec  3 10:58:23 2025 ] 	Top1: 80.73%
[ Wed Dec  3 10:58:23 2025 ] 	Top5: 95.25%
[ Wed Dec  3 10:58:23 2025 ] Training epoch: 474
[ Wed Dec  3 11:00:39 2025 ] 	Mean training loss: 0.7968.  Mean training acc: 98.49%.
[ Wed Dec  3 11:00:39 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:00:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:00:39 2025 ] Eval epoch: 474
[ Wed Dec  3 11:05:35 2025 ] 	Mean test loss of 1523 batches: 1.3474263728878173.
[ Wed Dec  3 11:05:35 2025 ] 	Top1: 80.76%
[ Wed Dec  3 11:05:36 2025 ] 	Top5: 95.22%
[ Wed Dec  3 11:05:36 2025 ] Training epoch: 475
[ Wed Dec  3 11:07:51 2025 ] 	Mean training loss: 0.7963.  Mean training acc: 98.44%.
[ Wed Dec  3 11:07:51 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:07:51 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:07:51 2025 ] Eval epoch: 475
[ Wed Dec  3 11:12:48 2025 ] 	Mean test loss of 1523 batches: 1.343213269683928.
[ Wed Dec  3 11:12:48 2025 ] 	Top1: 80.93%
[ Wed Dec  3 11:12:48 2025 ] 	Top5: 95.35%
[ Wed Dec  3 11:12:48 2025 ] Training epoch: 476
[ Wed Dec  3 11:15:04 2025 ] 	Mean training loss: 0.7993.  Mean training acc: 98.53%.
[ Wed Dec  3 11:15:04 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:15:04 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 11:15:04 2025 ] Eval epoch: 476
[ Wed Dec  3 11:20:01 2025 ] 	Mean test loss of 1523 batches: 1.3565482184124555.
[ Wed Dec  3 11:20:01 2025 ] 	Top1: 80.66%
[ Wed Dec  3 11:20:01 2025 ] 	Top5: 95.14%
[ Wed Dec  3 11:20:01 2025 ] Training epoch: 477
[ Wed Dec  3 11:22:17 2025 ] 	Mean training loss: 0.8021.  Mean training acc: 98.39%.
[ Wed Dec  3 11:22:17 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:22:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:22:17 2025 ] Eval epoch: 477
[ Wed Dec  3 11:27:14 2025 ] 	Mean test loss of 1523 batches: 1.3479878830424439.
[ Wed Dec  3 11:27:14 2025 ] 	Top1: 80.79%
[ Wed Dec  3 11:27:14 2025 ] 	Top5: 95.27%
[ Wed Dec  3 11:27:14 2025 ] Training epoch: 478
[ Wed Dec  3 11:29:30 2025 ] 	Mean training loss: 0.7989.  Mean training acc: 98.34%.
[ Wed Dec  3 11:29:30 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:29:30 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:29:30 2025 ] Eval epoch: 478
[ Wed Dec  3 11:34:26 2025 ] 	Mean test loss of 1523 batches: 1.3437884583022355.
[ Wed Dec  3 11:34:26 2025 ] 	Top1: 80.80%
[ Wed Dec  3 11:34:27 2025 ] 	Top5: 95.35%
[ Wed Dec  3 11:34:27 2025 ] Training epoch: 479
[ Wed Dec  3 11:36:42 2025 ] 	Mean training loss: 0.7967.  Mean training acc: 98.52%.
[ Wed Dec  3 11:36:42 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:36:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:36:42 2025 ] Eval epoch: 479
[ Wed Dec  3 11:41:39 2025 ] 	Mean test loss of 1523 batches: 1.3529800942518644.
[ Wed Dec  3 11:41:39 2025 ] 	Top1: 80.56%
[ Wed Dec  3 11:41:39 2025 ] 	Top5: 95.18%
[ Wed Dec  3 11:41:39 2025 ] Training epoch: 480
[ Wed Dec  3 11:43:55 2025 ] 	Mean training loss: 0.7973.  Mean training acc: 98.34%.
[ Wed Dec  3 11:43:55 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:43:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:43:55 2025 ] Eval epoch: 480
[ Wed Dec  3 11:48:51 2025 ] 	Mean test loss of 1523 batches: 1.3440488781180728.
[ Wed Dec  3 11:48:51 2025 ] 	Top1: 80.80%
[ Wed Dec  3 11:48:51 2025 ] 	Top5: 95.35%
[ Wed Dec  3 11:48:52 2025 ] Training epoch: 481
[ Wed Dec  3 11:51:07 2025 ] 	Mean training loss: 0.7967.  Mean training acc: 98.35%.
[ Wed Dec  3 11:51:07 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:51:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:51:07 2025 ] Eval epoch: 481
[ Wed Dec  3 11:56:03 2025 ] 	Mean test loss of 1523 batches: 1.3445165987791234.
[ Wed Dec  3 11:56:03 2025 ] 	Top1: 80.95%
[ Wed Dec  3 11:56:03 2025 ] 	Top5: 95.34%
[ Wed Dec  3 11:56:04 2025 ] Training epoch: 482
[ Wed Dec  3 11:58:19 2025 ] 	Mean training loss: 0.7943.  Mean training acc: 98.61%.
[ Wed Dec  3 11:58:19 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 11:58:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:58:19 2025 ] Eval epoch: 482
[ Wed Dec  3 12:03:16 2025 ] 	Mean test loss of 1523 batches: 1.347615754964394.
[ Wed Dec  3 12:03:16 2025 ] 	Top1: 80.76%
[ Wed Dec  3 12:03:17 2025 ] 	Top5: 95.25%
[ Wed Dec  3 12:03:17 2025 ] Training epoch: 483
[ Wed Dec  3 12:05:32 2025 ] 	Mean training loss: 0.8008.  Mean training acc: 98.27%.
[ Wed Dec  3 12:05:32 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 12:05:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:05:32 2025 ] Eval epoch: 483
[ Wed Dec  3 12:10:29 2025 ] 	Mean test loss of 1523 batches: 1.3445009522663474.
[ Wed Dec  3 12:10:29 2025 ] 	Top1: 80.93%
[ Wed Dec  3 12:10:29 2025 ] 	Top5: 95.31%
[ Wed Dec  3 12:10:30 2025 ] Training epoch: 484
[ Wed Dec  3 12:12:45 2025 ] 	Mean training loss: 0.7998.  Mean training acc: 98.39%.
[ Wed Dec  3 12:12:45 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 12:12:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:12:45 2025 ] Eval epoch: 484
[ Wed Dec  3 12:17:43 2025 ] 	Mean test loss of 1523 batches: 1.3478801774101983.
[ Wed Dec  3 12:17:43 2025 ] 	Top1: 80.86%
[ Wed Dec  3 12:17:43 2025 ] 	Top5: 95.18%
[ Wed Dec  3 12:17:43 2025 ] Training epoch: 485
[ Wed Dec  3 12:19:59 2025 ] 	Mean training loss: 0.8035.  Mean training acc: 98.33%.
[ Wed Dec  3 12:19:59 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 12:19:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 12:19:59 2025 ] Eval epoch: 485
[ Wed Dec  3 12:24:55 2025 ] 	Mean test loss of 1523 batches: 1.3472475665068047.
[ Wed Dec  3 12:24:55 2025 ] 	Top1: 80.82%
[ Wed Dec  3 12:24:56 2025 ] 	Top5: 95.34%
[ Wed Dec  3 12:24:56 2025 ] Training epoch: 486
[ Wed Dec  3 12:27:11 2025 ] 	Mean training loss: 0.7969.  Mean training acc: 98.48%.
[ Wed Dec  3 12:27:11 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 12:27:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:27:11 2025 ] Eval epoch: 486
[ Wed Dec  3 12:32:08 2025 ] 	Mean test loss of 1523 batches: 1.3442414093393287.
[ Wed Dec  3 12:32:08 2025 ] 	Top1: 80.87%
[ Wed Dec  3 12:32:08 2025 ] 	Top5: 95.33%
[ Wed Dec  3 12:32:08 2025 ] Training epoch: 487
[ Wed Dec  3 12:34:24 2025 ] 	Mean training loss: 0.7947.  Mean training acc: 98.43%.
[ Wed Dec  3 12:34:24 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 12:34:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:34:24 2025 ] Eval epoch: 487
[ Wed Dec  3 12:39:20 2025 ] 	Mean test loss of 1523 batches: 1.3498868098089902.
[ Wed Dec  3 12:39:21 2025 ] 	Top1: 80.76%
[ Wed Dec  3 12:39:21 2025 ] 	Top5: 95.29%
[ Wed Dec  3 12:39:21 2025 ] Training epoch: 488
[ Wed Dec  3 12:41:36 2025 ] 	Mean training loss: 0.7927.  Mean training acc: 98.56%.
[ Wed Dec  3 12:41:36 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 12:41:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:41:36 2025 ] Eval epoch: 488
[ Wed Dec  3 12:46:33 2025 ] 	Mean test loss of 1523 batches: 1.3456021183740912.
[ Wed Dec  3 12:46:33 2025 ] 	Top1: 80.77%
[ Wed Dec  3 12:46:33 2025 ] 	Top5: 95.29%
[ Wed Dec  3 12:46:33 2025 ] Training epoch: 489
[ Wed Dec  3 12:48:49 2025 ] 	Mean training loss: 0.7912.  Mean training acc: 98.72%.
[ Wed Dec  3 12:48:49 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 12:48:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:48:49 2025 ] Eval epoch: 489
[ Wed Dec  3 12:53:45 2025 ] 	Mean test loss of 1523 batches: 1.344291501114107.
[ Wed Dec  3 12:53:45 2025 ] 	Top1: 80.92%
[ Wed Dec  3 12:53:45 2025 ] 	Top5: 95.31%
[ Wed Dec  3 12:53:46 2025 ] Training epoch: 490
[ Wed Dec  3 12:56:01 2025 ] 	Mean training loss: 0.7940.  Mean training acc: 98.58%.
[ Wed Dec  3 12:56:01 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 12:56:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:56:01 2025 ] Eval epoch: 490
[ Wed Dec  3 13:00:57 2025 ] 	Mean test loss of 1523 batches: 1.3440209971551276.
[ Wed Dec  3 13:00:58 2025 ] 	Top1: 80.97%
[ Wed Dec  3 13:00:58 2025 ] 	Top5: 95.24%
[ Wed Dec  3 13:00:58 2025 ] Training epoch: 491
[ Wed Dec  3 13:03:13 2025 ] 	Mean training loss: 0.7948.  Mean training acc: 98.39%.
[ Wed Dec  3 13:03:13 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:03:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:03:13 2025 ] Eval epoch: 491
[ Wed Dec  3 13:08:10 2025 ] 	Mean test loss of 1523 batches: 1.3467630989756618.
[ Wed Dec  3 13:08:10 2025 ] 	Top1: 80.84%
[ Wed Dec  3 13:08:11 2025 ] 	Top5: 95.27%
[ Wed Dec  3 13:08:11 2025 ] Training epoch: 492
[ Wed Dec  3 13:10:26 2025 ] 	Mean training loss: 0.7911.  Mean training acc: 98.62%.
[ Wed Dec  3 13:10:26 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:10:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:10:26 2025 ] Eval epoch: 492
[ Wed Dec  3 13:15:23 2025 ] 	Mean test loss of 1523 batches: 1.343951225202489.
[ Wed Dec  3 13:15:23 2025 ] 	Top1: 80.94%
[ Wed Dec  3 13:15:24 2025 ] 	Top5: 95.37%
[ Wed Dec  3 13:15:24 2025 ] Training epoch: 493
[ Wed Dec  3 13:17:39 2025 ] 	Mean training loss: 0.7946.  Mean training acc: 98.51%.
[ Wed Dec  3 13:17:39 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:17:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:17:39 2025 ] Eval epoch: 493
[ Wed Dec  3 13:22:35 2025 ] 	Mean test loss of 1523 batches: 1.346148287357661.
[ Wed Dec  3 13:22:35 2025 ] 	Top1: 80.87%
[ Wed Dec  3 13:22:36 2025 ] 	Top5: 95.24%
[ Wed Dec  3 13:22:36 2025 ] Training epoch: 494
[ Wed Dec  3 13:24:51 2025 ] 	Mean training loss: 0.7934.  Mean training acc: 98.48%.
[ Wed Dec  3 13:24:51 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:24:51 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:24:51 2025 ] Eval epoch: 494
[ Wed Dec  3 13:29:48 2025 ] 	Mean test loss of 1523 batches: 1.3471546915120696.
[ Wed Dec  3 13:29:48 2025 ] 	Top1: 80.85%
[ Wed Dec  3 13:29:48 2025 ] 	Top5: 95.22%
[ Wed Dec  3 13:29:48 2025 ] Training epoch: 495
[ Wed Dec  3 13:32:04 2025 ] 	Mean training loss: 0.7963.  Mean training acc: 98.52%.
[ Wed Dec  3 13:32:04 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:32:04 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:32:04 2025 ] Eval epoch: 495
[ Wed Dec  3 13:37:01 2025 ] 	Mean test loss of 1523 batches: 1.3567523964126096.
[ Wed Dec  3 13:37:01 2025 ] 	Top1: 80.53%
[ Wed Dec  3 13:37:01 2025 ] 	Top5: 95.09%
[ Wed Dec  3 13:37:01 2025 ] Training epoch: 496
[ Wed Dec  3 13:39:17 2025 ] 	Mean training loss: 0.7986.  Mean training acc: 98.25%.
[ Wed Dec  3 13:39:17 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:39:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:39:17 2025 ] Eval epoch: 496
[ Wed Dec  3 13:44:13 2025 ] 	Mean test loss of 1523 batches: 1.3486146565260106.
[ Wed Dec  3 13:44:13 2025 ] 	Top1: 80.74%
[ Wed Dec  3 13:44:13 2025 ] 	Top5: 95.16%
[ Wed Dec  3 13:44:14 2025 ] Training epoch: 497
[ Wed Dec  3 13:46:29 2025 ] 	Mean training loss: 0.7987.  Mean training acc: 98.29%.
[ Wed Dec  3 13:46:29 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:46:29 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 13:46:29 2025 ] Eval epoch: 497
[ Wed Dec  3 13:51:25 2025 ] 	Mean test loss of 1523 batches: 1.3442962227177635.
[ Wed Dec  3 13:51:25 2025 ] 	Top1: 80.79%
[ Wed Dec  3 13:51:25 2025 ] 	Top5: 95.30%
[ Wed Dec  3 13:51:25 2025 ] Training epoch: 498
[ Wed Dec  3 13:53:41 2025 ] 	Mean training loss: 0.7930.  Mean training acc: 98.44%.
[ Wed Dec  3 13:53:41 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:53:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 13:53:41 2025 ] Eval epoch: 498
[ Wed Dec  3 13:58:38 2025 ] 	Mean test loss of 1523 batches: 1.34960071369761.
[ Wed Dec  3 13:58:38 2025 ] 	Top1: 80.68%
[ Wed Dec  3 13:58:38 2025 ] 	Top5: 95.23%
[ Wed Dec  3 13:58:38 2025 ] Training epoch: 499
[ Wed Dec  3 14:00:54 2025 ] 	Mean training loss: 0.7944.  Mean training acc: 98.56%.
[ Wed Dec  3 14:00:54 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:00:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:00:54 2025 ] Eval epoch: 499
[ Wed Dec  3 14:05:50 2025 ] 	Mean test loss of 1523 batches: 1.3444676443455021.
[ Wed Dec  3 14:05:50 2025 ] 	Top1: 80.91%
[ Wed Dec  3 14:05:50 2025 ] 	Top5: 95.30%
[ Wed Dec  3 14:05:51 2025 ] Training epoch: 500
[ Wed Dec  3 14:08:06 2025 ] 	Mean training loss: 0.7935.  Mean training acc: 98.58%.
[ Wed Dec  3 14:08:06 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:08:06 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 14:08:06 2025 ] Eval epoch: 500
[ Wed Dec  3 14:13:03 2025 ] 	Mean test loss of 1523 batches: 1.3479898241657375.
[ Wed Dec  3 14:13:03 2025 ] 	Top1: 80.74%
[ Wed Dec  3 14:13:03 2025 ] 	Top5: 95.23%
[ Wed Dec  3 14:18:02 2025 ] Best accuracy: 0.8097300626090527
[ Wed Dec  3 14:18:02 2025 ] Epoch number: 490
[ Wed Dec  3 14:18:02 2025 ] Model name: ./work_dir8/ntu/cs/SkateFormer_j/
[ Wed Dec  3 14:18:02 2025 ] Model total number of params: 3616083
[ Wed Dec  3 14:18:02 2025 ] Weight decay: 0.1
[ Wed Dec  3 14:18:02 2025 ] Base LR: 0.001
[ Wed Dec  3 14:18:02 2025 ] Batch Size: 32
[ Wed Dec  3 14:18:02 2025 ] Test Batch Size: 32
[ Wed Dec  3 14:18:02 2025 ] seed: 1
