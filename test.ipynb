{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df81f150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phuongnam/.miniconda3/envs/skateformer/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import inspect\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import traceback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchlight import DictAction\n",
    "\n",
    "# LR Scheduler\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdbb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_class(import_str):\n",
    "    mod_str, _sep, class_str = import_str.rpartition('.')\n",
    "    __import__(mod_str)\n",
    "    try:\n",
    "        return getattr(sys.modules[mod_str], class_str)\n",
    "    except AttributeError:\n",
    "        raise ImportError('Class %s cannot be found (%s)' % (class_str, traceback.format_exception(*sys.exc_info())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eff3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = import_class(\"model.SkateFormer.SkateFormer_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d57fab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "  \"num_classes\": 60,\n",
    "  \"num_people\": 2,\n",
    "  \"num_points\": 24,\n",
    "  \"kernel_size\": 7,\n",
    "  \"num_heads\": 32,\n",
    "  \"attn_drop\": 0.5,\n",
    "  \"head_drop\": 0.0,\n",
    "  \"rel\": True,\n",
    "  \"drop_path\": 0.2,\n",
    "  \"type_1_size\": [8, 8],\n",
    "  \"type_2_size\": [8, 12],\n",
    "  \"type_3_size\": [8, 8],\n",
    "  \"type_4_size\": [8, 12],\n",
    "  \"mlp_ratio\": 4.0,\n",
    "  \"index_t\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3599e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Tuple, Optional, Set, List, Union\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.layers import drop_path, trunc_normal_, Mlp, DropPath, create_act_layer, get_norm_act_layer, create_conv2d\n",
    "\n",
    "''' Partition and Reverse '''\n",
    "\n",
    "\n",
    "def type_1_partition(input, partition_size):  # partition_size = [N, L]\n",
    "    B, C, T, V = input.shape\n",
    "    partitions = input.view(B, C, T // partition_size[0], partition_size[0], V // partition_size[1], partition_size[1])\n",
    "    partitions = partitions.permute(0, 2, 4, 3, 5, 1).contiguous().view(-1, partition_size[0], partition_size[1], C)\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def type_1_reverse(partitions, original_size, partition_size):  # original_size = [T, V]\n",
    "    T, V = original_size\n",
    "    B = int(partitions.shape[0] / (T * V / partition_size[0] / partition_size[1]))\n",
    "    output = partitions.view(B, T // partition_size[0], V // partition_size[1], partition_size[0], partition_size[1], -1)\n",
    "    output = output.permute(0, 5, 1, 3, 2, 4).contiguous().view(B, -1, T, V)\n",
    "    return output\n",
    "\n",
    "\n",
    "def type_2_partition(input, partition_size):  # partition_size = [N, K]\n",
    "    B, C, T, V = input.shape\n",
    "    partitions = input.view(B, C, T // partition_size[0], partition_size[0], partition_size[1], V // partition_size[1])\n",
    "    partitions = partitions.permute(0, 2, 5, 3, 4, 1).contiguous().view(-1, partition_size[0], partition_size[1], C)\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def type_2_reverse(partitions, original_size, partition_size):  # original_size = [T, V]\n",
    "    T, V = original_size\n",
    "    B = int(partitions.shape[0] / (T * V / partition_size[0] / partition_size[1]))\n",
    "    output = partitions.view(B, T // partition_size[0], V // partition_size[1], partition_size[0], partition_size[1], -1)\n",
    "    output = output.permute(0, 5, 1, 3, 4, 2).contiguous().view(B, -1, T, V)\n",
    "    return output\n",
    "\n",
    "\n",
    "def type_3_partition(input, partition_size):  # partition_size = [M, L]\n",
    "    B, C, T, V = input.shape\n",
    "    partitions = input.view(B, C, partition_size[0], T // partition_size[0], V // partition_size[1], partition_size[1])\n",
    "    partitions = partitions.permute(0, 3, 4, 2, 5, 1).contiguous().view(-1, partition_size[0], partition_size[1], C)\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def type_3_reverse(partitions, original_size, partition_size):  # original_size = [T, V]\n",
    "    T, V = original_size\n",
    "    B = int(partitions.shape[0] / (T * V / partition_size[0] / partition_size[1]))\n",
    "    output = partitions.view(B, T // partition_size[0], V // partition_size[1], partition_size[0], partition_size[1], -1)\n",
    "    output = output.permute(0, 5, 3, 1, 2, 4).contiguous().view(B, -1, T, V)\n",
    "    return output\n",
    "\n",
    "\n",
    "def type_4_partition(input, partition_size):  # partition_size = [M, K]\n",
    "    B, C, T, V = input.shape\n",
    "    partitions = input.view(B, C, partition_size[0], T // partition_size[0], partition_size[1], V // partition_size[1])\n",
    "    partitions = partitions.permute(0, 3, 5, 2, 4, 1).contiguous().view(-1, partition_size[0], partition_size[1], C)\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def type_4_reverse(partitions, original_size, partition_size):  # original_size = [T, V]\n",
    "    T, V = original_size\n",
    "    B = int(partitions.shape[0] / (T * V / partition_size[0] / partition_size[1]))\n",
    "    output = partitions.view(B, T // partition_size[0], V // partition_size[1], partition_size[0], partition_size[1], -1)\n",
    "    output = output.permute(0, 5, 3, 1, 4, 2).contiguous().view(B, -1, T, V)\n",
    "    return output\n",
    "\n",
    "\n",
    "''' 1D relative positional bias: B_{h}^{t} '''\n",
    "\n",
    "\n",
    "def get_relative_position_index_1d(T):\n",
    "    coords = torch.stack(torch.meshgrid([torch.arange(T)]))\n",
    "    coords_flatten = torch.flatten(coords, 1)\n",
    "    relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "    relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "    relative_coords[:, :, 0] += T - 1\n",
    "    return relative_coords.sum(-1)\n",
    "\n",
    "\n",
    "''' MSA '''\n",
    "\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels, rel_type, num_heads=32, partition_size=(1, 1), attn_drop=0., rel=True):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.rel_type = rel_type\n",
    "        self.num_heads = num_heads\n",
    "        self.partition_size = partition_size\n",
    "        self.scale = num_heads ** -0.5\n",
    "        self.attn_area = partition_size[0] * partition_size[1]\n",
    "        self.attn_drop = nn.Dropout(p=attn_drop)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.rel = rel\n",
    "\n",
    "        if self.rel:\n",
    "            if self.rel_type == 'type_1' or self.rel_type == 'type_3':\n",
    "                self.relative_position_bias_table = nn.Parameter(torch.zeros((2 * partition_size[0] - 1), num_heads))\n",
    "                self.register_buffer(\"relative_position_index\", get_relative_position_index_1d(partition_size[0]))\n",
    "                trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "                self.ones = torch.ones(partition_size[1], partition_size[1], num_heads)\n",
    "            elif self.rel_type == 'type_2' or self.rel_type == 'type_4':\n",
    "                self.relative_position_bias_table = nn.Parameter(\n",
    "                    torch.zeros((2 * partition_size[0] - 1), partition_size[1], partition_size[1], num_heads))\n",
    "                self.register_buffer(\"relative_position_index\", get_relative_position_index_1d(partition_size[0]))\n",
    "                trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "\n",
    "    def _get_relative_positional_bias(self):\n",
    "        if self.rel_type == 'type_1' or self.rel_type == 'type_3':\n",
    "            relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "                self.partition_size[0], self.partition_size[0], -1)\n",
    "            relative_position_bias = relative_position_bias.unsqueeze(1).unsqueeze(3).repeat(1, self.partition_size[1], 1, self.partition_size[1], 1, 1).view(self.attn_area, self.attn_area, -1)\n",
    "            relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()\n",
    "            return relative_position_bias.unsqueeze(0)\n",
    "        elif self.rel_type == 'type_2' or self.rel_type == 'type_4':\n",
    "            relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(self.partition_size[0], self.partition_size[0], self.partition_size[1], self.partition_size[1], -1)\n",
    "            relative_position_bias = relative_position_bias.permute(0, 2, 1, 3, 4).contiguous().view(self.attn_area, self.attn_area, -1)\n",
    "            relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()\n",
    "            return relative_position_bias.unsqueeze(0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        B_, N, C = input.shape\n",
    "        qkv = input.reshape(B_, N, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)\n",
    "        q = q * self.scale\n",
    "        attn = q @ k.transpose(-2, -1)\n",
    "        if self.rel:\n",
    "            attn = attn + self._get_relative_positional_bias()\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "        output = (attn @ v).transpose(1, 2).reshape(B_, N, -1)\n",
    "        return output\n",
    "\n",
    "\n",
    "''' SkateFormer Block '''\n",
    "\n",
    "\n",
    "class SkateFormerBlock(nn.Module):\n",
    "    def __init__(self, in_channels, num_points=50, kernel_size=7, num_heads=32,\n",
    "                 type_1_size=(1, 1), type_2_size=(1, 1), type_3_size=(1, 1), type_4_size=(1, 1),\n",
    "                 attn_drop=0., drop=0., rel=True, drop_path=0., mlp_ratio=4.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super(SkateFormerBlock, self).__init__()\n",
    "        self.type_1_size = type_1_size\n",
    "        self.type_2_size = type_2_size\n",
    "        self.type_3_size = type_3_size\n",
    "        self.type_4_size = type_4_size\n",
    "        self.partition_function = [type_1_partition, type_2_partition, type_3_partition, type_4_partition]\n",
    "        self.reverse_function = [type_1_reverse, type_2_reverse, type_3_reverse, type_4_reverse]\n",
    "        self.partition_size = [type_1_size, type_2_size, type_3_size, type_4_size]\n",
    "        self.rel_type = ['type_1', 'type_2', 'type_3', 'type_4']\n",
    "\n",
    "        self.norm_1 = norm_layer(in_channels)\n",
    "        self.mapping = nn.Linear(in_features=in_channels, out_features=2 * in_channels, bias=True)\n",
    "        self.gconv = nn.Parameter(torch.zeros(num_heads // (2 * 2), num_points, num_points))\n",
    "        trunc_normal_(self.gconv, std=.02)\n",
    "        self.tcbam = CBAM(in_channels // (2 * 2), r=16)\n",
    "        self.tconv = nn.Conv2d(in_channels // (2 * 2), in_channels // (2 * 2), kernel_size=(kernel_size, 1),\n",
    "                               padding=((kernel_size - 1) // 2, 0), groups=num_heads // (2 * 2))\n",
    "\n",
    "        # Attention layers\n",
    "        attention = []\n",
    "        for i in range(len(self.partition_function)):\n",
    "            attention.append(\n",
    "                MultiHeadSelfAttention(in_channels=in_channels // (len(self.partition_function) * 2),\n",
    "                                       rel_type=self.rel_type[i],\n",
    "                                       num_heads=num_heads // (len(self.partition_function) * 2),\n",
    "                                       partition_size=self.partition_size[i], attn_drop=attn_drop, rel=rel))\n",
    "        self.attention = nn.ModuleList(attention)\n",
    "        self.proj = nn.Linear(in_features=in_channels, out_features=in_channels, bias=True)\n",
    "        self.proj_drop = nn.Dropout(p=drop)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm_2 = norm_layer(in_channels)\n",
    "        self.mlp = Mlp(in_features=in_channels, hidden_features=int(mlp_ratio * in_channels),\n",
    "                       act_layer=act_layer, drop=drop)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, input):\n",
    "        B, C, T, V = input.shape\n",
    "\n",
    "        # Partition\n",
    "        input = input.permute(0, 2, 3, 1).contiguous()\n",
    "        skip = input\n",
    "\n",
    "        f = self.mapping(self.norm_1(input)).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        f_conv, f_attn = torch.split(f, [C // 2, 3 * C // 2], dim=1)\n",
    "        y = []\n",
    "\n",
    "        # G-Conv\n",
    "        split_f_conv = torch.chunk(f_conv, 2, dim=1)\n",
    "        y_gconv = []\n",
    "        split_f_gconv = torch.chunk(split_f_conv[0], self.gconv.shape[0], dim=1)\n",
    "        for i in range(self.gconv.shape[0]):\n",
    "            z = torch.einsum('n c t u, v u -> n c t v', split_f_gconv[i], self.gconv[i])\n",
    "            y_gconv.append(z)\n",
    "        y.append(torch.cat(y_gconv, dim=1))  # N C T V\n",
    "\n",
    "        # T-Conv\n",
    "        output = self.tcbam(split_f_conv[1])\n",
    "        y.append(self.tconv(output))\n",
    "\n",
    "        # Skate-MSA\n",
    "        split_f_attn = torch.chunk(f_attn, len(self.partition_function), dim=1)\n",
    "\n",
    "        for i in range(len(self.partition_function)):\n",
    "            C = split_f_attn[i].shape[1]\n",
    "            input_partitioned = self.partition_function[i](split_f_attn[i], self.partition_size[i])\n",
    "            input_partitioned = input_partitioned.view(-1, self.partition_size[i][0] * self.partition_size[i][1], C)\n",
    "            y.append(self.reverse_function[i](self.attention[i](input_partitioned), (T, V), self.partition_size[i]))\n",
    "\n",
    "        output = self.proj(torch.cat(y, dim=1).permute(0, 2, 3, 1).contiguous())\n",
    "        output = self.proj_drop(output)\n",
    "        output = skip + self.drop_path(output)\n",
    "       \n",
    "\n",
    "        # Feed Forward\n",
    "        output = output + self.drop_path(self.mlp(self.norm_2(output)))\n",
    "        output = output.permute(0, 3, 1, 2).contiguous()\n",
    "        return output\n",
    "\n",
    "\n",
    "''' Downsampling '''\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SAM(nn.Module):\n",
    "    def __init__(self, bias=False):\n",
    "        super(SAM, self).__init__()\n",
    "        self.bias = bias\n",
    "        self.conv = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, stride=1, padding=3, dilation=1, bias=self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        max = torch.max(x,1)[0].unsqueeze(1)\n",
    "        avg = torch.mean(x,1).unsqueeze(1)\n",
    "        concat = torch.cat((max,avg), dim=1)\n",
    "        output = self.conv(concat)\n",
    "        output = torch.sigmoid(output) * x \n",
    "        return output \n",
    "\n",
    "class CAM(nn.Module):\n",
    "    def __init__(self, channels, r):\n",
    "        super(CAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.r = r\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=self.channels, out_features=self.channels//self.r, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=self.channels//self.r, out_features=self.channels, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        max = F.adaptive_max_pool2d(x, output_size=1)\n",
    "        avg = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        b, c, _, _ = x.size()\n",
    "        linear_max = self.linear(max.view(b,c)).view(b, c, 1, 1)\n",
    "        linear_avg = self.linear(avg.view(b,c)).view(b, c, 1, 1)\n",
    "        output = linear_max + linear_avg\n",
    "        output = torch.sigmoid(output) * x\n",
    "        return output\n",
    "    \n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, r):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.r = r\n",
    "        self.sam = SAM(bias=False)\n",
    "        self.cam = CAM(channels=self.channels, r=self.r)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cam(x)\n",
    "        output = self.sam(output)\n",
    "        return output + x\n",
    "    \n",
    "\n",
    "class PatchMergingTconv(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, kernel_size=7, stride=2, dilation=1):\n",
    "        super().__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "        pad = (kernel_size + (kernel_size - 1) * (dilation - 1) - 1) // 2\n",
    "        self.reduction_cbam = CBAM(channels=dim_in, r=16)\n",
    "        self.reduction = nn.Conv2d(dim_in, dim_out, kernel_size=(kernel_size, 1), padding=(pad, 0), stride=(stride, 1),\n",
    "                                   dilation=(dilation, 1))\n",
    "        self.bn = nn.BatchNorm2d(dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.reduction(self.reduction_cbam(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "''' SkateFormer Block with Downsampling '''\n",
    "\n",
    "\n",
    "class SkateFormerBlockDS(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels, out_channels, num_points=50, kernel_size=7, downscale=False, num_heads=32,\n",
    "            type_1_size=(1, 1), type_2_size=(1, 1), type_3_size=(1, 1), type_4_size=(1, 1),\n",
    "            attn_drop=0., drop=0., rel=True, drop_path=0., mlp_ratio=4.,\n",
    "            act_layer=nn.GELU, norm_layer_transformer=nn.LayerNorm):\n",
    "        super(SkateFormerBlockDS, self).__init__()\n",
    "\n",
    "        if downscale:\n",
    "            self.downsample = PatchMergingTconv(in_channels, out_channels, kernel_size=kernel_size)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.transformer = SkateFormerBlock(\n",
    "            in_channels=out_channels,\n",
    "            num_points=num_points,\n",
    "            kernel_size=kernel_size,\n",
    "            num_heads=num_heads,\n",
    "            type_1_size=type_1_size,\n",
    "            type_2_size=type_2_size,\n",
    "            type_3_size=type_3_size,\n",
    "            type_4_size=type_4_size,\n",
    "            attn_drop=attn_drop,\n",
    "            drop=drop,\n",
    "            rel=rel,\n",
    "            drop_path=drop_path,\n",
    "            mlp_ratio=mlp_ratio,\n",
    "            act_layer=act_layer,\n",
    "            norm_layer=norm_layer_transformer,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.downsample is not None:\n",
    "            output = self.transformer(self.downsample(input))\n",
    "        else:\n",
    "            output = self.transformer(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "''' SkateFormer Stage '''\n",
    "\n",
    "\n",
    "class SkateFormerStage(nn.Module):\n",
    "    def __init__(\n",
    "            self, depth, in_channels, out_channels, first_depth=False,\n",
    "            num_points=50, kernel_size=7, num_heads=32,\n",
    "            type_1_size=(1, 1), type_2_size=(1, 1), type_3_size=(1, 1), type_4_size=(1, 1),\n",
    "            attn_drop=0., drop=0., rel=True, drop_path=0., mlp_ratio=4.,\n",
    "            act_layer=nn.GELU, norm_layer_transformer=nn.LayerNorm):\n",
    "        super(SkateFormerStage, self).__init__()\n",
    "        blocks = []\n",
    "        for index in range(depth):\n",
    "            blocks.append(\n",
    "                SkateFormerBlockDS(\n",
    "                    in_channels=in_channels if index == 0 else out_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    num_points=num_points,\n",
    "                    kernel_size=kernel_size,\n",
    "                    downscale=((index == 0) & ~first_depth),\n",
    "                    num_heads=num_heads,\n",
    "                    type_1_size=type_1_size,\n",
    "                    type_2_size=type_2_size,\n",
    "                    type_3_size=type_3_size,\n",
    "                    type_4_size=type_4_size,\n",
    "                    attn_drop=attn_drop,\n",
    "                    drop=drop,\n",
    "                    rel=rel,\n",
    "                    drop_path=drop_path if isinstance(drop_path, float) else drop_path[index],\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    act_layer=act_layer,\n",
    "                    norm_layer_transformer=norm_layer_transformer))\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        for block in self.blocks:\n",
    "            output = block(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "''' SkateFormer '''\n",
    "\n",
    "\n",
    "class SkateFormer(nn.Module):\n",
    "    def __init__(self, in_channels=3, depths=(2, 2, 2, 2), channels=(96, 192, 192, 192), num_classes=60,\n",
    "                 embed_dim=64, num_people=2, num_frames=64, num_points=50, kernel_size=7, num_heads=32,\n",
    "                 type_1_size=(1, 1), type_2_size=(1, 1), type_3_size=(1, 1), type_4_size=(1, 1),\n",
    "                 attn_drop=0., head_drop=0., drop=0., rel=True, drop_path=0., mlp_ratio=4.,\n",
    "                 act_layer=nn.GELU, norm_layer_transformer=nn.LayerNorm, index_t=False, global_pool='avg'):\n",
    "\n",
    "        super(SkateFormer, self).__init__()\n",
    "\n",
    "        assert len(depths) == len(channels), \"For each stage a channel dimension must be given.\"\n",
    "        assert global_pool in [\"avg\", \"max\"], f\"Only avg and max is supported but {global_pool} is given\"\n",
    "        self.num_classes: int = num_classes\n",
    "        self.head_drop = head_drop\n",
    "        self.index_t = index_t\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        if self.head_drop != 0:\n",
    "            self.dropout = nn.Dropout(p=self.head_drop)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "        stem = []\n",
    "        stem.append(CBAM(channels=in_channels, r=16))\n",
    "        stem.append(nn.Conv2d(in_channels=in_channels, out_channels=2 * in_channels, kernel_size=(1, 1), stride=(1, 1),\n",
    "                              padding=(0, 0)))\n",
    "        stem.append(act_layer())\n",
    "        stem.append(CBAM(channels=2 * in_channels, r=16))\n",
    "        stem.append(\n",
    "            nn.Conv2d(in_channels=2 * in_channels, out_channels=3 * in_channels, kernel_size=(1, 1), stride=(1, 1),\n",
    "                      padding=(0, 0)))\n",
    "        stem.append(act_layer())\n",
    "        stem.append(CBAM(channels=3 * in_channels, r=16))\n",
    "        stem.append(nn.Conv2d(in_channels=3 * in_channels, out_channels=embed_dim, kernel_size=(1, 1), stride=(1, 1),\n",
    "                              padding=(0, 0)))\n",
    "        self.stem = nn.ModuleList(stem)\n",
    "\n",
    "        if self.index_t:\n",
    "            self.joint_person_embedding = nn.Parameter(torch.zeros(embed_dim, num_points * num_people))\n",
    "            trunc_normal_(self.joint_person_embedding, std=.02)\n",
    "        else:\n",
    "            self.joint_person_temporal_embedding = nn.Parameter(\n",
    "                torch.zeros(1, embed_dim, num_frames, num_points * num_people))\n",
    "            trunc_normal_(self.joint_person_temporal_embedding, std=.02)\n",
    "\n",
    "        # Init blocks\n",
    "        drop_path = torch.linspace(0.0, drop_path, sum(depths)).tolist()\n",
    "        stages = []\n",
    "        for index, (depth, channel) in enumerate(zip(depths, channels)):\n",
    "            stages.append(\n",
    "                SkateFormerStage(\n",
    "                    depth=depth,\n",
    "                    in_channels=embed_dim if index == 0 else channels[index - 1],\n",
    "                    out_channels=channel,\n",
    "                    first_depth=index == 0,\n",
    "                    num_points=num_points * num_people,\n",
    "                    kernel_size=kernel_size,\n",
    "                    num_heads=num_heads,\n",
    "                    type_1_size=type_1_size,\n",
    "                    type_2_size=type_2_size,\n",
    "                    type_3_size=type_3_size,\n",
    "                    type_4_size=type_4_size,\n",
    "                    attn_drop=attn_drop,\n",
    "                    drop=drop,\n",
    "                    rel=rel,\n",
    "                    drop_path=drop_path[sum(depths[:index]):sum(depths[:index + 1])],\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    act_layer=act_layer,\n",
    "                    norm_layer_transformer=norm_layer_transformer\n",
    "                )\n",
    "            )\n",
    "        self.stages = nn.ModuleList(stages)\n",
    "        self.global_pool: str = global_pool\n",
    "        self.head = nn.Linear(channels[-1], num_classes)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        nwd = set()\n",
    "        for n, _ in self.named_parameters():\n",
    "            if \"relative_position_bias_table\" in n:\n",
    "                nwd.add(n)\n",
    "        return nwd\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=None):\n",
    "        self.num_classes: int = num_classes\n",
    "        if global_pool is not None:\n",
    "            self.global_pool = global_pool\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, input):\n",
    "        output = input\n",
    "        for stage in self.stages:\n",
    "            output = stage(output)\n",
    "        return output\n",
    "\n",
    "    def forward_head(self, input, pre_logits=False):\n",
    "        if self.global_pool == \"avg\":\n",
    "            input = input.mean(dim=(2, 3))\n",
    "        elif self.global_pool == \"max\":\n",
    "            input = torch.amax(input, dim=(2, 3))\n",
    "        if self.dropout is not None:\n",
    "            input = self.dropout(input)\n",
    "        return input if pre_logits else self.head(input)\n",
    "\n",
    "    def forward(self, input, index_t):\n",
    "        B, C, T, V, M = input.shape\n",
    "\n",
    "        output = input.permute(0, 1, 2, 4, 3).contiguous().view(B, C, T, -1)  # [B, C, T, M * V]\n",
    "        for layer in self.stem:\n",
    "            output = layer(output)\n",
    "        if self.index_t:\n",
    "            te = torch.zeros(B, T, self.embed_dim).to(output.device)  # B, T, C\n",
    "            div_term = torch.exp(\n",
    "                (torch.arange(0, self.embed_dim, 2, dtype=torch.float) * -(math.log(10000.0) / self.embed_dim))).to(\n",
    "                output.device)\n",
    "            te[:, :, 0::2] = torch.sin(index_t.unsqueeze(-1).float() * div_term)\n",
    "            te[:, :, 1::2] = torch.cos(index_t.unsqueeze(-1).float() * div_term)\n",
    "            output = output + torch.einsum('b t c, c v -> b c t v', te, self.joint_person_embedding)\n",
    "        else:\n",
    "            output = output + self.joint_person_temporal_embedding\n",
    "        output = self.forward_features(output)\n",
    "        output = self.forward_head(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def SkateFormer_(**kwargs):\n",
    "    return SkateFormer(\n",
    "        depths=(2, 2, 2, 2),\n",
    "        channels=(96, 192, 192, 192),\n",
    "        embed_dim=96,\n",
    "        **kwargs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08f01da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phuongnam/.miniconda3/envs/skateformer/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "/home/phuongnam/.miniconda3/envs/skateformer/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484809662/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 60])\n"
     ]
    }
   ],
   "source": [
    "model = SkateFormer_(**model_args)\n",
    "x = torch.randn(2, 3, 64, 24, 2)\n",
    "index = torch.randn(2, 64)\n",
    "y = model(x,index)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d83306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skateformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
