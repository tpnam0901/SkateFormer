[ Tue Dec  2 14:47:30 2025 ] using warm up, epoch: 25
[ Tue Dec  2 14:59:18 2025 ] Parameters:
{'work_dir': './work_dir7/ntu/cs/SkateFormer_j/', 'model_saved_name': './work_dir7/ntu/cs/SkateFormer_j/runs', 'config': './config/train/ntu_cs/SkateFormer_j.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 0, 'train_feeder_args': {'data_path': './data/ntu/random_split_predefined7/NTU60_CS.npz', 'split': 'train', 'debug': False, 'window_size': 64, 'p_interval': [0.5, 1], 'aug_method': 'a123489', 'intra_p': 0.5, 'inter_p': 0.2, 'thres': 64, 'uniform': True, 'partition': True}, 'test_feeder_args': {'data_path': './data/ntu/random_split_predefined7/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'thres': 64, 'uniform': True, 'partition': True, 'debug': False}, 'model': 'model.SkateFormer.SkateFormer_', 'model_args': {'num_classes': 60, 'num_people': 2, 'num_points': 24, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 8], 'type_2_size': [8, 12], 'type_3_size': [8, 8], 'type_4_size': [8, 12], 'mlp_ratio': 4.0, 'index_t': True}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 32, 'test_batch_size': 32, 'start_epoch': 0, 'num_epoch': 500, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Tue Dec  2 14:59:18 2025 ] # Parameters: 3616083
[ Tue Dec  2 14:59:18 2025 ] Training epoch: 1
[ Tue Dec  2 15:14:15 2025 ] 	Mean training loss: 4.0021.  Mean training acc: 3.80%.
[ Tue Dec  2 15:14:15 2025 ] 	Learning Rate: 0.0000
[ Tue Dec  2 15:14:15 2025 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Dec  2 15:14:15 2025 ] Training epoch: 2
[ Tue Dec  2 15:18:04 2025 ] 	Mean training loss: 3.6913.  Mean training acc: 8.11%.
[ Tue Dec  2 15:18:04 2025 ] 	Learning Rate: 0.0001
[ Tue Dec  2 15:18:04 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:18:04 2025 ] Training epoch: 3
[ Tue Dec  2 15:21:53 2025 ] 	Mean training loss: 3.3858.  Mean training acc: 14.52%.
[ Tue Dec  2 15:21:53 2025 ] 	Learning Rate: 0.0001
[ Tue Dec  2 15:21:53 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:21:53 2025 ] Training epoch: 4
[ Tue Dec  2 15:25:41 2025 ] 	Mean training loss: 3.0622.  Mean training acc: 22.41%.
[ Tue Dec  2 15:25:41 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:25:41 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:25:41 2025 ] Training epoch: 5
[ Tue Dec  2 15:29:30 2025 ] 	Mean training loss: 2.8149.  Mean training acc: 30.11%.
[ Tue Dec  2 15:29:30 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:29:30 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:29:30 2025 ] Training epoch: 6
[ Tue Dec  2 15:33:18 2025 ] 	Mean training loss: 2.6616.  Mean training acc: 34.72%.
[ Tue Dec  2 15:33:18 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:33:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:33:18 2025 ] Training epoch: 7
[ Tue Dec  2 15:37:07 2025 ] 	Mean training loss: 2.5573.  Mean training acc: 38.20%.
[ Tue Dec  2 15:37:07 2025 ] 	Learning Rate: 0.0003
[ Tue Dec  2 15:37:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:37:07 2025 ] Training epoch: 8
[ Tue Dec  2 15:40:56 2025 ] 	Mean training loss: 2.4625.  Mean training acc: 40.82%.
[ Tue Dec  2 15:40:56 2025 ] 	Learning Rate: 0.0003
[ Tue Dec  2 15:40:56 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:40:56 2025 ] Training epoch: 9
[ Tue Dec  2 15:44:44 2025 ] 	Mean training loss: 2.4028.  Mean training acc: 42.85%.
[ Tue Dec  2 15:44:44 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:44:44 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:44:44 2025 ] Training epoch: 10
[ Tue Dec  2 15:48:33 2025 ] 	Mean training loss: 2.3351.  Mean training acc: 44.98%.
[ Tue Dec  2 15:48:33 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:48:33 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:48:33 2025 ] Training epoch: 11
[ Tue Dec  2 15:52:21 2025 ] 	Mean training loss: 2.2961.  Mean training acc: 46.52%.
[ Tue Dec  2 15:52:21 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:52:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:52:22 2025 ] Training epoch: 12
[ Tue Dec  2 15:56:10 2025 ] 	Mean training loss: 2.2371.  Mean training acc: 48.35%.
[ Tue Dec  2 15:56:10 2025 ] 	Learning Rate: 0.0005
[ Tue Dec  2 15:56:10 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 15:56:10 2025 ] Training epoch: 13
[ Tue Dec  2 15:59:59 2025 ] 	Mean training loss: 2.1970.  Mean training acc: 50.08%.
[ Tue Dec  2 15:59:59 2025 ] 	Learning Rate: 0.0005
[ Tue Dec  2 15:59:59 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 15:59:59 2025 ] Training epoch: 14
[ Tue Dec  2 16:03:47 2025 ] 	Mean training loss: 2.1526.  Mean training acc: 51.31%.
[ Tue Dec  2 16:03:47 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 16:03:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:03:47 2025 ] Training epoch: 15
[ Tue Dec  2 16:07:36 2025 ] 	Mean training loss: 2.1110.  Mean training acc: 52.97%.
[ Tue Dec  2 16:07:36 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 16:07:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:07:36 2025 ] Training epoch: 16
[ Tue Dec  2 16:11:24 2025 ] 	Mean training loss: 2.0635.  Mean training acc: 54.53%.
[ Tue Dec  2 16:11:24 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 16:11:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:11:24 2025 ] Training epoch: 17
[ Tue Dec  2 16:15:13 2025 ] 	Mean training loss: 2.0383.  Mean training acc: 55.37%.
[ Tue Dec  2 16:15:13 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 16:15:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:15:13 2025 ] Training epoch: 18
[ Tue Dec  2 16:19:02 2025 ] 	Mean training loss: 2.0136.  Mean training acc: 56.66%.
[ Tue Dec  2 16:19:02 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 16:19:02 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:19:02 2025 ] Training epoch: 19
[ Tue Dec  2 16:22:50 2025 ] 	Mean training loss: 1.9726.  Mean training acc: 57.57%.
[ Tue Dec  2 16:22:50 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 16:22:50 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:22:50 2025 ] Training epoch: 20
[ Tue Dec  2 16:26:39 2025 ] 	Mean training loss: 1.9632.  Mean training acc: 57.99%.
[ Tue Dec  2 16:26:39 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 16:26:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:26:39 2025 ] Training epoch: 21
[ Tue Dec  2 16:30:28 2025 ] 	Mean training loss: 1.9404.  Mean training acc: 58.27%.
[ Tue Dec  2 16:30:28 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 16:30:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:30:28 2025 ] Training epoch: 22
[ Tue Dec  2 16:34:16 2025 ] 	Mean training loss: 1.9239.  Mean training acc: 59.54%.
[ Tue Dec  2 16:34:16 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 16:34:16 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:34:16 2025 ] Training epoch: 23
[ Tue Dec  2 16:38:05 2025 ] 	Mean training loss: 1.9029.  Mean training acc: 60.28%.
[ Tue Dec  2 16:38:05 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 16:38:05 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:38:05 2025 ] Training epoch: 24
[ Tue Dec  2 16:41:53 2025 ] 	Mean training loss: 1.8893.  Mean training acc: 60.59%.
[ Tue Dec  2 16:41:53 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:41:53 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:41:53 2025 ] Training epoch: 25
[ Tue Dec  2 16:45:42 2025 ] 	Mean training loss: 1.8784.  Mean training acc: 60.87%.
[ Tue Dec  2 16:45:42 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:45:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:45:42 2025 ] Training epoch: 26
[ Tue Dec  2 16:49:31 2025 ] 	Mean training loss: 1.8512.  Mean training acc: 61.68%.
[ Tue Dec  2 16:49:31 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:49:31 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:49:31 2025 ] Training epoch: 27
[ Tue Dec  2 16:53:20 2025 ] 	Mean training loss: 1.8338.  Mean training acc: 62.18%.
[ Tue Dec  2 16:53:20 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:53:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:53:20 2025 ] Training epoch: 28
[ Tue Dec  2 16:57:08 2025 ] 	Mean training loss: 1.8043.  Mean training acc: 63.54%.
[ Tue Dec  2 16:57:08 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:57:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:57:08 2025 ] Training epoch: 29
[ Tue Dec  2 17:00:57 2025 ] 	Mean training loss: 1.7943.  Mean training acc: 63.40%.
[ Tue Dec  2 17:00:57 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:00:57 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:00:57 2025 ] Training epoch: 30
[ Tue Dec  2 17:04:46 2025 ] 	Mean training loss: 1.7560.  Mean training acc: 65.16%.
[ Tue Dec  2 17:04:46 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:04:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:04:46 2025 ] Training epoch: 31
[ Tue Dec  2 17:08:34 2025 ] 	Mean training loss: 1.7412.  Mean training acc: 65.50%.
[ Tue Dec  2 17:08:34 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:08:34 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:08:34 2025 ] Training epoch: 32
[ Tue Dec  2 17:12:23 2025 ] 	Mean training loss: 1.7220.  Mean training acc: 66.25%.
[ Tue Dec  2 17:12:23 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:12:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:12:23 2025 ] Training epoch: 33
[ Tue Dec  2 17:16:11 2025 ] 	Mean training loss: 1.7092.  Mean training acc: 66.42%.
[ Tue Dec  2 17:16:11 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:16:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:16:11 2025 ] Training epoch: 34
[ Tue Dec  2 17:20:00 2025 ] 	Mean training loss: 1.6789.  Mean training acc: 67.67%.
[ Tue Dec  2 17:20:00 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:20:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:20:00 2025 ] Training epoch: 35
[ Tue Dec  2 17:23:49 2025 ] 	Mean training loss: 1.6709.  Mean training acc: 67.97%.
[ Tue Dec  2 17:23:49 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:23:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:23:49 2025 ] Training epoch: 36
[ Tue Dec  2 17:27:37 2025 ] 	Mean training loss: 1.6397.  Mean training acc: 68.83%.
[ Tue Dec  2 17:27:37 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:27:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:27:37 2025 ] Training epoch: 37
[ Tue Dec  2 17:31:26 2025 ] 	Mean training loss: 1.6223.  Mean training acc: 69.51%.
[ Tue Dec  2 17:31:26 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:31:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:31:26 2025 ] Training epoch: 38
[ Tue Dec  2 17:35:14 2025 ] 	Mean training loss: 1.6106.  Mean training acc: 69.81%.
[ Tue Dec  2 17:35:14 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:35:14 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:35:14 2025 ] Training epoch: 39
[ Tue Dec  2 17:39:03 2025 ] 	Mean training loss: 1.6159.  Mean training acc: 69.57%.
[ Tue Dec  2 17:39:03 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:39:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:39:03 2025 ] Training epoch: 40
[ Tue Dec  2 17:42:52 2025 ] 	Mean training loss: 1.5937.  Mean training acc: 70.56%.
[ Tue Dec  2 17:42:52 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:42:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:42:52 2025 ] Training epoch: 41
[ Tue Dec  2 17:46:40 2025 ] 	Mean training loss: 1.5899.  Mean training acc: 71.02%.
[ Tue Dec  2 17:46:40 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:46:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:46:40 2025 ] Training epoch: 42
[ Tue Dec  2 17:50:29 2025 ] 	Mean training loss: 1.5597.  Mean training acc: 71.33%.
[ Tue Dec  2 17:50:29 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:50:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:50:29 2025 ] Training epoch: 43
[ Tue Dec  2 17:54:18 2025 ] 	Mean training loss: 1.5655.  Mean training acc: 71.33%.
[ Tue Dec  2 17:54:18 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:54:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:54:18 2025 ] Training epoch: 44
[ Tue Dec  2 17:58:06 2025 ] 	Mean training loss: 1.5550.  Mean training acc: 71.97%.
[ Tue Dec  2 17:58:06 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:58:06 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:58:06 2025 ] Training epoch: 45
[ Tue Dec  2 18:01:55 2025 ] 	Mean training loss: 1.5362.  Mean training acc: 72.34%.
[ Tue Dec  2 18:01:55 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:01:55 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:01:55 2025 ] Training epoch: 46
[ Tue Dec  2 18:05:44 2025 ] 	Mean training loss: 1.5292.  Mean training acc: 72.76%.
[ Tue Dec  2 18:05:44 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:05:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:05:44 2025 ] Training epoch: 47
[ Tue Dec  2 18:09:32 2025 ] 	Mean training loss: 1.5223.  Mean training acc: 72.96%.
[ Tue Dec  2 18:09:32 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:09:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:09:32 2025 ] Training epoch: 48
[ Tue Dec  2 18:13:21 2025 ] 	Mean training loss: 1.5273.  Mean training acc: 72.85%.
[ Tue Dec  2 18:13:21 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:13:21 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:13:21 2025 ] Training epoch: 49
[ Tue Dec  2 18:17:09 2025 ] 	Mean training loss: 1.5065.  Mean training acc: 73.83%.
[ Tue Dec  2 18:17:09 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:17:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:17:09 2025 ] Training epoch: 50
[ Tue Dec  2 18:20:58 2025 ] 	Mean training loss: 1.5127.  Mean training acc: 73.49%.
[ Tue Dec  2 18:20:58 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:20:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:20:58 2025 ] Training epoch: 51
[ Tue Dec  2 18:24:47 2025 ] 	Mean training loss: 1.5010.  Mean training acc: 73.54%.
[ Tue Dec  2 18:24:47 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:24:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:24:47 2025 ] Training epoch: 52
[ Tue Dec  2 18:28:35 2025 ] 	Mean training loss: 1.4809.  Mean training acc: 74.53%.
[ Tue Dec  2 18:28:35 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:28:35 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:28:35 2025 ] Training epoch: 53
[ Tue Dec  2 18:32:24 2025 ] 	Mean training loss: 1.4843.  Mean training acc: 74.63%.
[ Tue Dec  2 18:32:24 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:32:24 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:32:24 2025 ] Training epoch: 54
[ Tue Dec  2 18:36:12 2025 ] 	Mean training loss: 1.4782.  Mean training acc: 74.52%.
[ Tue Dec  2 18:36:12 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:36:12 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:36:12 2025 ] Training epoch: 55
[ Tue Dec  2 18:40:01 2025 ] 	Mean training loss: 1.4728.  Mean training acc: 75.13%.
[ Tue Dec  2 18:40:01 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:40:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:40:01 2025 ] Training epoch: 56
[ Tue Dec  2 18:43:49 2025 ] 	Mean training loss: 1.4550.  Mean training acc: 75.55%.
[ Tue Dec  2 18:43:49 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:43:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:43:49 2025 ] Training epoch: 57
[ Tue Dec  2 18:47:38 2025 ] 	Mean training loss: 1.4457.  Mean training acc: 75.85%.
[ Tue Dec  2 18:47:38 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:47:38 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:47:38 2025 ] Training epoch: 58
[ Tue Dec  2 18:51:26 2025 ] 	Mean training loss: 1.4640.  Mean training acc: 75.14%.
[ Tue Dec  2 18:51:26 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:51:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:51:26 2025 ] Training epoch: 59
[ Tue Dec  2 18:55:15 2025 ] 	Mean training loss: 1.4561.  Mean training acc: 75.08%.
[ Tue Dec  2 18:55:15 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:55:15 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:55:15 2025 ] Training epoch: 60
[ Tue Dec  2 18:59:04 2025 ] 	Mean training loss: 1.4440.  Mean training acc: 75.86%.
[ Tue Dec  2 18:59:04 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:59:04 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:59:04 2025 ] Training epoch: 61
[ Tue Dec  2 19:02:52 2025 ] 	Mean training loss: 1.4349.  Mean training acc: 76.13%.
[ Tue Dec  2 19:02:52 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:02:52 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:02:52 2025 ] Training epoch: 62
[ Tue Dec  2 19:06:41 2025 ] 	Mean training loss: 1.4313.  Mean training acc: 76.33%.
[ Tue Dec  2 19:06:41 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:06:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:06:41 2025 ] Training epoch: 63
[ Tue Dec  2 19:10:30 2025 ] 	Mean training loss: 1.4273.  Mean training acc: 76.64%.
[ Tue Dec  2 19:10:30 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:10:30 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:10:30 2025 ] Training epoch: 64
[ Tue Dec  2 19:14:18 2025 ] 	Mean training loss: 1.4134.  Mean training acc: 76.68%.
[ Tue Dec  2 19:14:18 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:14:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:14:18 2025 ] Training epoch: 65
[ Tue Dec  2 19:18:07 2025 ] 	Mean training loss: 1.4192.  Mean training acc: 76.51%.
[ Tue Dec  2 19:18:07 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:18:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:18:07 2025 ] Training epoch: 66
[ Tue Dec  2 19:21:56 2025 ] 	Mean training loss: 1.4155.  Mean training acc: 76.66%.
[ Tue Dec  2 19:21:56 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:21:56 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:21:56 2025 ] Training epoch: 67
[ Tue Dec  2 19:25:44 2025 ] 	Mean training loss: 1.4136.  Mean training acc: 76.83%.
[ Tue Dec  2 19:25:44 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:25:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:25:44 2025 ] Training epoch: 68
[ Tue Dec  2 19:29:32 2025 ] 	Mean training loss: 1.3943.  Mean training acc: 77.64%.
[ Tue Dec  2 19:29:32 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:29:32 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:29:32 2025 ] Training epoch: 69
[ Tue Dec  2 19:33:21 2025 ] 	Mean training loss: 1.4133.  Mean training acc: 76.82%.
[ Tue Dec  2 19:33:21 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:33:21 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:33:21 2025 ] Training epoch: 70
[ Tue Dec  2 19:37:09 2025 ] 	Mean training loss: 1.4117.  Mean training acc: 76.85%.
[ Tue Dec  2 19:37:09 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:37:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:37:09 2025 ] Training epoch: 71
[ Tue Dec  2 19:40:58 2025 ] 	Mean training loss: 1.4035.  Mean training acc: 77.60%.
[ Tue Dec  2 19:40:58 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:40:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:40:58 2025 ] Training epoch: 72
[ Tue Dec  2 19:44:47 2025 ] 	Mean training loss: 1.3953.  Mean training acc: 77.17%.
[ Tue Dec  2 19:44:47 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 19:44:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:44:47 2025 ] Training epoch: 73
[ Tue Dec  2 19:48:35 2025 ] 	Mean training loss: 1.3939.  Mean training acc: 77.80%.
[ Tue Dec  2 19:48:35 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:48:35 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:48:35 2025 ] Training epoch: 74
[ Tue Dec  2 19:52:24 2025 ] 	Mean training loss: 1.3869.  Mean training acc: 77.80%.
[ Tue Dec  2 19:52:24 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:52:24 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:52:24 2025 ] Training epoch: 75
[ Tue Dec  2 19:56:12 2025 ] 	Mean training loss: 1.3820.  Mean training acc: 77.81%.
[ Tue Dec  2 19:56:12 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:56:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:56:12 2025 ] Training epoch: 76
[ Tue Dec  2 20:00:01 2025 ] 	Mean training loss: 1.3808.  Mean training acc: 78.12%.
[ Tue Dec  2 20:00:01 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:00:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:00:01 2025 ] Training epoch: 77
[ Tue Dec  2 20:03:50 2025 ] 	Mean training loss: 1.3811.  Mean training acc: 78.09%.
[ Tue Dec  2 20:03:50 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:03:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:03:50 2025 ] Training epoch: 78
[ Tue Dec  2 20:07:38 2025 ] 	Mean training loss: 1.3738.  Mean training acc: 78.34%.
[ Tue Dec  2 20:07:38 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:07:38 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:07:38 2025 ] Training epoch: 79
[ Tue Dec  2 20:11:27 2025 ] 	Mean training loss: 1.3637.  Mean training acc: 78.36%.
[ Tue Dec  2 20:11:27 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:11:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:11:27 2025 ] Training epoch: 80
[ Tue Dec  2 20:15:16 2025 ] 	Mean training loss: 1.3626.  Mean training acc: 79.10%.
[ Tue Dec  2 20:15:16 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:15:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:15:16 2025 ] Training epoch: 81
[ Tue Dec  2 20:19:04 2025 ] 	Mean training loss: 1.3574.  Mean training acc: 78.65%.
[ Tue Dec  2 20:19:04 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:19:04 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:19:04 2025 ] Training epoch: 82
[ Tue Dec  2 20:22:53 2025 ] 	Mean training loss: 1.3545.  Mean training acc: 78.53%.
[ Tue Dec  2 20:22:53 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:22:53 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 20:22:53 2025 ] Training epoch: 83
[ Tue Dec  2 20:26:42 2025 ] 	Mean training loss: 1.3563.  Mean training acc: 78.98%.
[ Tue Dec  2 20:26:42 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:26:42 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 20:26:42 2025 ] Training epoch: 84
[ Tue Dec  2 20:30:30 2025 ] 	Mean training loss: 1.3580.  Mean training acc: 78.47%.
[ Tue Dec  2 20:30:30 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:30:30 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 20:30:30 2025 ] Training epoch: 85
[ Tue Dec  2 20:34:19 2025 ] 	Mean training loss: 1.3474.  Mean training acc: 78.52%.
[ Tue Dec  2 20:34:19 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:34:19 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:34:19 2025 ] Training epoch: 86
[ Tue Dec  2 20:38:07 2025 ] 	Mean training loss: 1.3461.  Mean training acc: 78.35%.
[ Tue Dec  2 20:38:07 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:38:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 20:38:07 2025 ] Training epoch: 87
[ Tue Dec  2 20:41:56 2025 ] 	Mean training loss: 1.3486.  Mean training acc: 78.75%.
[ Tue Dec  2 20:41:56 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:41:56 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 20:41:56 2025 ] Training epoch: 88
[ Tue Dec  2 20:45:45 2025 ] 	Mean training loss: 1.3438.  Mean training acc: 79.20%.
[ Tue Dec  2 20:45:45 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:45:45 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 20:45:45 2025 ] Training epoch: 89
[ Tue Dec  2 20:49:33 2025 ] 	Mean training loss: 1.3311.  Mean training acc: 79.55%.
[ Tue Dec  2 20:49:33 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:49:33 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:49:33 2025 ] Training epoch: 90
[ Tue Dec  2 20:53:21 2025 ] 	Mean training loss: 1.3404.  Mean training acc: 79.36%.
[ Tue Dec  2 20:53:21 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:53:21 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 20:53:21 2025 ] Training epoch: 91
[ Tue Dec  2 20:57:10 2025 ] 	Mean training loss: 1.3394.  Mean training acc: 79.18%.
[ Tue Dec  2 20:57:10 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:57:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:57:10 2025 ] Training epoch: 92
[ Tue Dec  2 21:00:59 2025 ] 	Mean training loss: 1.3293.  Mean training acc: 79.59%.
[ Tue Dec  2 21:00:59 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:00:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:00:59 2025 ] Training epoch: 93
[ Tue Dec  2 21:04:47 2025 ] 	Mean training loss: 1.3341.  Mean training acc: 79.78%.
[ Tue Dec  2 21:04:47 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:04:47 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:04:47 2025 ] Training epoch: 94
[ Tue Dec  2 21:08:36 2025 ] 	Mean training loss: 1.3243.  Mean training acc: 79.57%.
[ Tue Dec  2 21:08:36 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:08:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:08:36 2025 ] Training epoch: 95
[ Tue Dec  2 21:12:24 2025 ] 	Mean training loss: 1.3321.  Mean training acc: 79.89%.
[ Tue Dec  2 21:12:24 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:12:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:12:24 2025 ] Training epoch: 96
[ Tue Dec  2 21:16:13 2025 ] 	Mean training loss: 1.3330.  Mean training acc: 79.50%.
[ Tue Dec  2 21:16:13 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:16:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:16:13 2025 ] Training epoch: 97
[ Tue Dec  2 21:20:01 2025 ] 	Mean training loss: 1.3090.  Mean training acc: 80.73%.
[ Tue Dec  2 21:20:01 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:20:01 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:20:01 2025 ] Training epoch: 98
[ Tue Dec  2 21:23:50 2025 ] 	Mean training loss: 1.3225.  Mean training acc: 80.15%.
[ Tue Dec  2 21:23:50 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:23:50 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:23:50 2025 ] Training epoch: 99
[ Tue Dec  2 21:27:39 2025 ] 	Mean training loss: 1.3126.  Mean training acc: 80.30%.
[ Tue Dec  2 21:27:39 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:27:39 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:27:39 2025 ] Training epoch: 100
[ Tue Dec  2 21:31:27 2025 ] 	Mean training loss: 1.3183.  Mean training acc: 80.14%.
[ Tue Dec  2 21:31:27 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:31:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:31:27 2025 ] Training epoch: 101
[ Tue Dec  2 21:35:16 2025 ] 	Mean training loss: 1.3120.  Mean training acc: 80.05%.
[ Tue Dec  2 21:35:16 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:35:16 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:35:16 2025 ] Training epoch: 102
[ Tue Dec  2 21:39:04 2025 ] 	Mean training loss: 1.3125.  Mean training acc: 80.61%.
[ Tue Dec  2 21:39:04 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:39:04 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:39:05 2025 ] Training epoch: 103
[ Tue Dec  2 21:42:53 2025 ] 	Mean training loss: 1.3065.  Mean training acc: 80.59%.
[ Tue Dec  2 21:42:53 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:42:53 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:42:53 2025 ] Training epoch: 104
[ Tue Dec  2 21:46:42 2025 ] 	Mean training loss: 1.2975.  Mean training acc: 80.89%.
[ Tue Dec  2 21:46:42 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:46:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:46:42 2025 ] Training epoch: 105
[ Tue Dec  2 21:50:30 2025 ] 	Mean training loss: 1.2948.  Mean training acc: 81.00%.
[ Tue Dec  2 21:50:30 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:50:30 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:50:30 2025 ] Training epoch: 106
[ Tue Dec  2 21:54:19 2025 ] 	Mean training loss: 1.2981.  Mean training acc: 81.06%.
[ Tue Dec  2 21:54:19 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:54:19 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:54:19 2025 ] Training epoch: 107
[ Tue Dec  2 21:58:08 2025 ] 	Mean training loss: 1.2895.  Mean training acc: 81.09%.
[ Tue Dec  2 21:58:08 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:58:08 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 21:58:08 2025 ] Training epoch: 108
[ Tue Dec  2 22:01:56 2025 ] 	Mean training loss: 1.2972.  Mean training acc: 80.94%.
[ Tue Dec  2 22:01:56 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:01:56 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:01:56 2025 ] Training epoch: 109
[ Tue Dec  2 22:05:45 2025 ] 	Mean training loss: 1.2935.  Mean training acc: 80.75%.
[ Tue Dec  2 22:05:45 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:05:45 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:05:45 2025 ] Training epoch: 110
[ Tue Dec  2 22:09:34 2025 ] 	Mean training loss: 1.2821.  Mean training acc: 81.77%.
[ Tue Dec  2 22:09:34 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:09:34 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:09:34 2025 ] Training epoch: 111
[ Tue Dec  2 22:13:22 2025 ] 	Mean training loss: 1.2838.  Mean training acc: 81.05%.
[ Tue Dec  2 22:13:22 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:13:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:13:22 2025 ] Training epoch: 112
[ Tue Dec  2 22:17:11 2025 ] 	Mean training loss: 1.2879.  Mean training acc: 81.15%.
[ Tue Dec  2 22:17:11 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:17:11 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:17:11 2025 ] Training epoch: 113
[ Tue Dec  2 22:21:00 2025 ] 	Mean training loss: 1.2814.  Mean training acc: 81.55%.
[ Tue Dec  2 22:21:00 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:21:00 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:21:00 2025 ] Training epoch: 114
[ Tue Dec  2 22:24:48 2025 ] 	Mean training loss: 1.2738.  Mean training acc: 81.70%.
[ Tue Dec  2 22:24:48 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:24:48 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:24:48 2025 ] Training epoch: 115
[ Tue Dec  2 22:28:37 2025 ] 	Mean training loss: 1.2763.  Mean training acc: 81.34%.
[ Tue Dec  2 22:28:37 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:28:37 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:28:37 2025 ] Training epoch: 116
[ Tue Dec  2 22:32:25 2025 ] 	Mean training loss: 1.2726.  Mean training acc: 81.70%.
[ Tue Dec  2 22:32:25 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:32:25 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:32:25 2025 ] Training epoch: 117
[ Tue Dec  2 22:36:14 2025 ] 	Mean training loss: 1.2810.  Mean training acc: 81.63%.
[ Tue Dec  2 22:36:14 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:36:14 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:36:14 2025 ] Training epoch: 118
[ Tue Dec  2 22:40:03 2025 ] 	Mean training loss: 1.2781.  Mean training acc: 81.79%.
[ Tue Dec  2 22:40:03 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:40:03 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:40:03 2025 ] Training epoch: 119
[ Tue Dec  2 22:43:51 2025 ] 	Mean training loss: 1.2720.  Mean training acc: 81.90%.
[ Tue Dec  2 22:43:51 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:43:51 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:43:51 2025 ] Training epoch: 120
[ Tue Dec  2 22:47:40 2025 ] 	Mean training loss: 1.2781.  Mean training acc: 81.54%.
[ Tue Dec  2 22:47:40 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:47:40 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:47:40 2025 ] Training epoch: 121
[ Tue Dec  2 22:51:29 2025 ] 	Mean training loss: 1.2569.  Mean training acc: 82.34%.
[ Tue Dec  2 22:51:29 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:51:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:51:29 2025 ] Training epoch: 122
[ Tue Dec  2 22:55:17 2025 ] 	Mean training loss: 1.2777.  Mean training acc: 81.46%.
[ Tue Dec  2 22:55:17 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:55:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:55:17 2025 ] Training epoch: 123
[ Tue Dec  2 22:59:06 2025 ] 	Mean training loss: 1.2630.  Mean training acc: 82.22%.
[ Tue Dec  2 22:59:06 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 22:59:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:59:06 2025 ] Training epoch: 124
[ Tue Dec  2 23:02:55 2025 ] 	Mean training loss: 1.2696.  Mean training acc: 81.89%.
[ Tue Dec  2 23:02:55 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 23:02:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:02:55 2025 ] Training epoch: 125
[ Tue Dec  2 23:06:43 2025 ] 	Mean training loss: 1.2620.  Mean training acc: 82.05%.
[ Tue Dec  2 23:06:43 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 23:06:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:06:43 2025 ] Training epoch: 126
[ Tue Dec  2 23:10:32 2025 ] 	Mean training loss: 1.2631.  Mean training acc: 82.23%.
[ Tue Dec  2 23:10:32 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 23:10:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:10:32 2025 ] Training epoch: 127
[ Tue Dec  2 23:14:20 2025 ] 	Mean training loss: 1.2613.  Mean training acc: 82.08%.
[ Tue Dec  2 23:14:20 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 23:14:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:14:20 2025 ] Training epoch: 128
[ Tue Dec  2 23:18:09 2025 ] 	Mean training loss: 1.2612.  Mean training acc: 82.32%.
[ Tue Dec  2 23:18:09 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:18:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:18:09 2025 ] Training epoch: 129
[ Tue Dec  2 23:21:58 2025 ] 	Mean training loss: 1.2573.  Mean training acc: 82.38%.
[ Tue Dec  2 23:21:58 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:21:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:21:58 2025 ] Training epoch: 130
[ Tue Dec  2 23:25:46 2025 ] 	Mean training loss: 1.2462.  Mean training acc: 82.77%.
[ Tue Dec  2 23:25:46 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:25:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:25:46 2025 ] Training epoch: 131
[ Tue Dec  2 23:29:35 2025 ] 	Mean training loss: 1.2538.  Mean training acc: 82.54%.
[ Tue Dec  2 23:29:35 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:29:35 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:29:35 2025 ] Training epoch: 132
[ Tue Dec  2 23:33:23 2025 ] 	Mean training loss: 1.2434.  Mean training acc: 82.49%.
[ Tue Dec  2 23:33:23 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:33:23 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:33:23 2025 ] Training epoch: 133
[ Tue Dec  2 23:37:12 2025 ] 	Mean training loss: 1.2531.  Mean training acc: 82.98%.
[ Tue Dec  2 23:37:12 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:37:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:37:12 2025 ] Training epoch: 134
[ Tue Dec  2 23:41:01 2025 ] 	Mean training loss: 1.2485.  Mean training acc: 82.73%.
[ Tue Dec  2 23:41:01 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:41:01 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:41:01 2025 ] Training epoch: 135
[ Tue Dec  2 23:44:49 2025 ] 	Mean training loss: 1.2457.  Mean training acc: 82.81%.
[ Tue Dec  2 23:44:49 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:44:49 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:44:49 2025 ] Training epoch: 136
[ Tue Dec  2 23:48:38 2025 ] 	Mean training loss: 1.2434.  Mean training acc: 82.77%.
[ Tue Dec  2 23:48:38 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:48:38 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:48:38 2025 ] Training epoch: 137
[ Tue Dec  2 23:52:26 2025 ] 	Mean training loss: 1.2525.  Mean training acc: 82.40%.
[ Tue Dec  2 23:52:26 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:52:26 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:52:26 2025 ] Training epoch: 138
[ Tue Dec  2 23:56:15 2025 ] 	Mean training loss: 1.2398.  Mean training acc: 82.88%.
[ Tue Dec  2 23:56:15 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:56:15 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:56:15 2025 ] Training epoch: 139
[ Wed Dec  3 00:00:04 2025 ] 	Mean training loss: 1.2352.  Mean training acc: 83.26%.
[ Wed Dec  3 00:00:04 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:00:04 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:00:04 2025 ] Training epoch: 140
[ Wed Dec  3 00:03:52 2025 ] 	Mean training loss: 1.2283.  Mean training acc: 83.22%.
[ Wed Dec  3 00:03:52 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:03:52 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:03:52 2025 ] Training epoch: 141
[ Wed Dec  3 00:07:41 2025 ] 	Mean training loss: 1.2274.  Mean training acc: 83.72%.
[ Wed Dec  3 00:07:41 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:07:41 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:07:41 2025 ] Training epoch: 142
[ Wed Dec  3 00:11:29 2025 ] 	Mean training loss: 1.2249.  Mean training acc: 82.95%.
[ Wed Dec  3 00:11:29 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:11:29 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:11:29 2025 ] Training epoch: 143
[ Wed Dec  3 00:15:17 2025 ] 	Mean training loss: 1.2373.  Mean training acc: 82.87%.
[ Wed Dec  3 00:15:17 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:15:17 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:15:17 2025 ] Training epoch: 144
[ Wed Dec  3 00:19:06 2025 ] 	Mean training loss: 1.2320.  Mean training acc: 83.00%.
[ Wed Dec  3 00:19:06 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:19:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:19:06 2025 ] Training epoch: 145
[ Wed Dec  3 00:22:55 2025 ] 	Mean training loss: 1.2319.  Mean training acc: 83.28%.
[ Wed Dec  3 00:22:55 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:22:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:22:55 2025 ] Training epoch: 146
[ Wed Dec  3 00:26:43 2025 ] 	Mean training loss: 1.2288.  Mean training acc: 83.60%.
[ Wed Dec  3 00:26:43 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:26:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:26:43 2025 ] Training epoch: 147
[ Wed Dec  3 00:30:32 2025 ] 	Mean training loss: 1.2173.  Mean training acc: 83.72%.
[ Wed Dec  3 00:30:32 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:30:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:30:32 2025 ] Training epoch: 148
[ Wed Dec  3 00:34:21 2025 ] 	Mean training loss: 1.2191.  Mean training acc: 83.48%.
[ Wed Dec  3 00:34:21 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:34:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:34:21 2025 ] Training epoch: 149
[ Wed Dec  3 00:38:09 2025 ] 	Mean training loss: 1.2155.  Mean training acc: 84.19%.
[ Wed Dec  3 00:38:09 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:38:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:38:09 2025 ] Training epoch: 150
[ Wed Dec  3 00:41:58 2025 ] 	Mean training loss: 1.2215.  Mean training acc: 83.82%.
[ Wed Dec  3 00:41:58 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:41:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:41:58 2025 ] Training epoch: 151
[ Wed Dec  3 00:45:47 2025 ] 	Mean training loss: 1.2088.  Mean training acc: 84.10%.
[ Wed Dec  3 00:45:47 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:45:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:45:47 2025 ] Training epoch: 152
[ Wed Dec  3 00:49:35 2025 ] 	Mean training loss: 1.2054.  Mean training acc: 84.12%.
[ Wed Dec  3 00:49:35 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:49:35 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:49:35 2025 ] Training epoch: 153
[ Wed Dec  3 00:53:24 2025 ] 	Mean training loss: 1.2126.  Mean training acc: 84.06%.
[ Wed Dec  3 00:53:24 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:53:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:53:24 2025 ] Training epoch: 154
[ Wed Dec  3 00:57:12 2025 ] 	Mean training loss: 1.2145.  Mean training acc: 83.88%.
[ Wed Dec  3 00:57:12 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 00:57:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:57:12 2025 ] Training epoch: 155
[ Wed Dec  3 01:01:01 2025 ] 	Mean training loss: 1.2017.  Mean training acc: 84.33%.
[ Wed Dec  3 01:01:01 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:01:01 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:01:01 2025 ] Training epoch: 156
[ Wed Dec  3 01:04:49 2025 ] 	Mean training loss: 1.1990.  Mean training acc: 84.06%.
[ Wed Dec  3 01:04:49 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:04:49 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:04:49 2025 ] Training epoch: 157
[ Wed Dec  3 01:08:38 2025 ] 	Mean training loss: 1.2063.  Mean training acc: 84.25%.
[ Wed Dec  3 01:08:38 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:08:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:08:38 2025 ] Training epoch: 158
[ Wed Dec  3 01:12:26 2025 ] 	Mean training loss: 1.2021.  Mean training acc: 84.13%.
[ Wed Dec  3 01:12:26 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:12:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:12:26 2025 ] Training epoch: 159
[ Wed Dec  3 01:16:15 2025 ] 	Mean training loss: 1.2062.  Mean training acc: 83.77%.
[ Wed Dec  3 01:16:15 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:16:15 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:16:15 2025 ] Training epoch: 160
[ Wed Dec  3 01:20:04 2025 ] 	Mean training loss: 1.1926.  Mean training acc: 84.75%.
[ Wed Dec  3 01:20:04 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:20:04 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:20:04 2025 ] Training epoch: 161
[ Wed Dec  3 01:23:53 2025 ] 	Mean training loss: 1.1969.  Mean training acc: 84.69%.
[ Wed Dec  3 01:23:53 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:23:53 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:23:53 2025 ] Training epoch: 162
[ Wed Dec  3 01:27:41 2025 ] 	Mean training loss: 1.1986.  Mean training acc: 84.28%.
[ Wed Dec  3 01:27:41 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:27:41 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:27:41 2025 ] Training epoch: 163
[ Wed Dec  3 01:31:30 2025 ] 	Mean training loss: 1.1836.  Mean training acc: 84.89%.
[ Wed Dec  3 01:31:30 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:31:30 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:31:30 2025 ] Training epoch: 164
[ Wed Dec  3 01:35:18 2025 ] 	Mean training loss: 1.2107.  Mean training acc: 83.69%.
[ Wed Dec  3 01:35:18 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:35:18 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:35:18 2025 ] Training epoch: 165
[ Wed Dec  3 01:39:07 2025 ] 	Mean training loss: 1.1975.  Mean training acc: 84.56%.
[ Wed Dec  3 01:39:07 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:39:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:39:07 2025 ] Training epoch: 166
[ Wed Dec  3 01:42:55 2025 ] 	Mean training loss: 1.1955.  Mean training acc: 84.25%.
[ Wed Dec  3 01:42:55 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:42:55 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:42:55 2025 ] Training epoch: 167
[ Wed Dec  3 01:46:44 2025 ] 	Mean training loss: 1.1847.  Mean training acc: 84.77%.
[ Wed Dec  3 01:46:44 2025 ] 	Learning Rate: 0.0008
[ Wed Dec  3 01:46:44 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:46:44 2025 ] Training epoch: 168
[ Wed Dec  3 01:50:33 2025 ] 	Mean training loss: 1.1949.  Mean training acc: 84.38%.
[ Wed Dec  3 01:50:33 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:50:33 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:50:33 2025 ] Training epoch: 169
[ Wed Dec  3 01:54:21 2025 ] 	Mean training loss: 1.1822.  Mean training acc: 85.04%.
[ Wed Dec  3 01:54:21 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:54:21 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:54:21 2025 ] Training epoch: 170
[ Wed Dec  3 01:58:09 2025 ] 	Mean training loss: 1.1948.  Mean training acc: 84.66%.
[ Wed Dec  3 01:58:09 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:58:09 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:58:09 2025 ] Training epoch: 171
[ Wed Dec  3 02:01:58 2025 ] 	Mean training loss: 1.1799.  Mean training acc: 84.80%.
[ Wed Dec  3 02:01:58 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:01:58 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:01:58 2025 ] Training epoch: 172
[ Wed Dec  3 02:05:47 2025 ] 	Mean training loss: 1.1833.  Mean training acc: 85.08%.
[ Wed Dec  3 02:05:47 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:05:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:05:47 2025 ] Training epoch: 173
[ Wed Dec  3 02:09:35 2025 ] 	Mean training loss: 1.1728.  Mean training acc: 85.24%.
[ Wed Dec  3 02:09:35 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:09:35 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:09:35 2025 ] Training epoch: 174
[ Wed Dec  3 02:13:24 2025 ] 	Mean training loss: 1.1864.  Mean training acc: 84.90%.
[ Wed Dec  3 02:13:24 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:13:24 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:13:24 2025 ] Training epoch: 175
[ Wed Dec  3 02:17:13 2025 ] 	Mean training loss: 1.1714.  Mean training acc: 85.35%.
[ Wed Dec  3 02:17:13 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:17:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:17:13 2025 ] Training epoch: 176
[ Wed Dec  3 02:21:01 2025 ] 	Mean training loss: 1.1738.  Mean training acc: 85.34%.
[ Wed Dec  3 02:21:01 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:21:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:21:01 2025 ] Training epoch: 177
[ Wed Dec  3 02:24:50 2025 ] 	Mean training loss: 1.1771.  Mean training acc: 85.05%.
[ Wed Dec  3 02:24:50 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:24:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:24:50 2025 ] Training epoch: 178
[ Wed Dec  3 02:28:38 2025 ] 	Mean training loss: 1.1693.  Mean training acc: 85.62%.
[ Wed Dec  3 02:28:38 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:28:38 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:28:38 2025 ] Training epoch: 179
[ Wed Dec  3 02:32:27 2025 ] 	Mean training loss: 1.1663.  Mean training acc: 85.53%.
[ Wed Dec  3 02:32:27 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:32:27 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:32:27 2025 ] Training epoch: 180
[ Wed Dec  3 02:36:16 2025 ] 	Mean training loss: 1.1609.  Mean training acc: 85.61%.
[ Wed Dec  3 02:36:16 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:36:16 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:36:16 2025 ] Training epoch: 181
[ Wed Dec  3 02:40:04 2025 ] 	Mean training loss: 1.1592.  Mean training acc: 86.02%.
[ Wed Dec  3 02:40:04 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:40:04 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:40:04 2025 ] Training epoch: 182
[ Wed Dec  3 02:43:53 2025 ] 	Mean training loss: 1.1610.  Mean training acc: 85.70%.
[ Wed Dec  3 02:43:53 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:43:53 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:43:53 2025 ] Training epoch: 183
[ Wed Dec  3 02:47:42 2025 ] 	Mean training loss: 1.1597.  Mean training acc: 85.71%.
[ Wed Dec  3 02:47:42 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:47:42 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:47:42 2025 ] Training epoch: 184
[ Wed Dec  3 02:51:30 2025 ] 	Mean training loss: 1.1734.  Mean training acc: 85.46%.
[ Wed Dec  3 02:51:30 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:51:30 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:51:30 2025 ] Training epoch: 185
[ Wed Dec  3 02:55:19 2025 ] 	Mean training loss: 1.1646.  Mean training acc: 85.78%.
[ Wed Dec  3 02:55:19 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:55:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:55:19 2025 ] Training epoch: 186
[ Wed Dec  3 02:59:07 2025 ] 	Mean training loss: 1.1528.  Mean training acc: 85.88%.
[ Wed Dec  3 02:59:07 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 02:59:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:59:07 2025 ] Training epoch: 187
[ Wed Dec  3 03:02:56 2025 ] 	Mean training loss: 1.1606.  Mean training acc: 85.66%.
[ Wed Dec  3 03:02:56 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:02:56 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:02:56 2025 ] Training epoch: 188
[ Wed Dec  3 03:06:45 2025 ] 	Mean training loss: 1.1550.  Mean training acc: 85.83%.
[ Wed Dec  3 03:06:45 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:06:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:06:45 2025 ] Training epoch: 189
[ Wed Dec  3 03:10:33 2025 ] 	Mean training loss: 1.1557.  Mean training acc: 86.00%.
[ Wed Dec  3 03:10:33 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:10:33 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:10:33 2025 ] Training epoch: 190
[ Wed Dec  3 03:14:22 2025 ] 	Mean training loss: 1.1460.  Mean training acc: 86.44%.
[ Wed Dec  3 03:14:22 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:14:22 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:14:22 2025 ] Training epoch: 191
[ Wed Dec  3 03:18:10 2025 ] 	Mean training loss: 1.1453.  Mean training acc: 86.30%.
[ Wed Dec  3 03:18:10 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:18:10 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:18:10 2025 ] Training epoch: 192
[ Wed Dec  3 03:21:59 2025 ] 	Mean training loss: 1.1496.  Mean training acc: 86.21%.
[ Wed Dec  3 03:21:59 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:21:59 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:21:59 2025 ] Training epoch: 193
[ Wed Dec  3 03:25:48 2025 ] 	Mean training loss: 1.1437.  Mean training acc: 86.39%.
[ Wed Dec  3 03:25:48 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:25:48 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:25:48 2025 ] Training epoch: 194
[ Wed Dec  3 03:29:36 2025 ] 	Mean training loss: 1.1483.  Mean training acc: 86.27%.
[ Wed Dec  3 03:29:36 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:29:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:29:36 2025 ] Training epoch: 195
[ Wed Dec  3 03:33:25 2025 ] 	Mean training loss: 1.1514.  Mean training acc: 85.95%.
[ Wed Dec  3 03:33:25 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:33:25 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:33:25 2025 ] Training epoch: 196
[ Wed Dec  3 03:37:13 2025 ] 	Mean training loss: 1.1408.  Mean training acc: 86.32%.
[ Wed Dec  3 03:37:13 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:37:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:37:13 2025 ] Training epoch: 197
[ Wed Dec  3 03:41:02 2025 ] 	Mean training loss: 1.1454.  Mean training acc: 86.23%.
[ Wed Dec  3 03:41:02 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:41:02 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:41:02 2025 ] Training epoch: 198
[ Wed Dec  3 03:44:50 2025 ] 	Mean training loss: 1.1366.  Mean training acc: 86.63%.
[ Wed Dec  3 03:44:50 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:44:50 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:44:50 2025 ] Training epoch: 199
[ Wed Dec  3 03:48:39 2025 ] 	Mean training loss: 1.1423.  Mean training acc: 86.41%.
[ Wed Dec  3 03:48:39 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:48:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:48:39 2025 ] Training epoch: 200
[ Wed Dec  3 03:52:28 2025 ] 	Mean training loss: 1.1409.  Mean training acc: 86.24%.
[ Wed Dec  3 03:52:28 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:52:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:52:28 2025 ] Training epoch: 201
[ Wed Dec  3 03:56:16 2025 ] 	Mean training loss: 1.1389.  Mean training acc: 86.40%.
[ Wed Dec  3 03:56:16 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 03:56:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:56:16 2025 ] Training epoch: 202
[ Wed Dec  3 04:00:05 2025 ] 	Mean training loss: 1.1278.  Mean training acc: 87.14%.
[ Wed Dec  3 04:00:05 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 04:00:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:00:05 2025 ] Training epoch: 203
[ Wed Dec  3 04:03:53 2025 ] 	Mean training loss: 1.1416.  Mean training acc: 86.58%.
[ Wed Dec  3 04:03:53 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:03:53 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:03:53 2025 ] Training epoch: 204
[ Wed Dec  3 04:07:42 2025 ] 	Mean training loss: 1.1270.  Mean training acc: 87.00%.
[ Wed Dec  3 04:07:42 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:07:42 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:07:42 2025 ] Training epoch: 205
[ Wed Dec  3 04:11:31 2025 ] 	Mean training loss: 1.1292.  Mean training acc: 87.21%.
[ Wed Dec  3 04:11:31 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:11:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:11:31 2025 ] Training epoch: 206
[ Wed Dec  3 04:15:19 2025 ] 	Mean training loss: 1.1354.  Mean training acc: 86.67%.
[ Wed Dec  3 04:15:19 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:15:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:15:19 2025 ] Training epoch: 207
[ Wed Dec  3 04:19:07 2025 ] 	Mean training loss: 1.1340.  Mean training acc: 86.61%.
[ Wed Dec  3 04:19:07 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:19:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:19:07 2025 ] Training epoch: 208
[ Wed Dec  3 04:22:56 2025 ] 	Mean training loss: 1.1314.  Mean training acc: 86.99%.
[ Wed Dec  3 04:22:56 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:22:56 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:22:56 2025 ] Training epoch: 209
[ Wed Dec  3 04:26:44 2025 ] 	Mean training loss: 1.1331.  Mean training acc: 86.73%.
[ Wed Dec  3 04:26:44 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:26:44 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:26:44 2025 ] Training epoch: 210
[ Wed Dec  3 04:30:33 2025 ] 	Mean training loss: 1.1244.  Mean training acc: 86.97%.
[ Wed Dec  3 04:30:33 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:30:33 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:30:33 2025 ] Training epoch: 211
[ Wed Dec  3 04:34:21 2025 ] 	Mean training loss: 1.1232.  Mean training acc: 86.88%.
[ Wed Dec  3 04:34:21 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:34:21 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:34:21 2025 ] Training epoch: 212
[ Wed Dec  3 04:38:10 2025 ] 	Mean training loss: 1.1238.  Mean training acc: 86.72%.
[ Wed Dec  3 04:38:10 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:38:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:38:10 2025 ] Training epoch: 213
[ Wed Dec  3 04:41:59 2025 ] 	Mean training loss: 1.1112.  Mean training acc: 87.58%.
[ Wed Dec  3 04:41:59 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:41:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:41:59 2025 ] Training epoch: 214
[ Wed Dec  3 04:45:47 2025 ] 	Mean training loss: 1.1213.  Mean training acc: 87.02%.
[ Wed Dec  3 04:45:47 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:45:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:45:47 2025 ] Training epoch: 215
[ Wed Dec  3 04:49:36 2025 ] 	Mean training loss: 1.1211.  Mean training acc: 87.16%.
[ Wed Dec  3 04:49:36 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:49:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:49:36 2025 ] Training epoch: 216
[ Wed Dec  3 04:53:24 2025 ] 	Mean training loss: 1.1170.  Mean training acc: 87.36%.
[ Wed Dec  3 04:53:24 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:53:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:53:24 2025 ] Training epoch: 217
[ Wed Dec  3 04:57:13 2025 ] 	Mean training loss: 1.1178.  Mean training acc: 87.40%.
[ Wed Dec  3 04:57:13 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 04:57:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:57:13 2025 ] Training epoch: 218
[ Wed Dec  3 05:01:02 2025 ] 	Mean training loss: 1.1151.  Mean training acc: 87.32%.
[ Wed Dec  3 05:01:02 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:01:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:01:02 2025 ] Training epoch: 219
[ Wed Dec  3 05:04:50 2025 ] 	Mean training loss: 1.1114.  Mean training acc: 87.77%.
[ Wed Dec  3 05:04:50 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:04:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:04:50 2025 ] Training epoch: 220
[ Wed Dec  3 05:08:39 2025 ] 	Mean training loss: 1.1104.  Mean training acc: 87.54%.
[ Wed Dec  3 05:08:39 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:08:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:08:39 2025 ] Training epoch: 221
[ Wed Dec  3 05:12:28 2025 ] 	Mean training loss: 1.1084.  Mean training acc: 87.80%.
[ Wed Dec  3 05:12:28 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:12:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:12:28 2025 ] Training epoch: 222
[ Wed Dec  3 05:16:16 2025 ] 	Mean training loss: 1.1088.  Mean training acc: 87.55%.
[ Wed Dec  3 05:16:16 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:16:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:16:16 2025 ] Training epoch: 223
[ Wed Dec  3 05:20:05 2025 ] 	Mean training loss: 1.1069.  Mean training acc: 88.08%.
[ Wed Dec  3 05:20:05 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:20:05 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:20:05 2025 ] Training epoch: 224
[ Wed Dec  3 05:23:54 2025 ] 	Mean training loss: 1.1001.  Mean training acc: 87.94%.
[ Wed Dec  3 05:23:54 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:23:54 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:23:54 2025 ] Training epoch: 225
[ Wed Dec  3 05:27:42 2025 ] 	Mean training loss: 1.1050.  Mean training acc: 87.71%.
[ Wed Dec  3 05:27:42 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:27:42 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:27:42 2025 ] Training epoch: 226
[ Wed Dec  3 05:31:31 2025 ] 	Mean training loss: 1.1046.  Mean training acc: 87.96%.
[ Wed Dec  3 05:31:31 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:31:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:31:31 2025 ] Training epoch: 227
[ Wed Dec  3 05:35:19 2025 ] 	Mean training loss: 1.1039.  Mean training acc: 87.87%.
[ Wed Dec  3 05:35:19 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:35:19 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:35:19 2025 ] Training epoch: 228
[ Wed Dec  3 05:39:08 2025 ] 	Mean training loss: 1.0951.  Mean training acc: 88.17%.
[ Wed Dec  3 05:39:08 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:39:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:39:08 2025 ] Training epoch: 229
[ Wed Dec  3 05:42:56 2025 ] 	Mean training loss: 1.0928.  Mean training acc: 88.14%.
[ Wed Dec  3 05:42:56 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:42:56 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:42:56 2025 ] Training epoch: 230
[ Wed Dec  3 05:46:45 2025 ] 	Mean training loss: 1.0914.  Mean training acc: 88.20%.
[ Wed Dec  3 05:46:45 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:46:45 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:46:45 2025 ] Training epoch: 231
[ Wed Dec  3 05:50:33 2025 ] 	Mean training loss: 1.0927.  Mean training acc: 88.07%.
[ Wed Dec  3 05:50:33 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:50:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:50:33 2025 ] Training epoch: 232
[ Wed Dec  3 05:54:21 2025 ] 	Mean training loss: 1.0955.  Mean training acc: 88.08%.
[ Wed Dec  3 05:54:21 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:54:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:54:21 2025 ] Training epoch: 233
[ Wed Dec  3 05:58:10 2025 ] 	Mean training loss: 1.0888.  Mean training acc: 88.30%.
[ Wed Dec  3 05:58:10 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 05:58:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:58:10 2025 ] Training epoch: 234
[ Wed Dec  3 06:01:59 2025 ] 	Mean training loss: 1.0910.  Mean training acc: 88.19%.
[ Wed Dec  3 06:01:59 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 06:01:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:01:59 2025 ] Training epoch: 235
[ Wed Dec  3 06:05:48 2025 ] 	Mean training loss: 1.0882.  Mean training acc: 88.17%.
[ Wed Dec  3 06:05:48 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 06:05:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:05:48 2025 ] Training epoch: 236
[ Wed Dec  3 06:09:36 2025 ] 	Mean training loss: 1.0778.  Mean training acc: 88.76%.
[ Wed Dec  3 06:09:36 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:09:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:09:36 2025 ] Training epoch: 237
[ Wed Dec  3 06:13:25 2025 ] 	Mean training loss: 1.0809.  Mean training acc: 88.75%.
[ Wed Dec  3 06:13:25 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:13:25 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:13:25 2025 ] Training epoch: 238
[ Wed Dec  3 06:17:13 2025 ] 	Mean training loss: 1.0834.  Mean training acc: 88.56%.
[ Wed Dec  3 06:17:13 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:17:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:17:13 2025 ] Training epoch: 239
[ Wed Dec  3 06:21:01 2025 ] 	Mean training loss: 1.0784.  Mean training acc: 88.70%.
[ Wed Dec  3 06:21:01 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:21:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:21:01 2025 ] Training epoch: 240
[ Wed Dec  3 06:24:50 2025 ] 	Mean training loss: 1.0824.  Mean training acc: 88.54%.
[ Wed Dec  3 06:24:50 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:24:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:24:50 2025 ] Training epoch: 241
[ Wed Dec  3 06:28:39 2025 ] 	Mean training loss: 1.0792.  Mean training acc: 88.90%.
[ Wed Dec  3 06:28:39 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:28:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:28:39 2025 ] Training epoch: 242
[ Wed Dec  3 06:32:27 2025 ] 	Mean training loss: 1.0803.  Mean training acc: 88.50%.
[ Wed Dec  3 06:32:27 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:32:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:32:27 2025 ] Training epoch: 243
[ Wed Dec  3 06:36:16 2025 ] 	Mean training loss: 1.0718.  Mean training acc: 88.98%.
[ Wed Dec  3 06:36:16 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:36:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:36:16 2025 ] Training epoch: 244
[ Wed Dec  3 06:40:05 2025 ] 	Mean training loss: 1.0777.  Mean training acc: 88.68%.
[ Wed Dec  3 06:40:05 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:40:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:40:05 2025 ] Training epoch: 245
[ Wed Dec  3 06:43:53 2025 ] 	Mean training loss: 1.0698.  Mean training acc: 88.88%.
[ Wed Dec  3 06:43:53 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:43:53 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:43:53 2025 ] Training epoch: 246
[ Wed Dec  3 06:47:42 2025 ] 	Mean training loss: 1.0706.  Mean training acc: 88.69%.
[ Wed Dec  3 06:47:42 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:47:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:47:42 2025 ] Training epoch: 247
[ Wed Dec  3 06:51:30 2025 ] 	Mean training loss: 1.0659.  Mean training acc: 89.19%.
[ Wed Dec  3 06:51:30 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:51:30 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:51:30 2025 ] Training epoch: 248
[ Wed Dec  3 06:55:18 2025 ] 	Mean training loss: 1.0721.  Mean training acc: 89.06%.
[ Wed Dec  3 06:55:18 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:55:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:55:18 2025 ] Training epoch: 249
[ Wed Dec  3 06:59:07 2025 ] 	Mean training loss: 1.0717.  Mean training acc: 88.96%.
[ Wed Dec  3 06:59:07 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 06:59:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:59:07 2025 ] Training epoch: 250
[ Wed Dec  3 07:02:55 2025 ] 	Mean training loss: 1.0631.  Mean training acc: 89.54%.
[ Wed Dec  3 07:02:55 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:02:55 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:02:55 2025 ] Training epoch: 251
[ Wed Dec  3 07:06:44 2025 ] 	Mean training loss: 1.0619.  Mean training acc: 89.01%.
[ Wed Dec  3 07:06:44 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:06:44 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:06:44 2025 ] Training epoch: 252
[ Wed Dec  3 07:10:33 2025 ] 	Mean training loss: 1.0584.  Mean training acc: 89.59%.
[ Wed Dec  3 07:10:33 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:10:33 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:10:33 2025 ] Training epoch: 253
[ Wed Dec  3 07:14:21 2025 ] 	Mean training loss: 1.0630.  Mean training acc: 89.12%.
[ Wed Dec  3 07:14:21 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:14:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:14:21 2025 ] Training epoch: 254
[ Wed Dec  3 07:18:10 2025 ] 	Mean training loss: 1.0548.  Mean training acc: 89.83%.
[ Wed Dec  3 07:18:10 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:18:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:18:10 2025 ] Training epoch: 255
[ Wed Dec  3 07:21:58 2025 ] 	Mean training loss: 1.0557.  Mean training acc: 89.77%.
[ Wed Dec  3 07:21:58 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:21:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:21:58 2025 ] Training epoch: 256
[ Wed Dec  3 07:25:47 2025 ] 	Mean training loss: 1.0577.  Mean training acc: 89.32%.
[ Wed Dec  3 07:25:47 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:25:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:25:47 2025 ] Training epoch: 257
[ Wed Dec  3 07:29:35 2025 ] 	Mean training loss: 1.0552.  Mean training acc: 89.51%.
[ Wed Dec  3 07:29:35 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:29:35 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:29:35 2025 ] Training epoch: 258
[ Wed Dec  3 07:33:24 2025 ] 	Mean training loss: 1.0530.  Mean training acc: 89.81%.
[ Wed Dec  3 07:33:24 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:33:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:33:24 2025 ] Training epoch: 259
[ Wed Dec  3 07:37:12 2025 ] 	Mean training loss: 1.0527.  Mean training acc: 89.76%.
[ Wed Dec  3 07:37:12 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:37:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:37:12 2025 ] Training epoch: 260
[ Wed Dec  3 07:41:01 2025 ] 	Mean training loss: 1.0508.  Mean training acc: 89.51%.
[ Wed Dec  3 07:41:01 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:41:01 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:41:01 2025 ] Training epoch: 261
[ Wed Dec  3 07:44:50 2025 ] 	Mean training loss: 1.0577.  Mean training acc: 89.26%.
[ Wed Dec  3 07:44:50 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:44:50 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:44:50 2025 ] Training epoch: 262
[ Wed Dec  3 07:48:38 2025 ] 	Mean training loss: 1.0438.  Mean training acc: 89.76%.
[ Wed Dec  3 07:48:38 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:48:38 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:48:38 2025 ] Training epoch: 263
[ Wed Dec  3 07:52:27 2025 ] 	Mean training loss: 1.0507.  Mean training acc: 89.85%.
[ Wed Dec  3 07:52:27 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:52:27 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:52:27 2025 ] Training epoch: 264
[ Wed Dec  3 07:56:15 2025 ] 	Mean training loss: 1.0396.  Mean training acc: 89.97%.
[ Wed Dec  3 07:56:15 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 07:56:15 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:56:15 2025 ] Training epoch: 265
[ Wed Dec  3 08:00:03 2025 ] 	Mean training loss: 1.0418.  Mean training acc: 89.99%.
[ Wed Dec  3 08:00:03 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 08:00:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:00:03 2025 ] Training epoch: 266
[ Wed Dec  3 08:03:52 2025 ] 	Mean training loss: 1.0446.  Mean training acc: 90.03%.
[ Wed Dec  3 08:03:52 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 08:03:52 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 08:03:52 2025 ] Training epoch: 267
[ Wed Dec  3 08:07:41 2025 ] 	Mean training loss: 1.0420.  Mean training acc: 89.71%.
[ Wed Dec  3 08:07:41 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 08:07:41 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 08:07:41 2025 ] Training epoch: 268
[ Wed Dec  3 08:11:17 2025 ] 	Mean training loss: 1.0407.  Mean training acc: 90.06%.
[ Wed Dec  3 08:11:17 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:11:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:11:17 2025 ] Training epoch: 269
[ Wed Dec  3 08:15:01 2025 ] 	Mean training loss: 1.0466.  Mean training acc: 89.73%.
[ Wed Dec  3 08:15:01 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:15:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:15:01 2025 ] Training epoch: 270
[ Wed Dec  3 08:18:37 2025 ] 	Mean training loss: 1.0354.  Mean training acc: 90.38%.
[ Wed Dec  3 08:18:37 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:18:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:18:37 2025 ] Training epoch: 271
[ Wed Dec  3 08:22:21 2025 ] 	Mean training loss: 1.0380.  Mean training acc: 90.26%.
[ Wed Dec  3 08:22:21 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:22:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:22:21 2025 ] Training epoch: 272
[ Wed Dec  3 08:25:57 2025 ] 	Mean training loss: 1.0307.  Mean training acc: 90.36%.
[ Wed Dec  3 08:25:57 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:25:57 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:25:57 2025 ] Training epoch: 273
[ Wed Dec  3 08:29:40 2025 ] 	Mean training loss: 1.0255.  Mean training acc: 90.48%.
[ Wed Dec  3 08:29:40 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:29:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:29:40 2025 ] Training epoch: 274
[ Wed Dec  3 08:33:17 2025 ] 	Mean training loss: 1.0293.  Mean training acc: 90.46%.
[ Wed Dec  3 08:33:17 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:33:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:33:17 2025 ] Training epoch: 275
[ Wed Dec  3 08:37:00 2025 ] 	Mean training loss: 1.0330.  Mean training acc: 90.38%.
[ Wed Dec  3 08:37:00 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:37:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:37:00 2025 ] Training epoch: 276
[ Wed Dec  3 08:40:37 2025 ] 	Mean training loss: 1.0195.  Mean training acc: 90.96%.
[ Wed Dec  3 08:40:37 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:40:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:40:37 2025 ] Training epoch: 277
[ Wed Dec  3 08:44:20 2025 ] 	Mean training loss: 1.0226.  Mean training acc: 90.38%.
[ Wed Dec  3 08:44:20 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:44:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:44:20 2025 ] Training epoch: 278
[ Wed Dec  3 08:47:57 2025 ] 	Mean training loss: 1.0257.  Mean training acc: 90.64%.
[ Wed Dec  3 08:47:57 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:47:57 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:47:57 2025 ] Training epoch: 279
[ Wed Dec  3 08:51:40 2025 ] 	Mean training loss: 1.0193.  Mean training acc: 90.59%.
[ Wed Dec  3 08:51:40 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:51:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:51:40 2025 ] Training epoch: 280
[ Wed Dec  3 08:55:17 2025 ] 	Mean training loss: 1.0176.  Mean training acc: 90.83%.
[ Wed Dec  3 08:55:17 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:55:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:55:17 2025 ] Training epoch: 281
[ Wed Dec  3 08:59:00 2025 ] 	Mean training loss: 1.0204.  Mean training acc: 90.72%.
[ Wed Dec  3 08:59:00 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 08:59:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:59:00 2025 ] Training epoch: 282
[ Wed Dec  3 09:02:37 2025 ] 	Mean training loss: 1.0108.  Mean training acc: 91.31%.
[ Wed Dec  3 09:02:37 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:02:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:02:37 2025 ] Training epoch: 283
[ Wed Dec  3 09:06:20 2025 ] 	Mean training loss: 1.0161.  Mean training acc: 91.05%.
[ Wed Dec  3 09:06:20 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:06:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:06:20 2025 ] Training epoch: 284
[ Wed Dec  3 09:09:57 2025 ] 	Mean training loss: 1.0147.  Mean training acc: 91.03%.
[ Wed Dec  3 09:09:57 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:09:57 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:09:57 2025 ] Training epoch: 285
[ Wed Dec  3 09:13:40 2025 ] 	Mean training loss: 1.0108.  Mean training acc: 91.24%.
[ Wed Dec  3 09:13:40 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:13:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:13:40 2025 ] Training epoch: 286
[ Wed Dec  3 09:17:17 2025 ] 	Mean training loss: 1.0146.  Mean training acc: 90.86%.
[ Wed Dec  3 09:17:17 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:17:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:17:17 2025 ] Training epoch: 287
[ Wed Dec  3 09:21:00 2025 ] 	Mean training loss: 1.0043.  Mean training acc: 91.37%.
[ Wed Dec  3 09:21:00 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:21:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:21:00 2025 ] Training epoch: 288
[ Wed Dec  3 09:24:37 2025 ] 	Mean training loss: 1.0136.  Mean training acc: 91.15%.
[ Wed Dec  3 09:24:37 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:24:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:24:37 2025 ] Training epoch: 289
[ Wed Dec  3 09:28:20 2025 ] 	Mean training loss: 1.0101.  Mean training acc: 91.28%.
[ Wed Dec  3 09:28:20 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:28:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:28:20 2025 ] Training epoch: 290
[ Wed Dec  3 09:31:56 2025 ] 	Mean training loss: 1.0019.  Mean training acc: 91.36%.
[ Wed Dec  3 09:31:56 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:31:56 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:31:56 2025 ] Training epoch: 291
[ Wed Dec  3 09:35:40 2025 ] 	Mean training loss: 1.0011.  Mean training acc: 91.57%.
[ Wed Dec  3 09:35:40 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:35:40 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 09:35:40 2025 ] Training epoch: 292
[ Wed Dec  3 09:39:17 2025 ] 	Mean training loss: 1.0001.  Mean training acc: 91.38%.
[ Wed Dec  3 09:39:17 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:39:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:39:17 2025 ] Training epoch: 293
[ Wed Dec  3 09:43:01 2025 ] 	Mean training loss: 1.0008.  Mean training acc: 91.62%.
[ Wed Dec  3 09:43:01 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:43:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:43:01 2025 ] Training epoch: 294
[ Wed Dec  3 09:46:38 2025 ] 	Mean training loss: 1.0035.  Mean training acc: 91.31%.
[ Wed Dec  3 09:46:38 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:46:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:46:38 2025 ] Training epoch: 295
[ Wed Dec  3 09:50:21 2025 ] 	Mean training loss: 0.9996.  Mean training acc: 91.45%.
[ Wed Dec  3 09:50:21 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:50:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:50:21 2025 ] Training epoch: 296
[ Wed Dec  3 09:53:58 2025 ] 	Mean training loss: 0.9982.  Mean training acc: 91.39%.
[ Wed Dec  3 09:53:58 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:53:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:53:58 2025 ] Training epoch: 297
[ Wed Dec  3 09:57:41 2025 ] 	Mean training loss: 0.9918.  Mean training acc: 91.67%.
[ Wed Dec  3 09:57:41 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 09:57:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:57:41 2025 ] Training epoch: 298
[ Wed Dec  3 10:01:19 2025 ] 	Mean training loss: 0.9955.  Mean training acc: 91.59%.
[ Wed Dec  3 10:01:19 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 10:01:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:01:19 2025 ] Training epoch: 299
[ Wed Dec  3 10:05:01 2025 ] 	Mean training loss: 1.0015.  Mean training acc: 91.29%.
[ Wed Dec  3 10:05:01 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 10:05:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:05:01 2025 ] Training epoch: 300
[ Wed Dec  3 10:08:39 2025 ] 	Mean training loss: 0.9917.  Mean training acc: 91.86%.
[ Wed Dec  3 10:08:39 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 10:08:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:08:39 2025 ] Training epoch: 301
[ Wed Dec  3 10:12:21 2025 ] 	Mean training loss: 0.9971.  Mean training acc: 91.40%.
[ Wed Dec  3 10:12:21 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:12:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:12:21 2025 ] Training epoch: 302
[ Wed Dec  3 10:16:00 2025 ] 	Mean training loss: 0.9908.  Mean training acc: 91.62%.
[ Wed Dec  3 10:16:00 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:16:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:16:00 2025 ] Training epoch: 303
[ Wed Dec  3 10:19:41 2025 ] 	Mean training loss: 0.9929.  Mean training acc: 91.69%.
[ Wed Dec  3 10:19:41 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:19:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:19:41 2025 ] Training epoch: 304
[ Wed Dec  3 10:23:21 2025 ] 	Mean training loss: 0.9778.  Mean training acc: 92.33%.
[ Wed Dec  3 10:23:21 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:23:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:23:21 2025 ] Training epoch: 305
[ Wed Dec  3 10:27:01 2025 ] 	Mean training loss: 0.9915.  Mean training acc: 91.87%.
[ Wed Dec  3 10:27:01 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:27:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:27:01 2025 ] Training epoch: 306
[ Wed Dec  3 10:30:41 2025 ] 	Mean training loss: 0.9809.  Mean training acc: 91.82%.
[ Wed Dec  3 10:30:41 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:30:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:30:41 2025 ] Training epoch: 307
[ Wed Dec  3 10:34:21 2025 ] 	Mean training loss: 0.9866.  Mean training acc: 92.13%.
[ Wed Dec  3 10:34:21 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:34:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:34:21 2025 ] Training epoch: 308
[ Wed Dec  3 10:38:02 2025 ] 	Mean training loss: 0.9829.  Mean training acc: 92.24%.
[ Wed Dec  3 10:38:02 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:38:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:38:02 2025 ] Training epoch: 309
[ Wed Dec  3 10:41:41 2025 ] 	Mean training loss: 0.9727.  Mean training acc: 92.34%.
[ Wed Dec  3 10:41:41 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:41:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:41:41 2025 ] Training epoch: 310
[ Wed Dec  3 10:45:22 2025 ] 	Mean training loss: 0.9686.  Mean training acc: 92.44%.
[ Wed Dec  3 10:45:22 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:45:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:45:22 2025 ] Training epoch: 311
[ Wed Dec  3 10:49:02 2025 ] 	Mean training loss: 0.9761.  Mean training acc: 92.20%.
[ Wed Dec  3 10:49:02 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:49:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:49:02 2025 ] Training epoch: 312
[ Wed Dec  3 10:52:43 2025 ] 	Mean training loss: 0.9818.  Mean training acc: 92.26%.
[ Wed Dec  3 10:52:43 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:52:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:52:43 2025 ] Training epoch: 313
[ Wed Dec  3 10:56:22 2025 ] 	Mean training loss: 0.9682.  Mean training acc: 92.80%.
[ Wed Dec  3 10:56:22 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 10:56:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:56:22 2025 ] Training epoch: 314
[ Wed Dec  3 11:00:04 2025 ] 	Mean training loss: 0.9703.  Mean training acc: 92.37%.
[ Wed Dec  3 11:00:04 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:00:04 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:00:04 2025 ] Training epoch: 315
[ Wed Dec  3 11:03:42 2025 ] 	Mean training loss: 0.9802.  Mean training acc: 92.20%.
[ Wed Dec  3 11:03:42 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:03:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:03:42 2025 ] Training epoch: 316
[ Wed Dec  3 11:07:24 2025 ] 	Mean training loss: 0.9695.  Mean training acc: 92.64%.
[ Wed Dec  3 11:07:24 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:07:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:07:24 2025 ] Training epoch: 317
[ Wed Dec  3 11:11:02 2025 ] 	Mean training loss: 0.9717.  Mean training acc: 92.51%.
[ Wed Dec  3 11:11:02 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:11:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:11:02 2025 ] Training epoch: 318
[ Wed Dec  3 11:14:45 2025 ] 	Mean training loss: 0.9579.  Mean training acc: 93.06%.
[ Wed Dec  3 11:14:45 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:14:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:14:45 2025 ] Training epoch: 319
[ Wed Dec  3 11:18:22 2025 ] 	Mean training loss: 0.9608.  Mean training acc: 92.87%.
[ Wed Dec  3 11:18:22 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:18:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:18:22 2025 ] Training epoch: 320
[ Wed Dec  3 11:22:05 2025 ] 	Mean training loss: 0.9587.  Mean training acc: 92.98%.
[ Wed Dec  3 11:22:05 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:22:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:22:05 2025 ] Training epoch: 321
[ Wed Dec  3 11:25:42 2025 ] 	Mean training loss: 0.9617.  Mean training acc: 92.71%.
[ Wed Dec  3 11:25:42 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:25:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:25:42 2025 ] Training epoch: 322
[ Wed Dec  3 11:29:25 2025 ] 	Mean training loss: 0.9633.  Mean training acc: 92.68%.
[ Wed Dec  3 11:29:25 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:29:25 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:29:25 2025 ] Training epoch: 323
[ Wed Dec  3 11:33:02 2025 ] 	Mean training loss: 0.9659.  Mean training acc: 92.54%.
[ Wed Dec  3 11:33:02 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:33:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:33:02 2025 ] Training epoch: 324
[ Wed Dec  3 11:36:46 2025 ] 	Mean training loss: 0.9533.  Mean training acc: 92.95%.
[ Wed Dec  3 11:36:46 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:36:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:36:46 2025 ] Training epoch: 325
[ Wed Dec  3 11:40:22 2025 ] 	Mean training loss: 0.9564.  Mean training acc: 93.02%.
[ Wed Dec  3 11:40:22 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:40:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:40:22 2025 ] Training epoch: 326
[ Wed Dec  3 11:44:06 2025 ] 	Mean training loss: 0.9576.  Mean training acc: 93.27%.
[ Wed Dec  3 11:44:06 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:44:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:44:06 2025 ] Training epoch: 327
[ Wed Dec  3 11:47:42 2025 ] 	Mean training loss: 0.9572.  Mean training acc: 92.96%.
[ Wed Dec  3 11:47:42 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:47:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:47:42 2025 ] Training epoch: 328
[ Wed Dec  3 11:51:26 2025 ] 	Mean training loss: 0.9535.  Mean training acc: 93.34%.
[ Wed Dec  3 11:51:26 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:51:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:51:26 2025 ] Training epoch: 329
[ Wed Dec  3 11:55:03 2025 ] 	Mean training loss: 0.9488.  Mean training acc: 93.11%.
[ Wed Dec  3 11:55:03 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:55:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:55:03 2025 ] Training epoch: 330
[ Wed Dec  3 11:58:46 2025 ] 	Mean training loss: 0.9486.  Mean training acc: 93.24%.
[ Wed Dec  3 11:58:46 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 11:58:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:58:46 2025 ] Training epoch: 331
[ Wed Dec  3 12:02:23 2025 ] 	Mean training loss: 0.9416.  Mean training acc: 93.61%.
[ Wed Dec  3 12:02:23 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 12:02:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:02:23 2025 ] Training epoch: 332
[ Wed Dec  3 12:06:06 2025 ] 	Mean training loss: 0.9513.  Mean training acc: 93.23%.
[ Wed Dec  3 12:06:06 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 12:06:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:06:06 2025 ] Training epoch: 333
[ Wed Dec  3 12:09:42 2025 ] 	Mean training loss: 0.9454.  Mean training acc: 93.34%.
[ Wed Dec  3 12:09:42 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 12:09:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:09:42 2025 ] Training epoch: 334
[ Wed Dec  3 12:13:26 2025 ] 	Mean training loss: 0.9416.  Mean training acc: 93.70%.
[ Wed Dec  3 12:13:26 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 12:13:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:13:26 2025 ] Training epoch: 335
[ Wed Dec  3 12:17:02 2025 ] 	Mean training loss: 0.9356.  Mean training acc: 93.52%.
[ Wed Dec  3 12:17:02 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 12:17:02 2025 ] 	Time consumption: [Data]09%, [Network]89%
[ Wed Dec  3 12:17:02 2025 ] Training epoch: 336
[ Wed Dec  3 12:20:46 2025 ] 	Mean training loss: 0.9443.  Mean training acc: 93.45%.
[ Wed Dec  3 12:20:46 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 12:20:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:20:46 2025 ] Training epoch: 337
[ Wed Dec  3 12:24:22 2025 ] 	Mean training loss: 0.9415.  Mean training acc: 93.55%.
[ Wed Dec  3 12:24:22 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:24:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:24:22 2025 ] Training epoch: 338
[ Wed Dec  3 12:28:06 2025 ] 	Mean training loss: 0.9411.  Mean training acc: 93.69%.
[ Wed Dec  3 12:28:06 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:28:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:28:06 2025 ] Training epoch: 339
[ Wed Dec  3 12:31:42 2025 ] 	Mean training loss: 0.9366.  Mean training acc: 93.83%.
[ Wed Dec  3 12:31:42 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:31:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:31:42 2025 ] Training epoch: 340
[ Wed Dec  3 12:35:26 2025 ] 	Mean training loss: 0.9338.  Mean training acc: 93.86%.
[ Wed Dec  3 12:35:26 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:35:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:35:26 2025 ] Training epoch: 341
[ Wed Dec  3 12:39:02 2025 ] 	Mean training loss: 0.9335.  Mean training acc: 93.66%.
[ Wed Dec  3 12:39:02 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:39:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:39:02 2025 ] Training epoch: 342
[ Wed Dec  3 12:42:46 2025 ] 	Mean training loss: 0.9383.  Mean training acc: 93.67%.
[ Wed Dec  3 12:42:46 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:42:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:42:46 2025 ] Training epoch: 343
[ Wed Dec  3 12:46:23 2025 ] 	Mean training loss: 0.9231.  Mean training acc: 94.39%.
[ Wed Dec  3 12:46:23 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:46:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:46:23 2025 ] Training epoch: 344
[ Wed Dec  3 12:50:06 2025 ] 	Mean training loss: 0.9343.  Mean training acc: 93.74%.
[ Wed Dec  3 12:50:06 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:50:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:50:06 2025 ] Training epoch: 345
[ Wed Dec  3 12:53:43 2025 ] 	Mean training loss: 0.9253.  Mean training acc: 94.13%.
[ Wed Dec  3 12:53:43 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:53:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:53:43 2025 ] Training epoch: 346
[ Wed Dec  3 12:57:27 2025 ] 	Mean training loss: 0.9243.  Mean training acc: 94.25%.
[ Wed Dec  3 12:57:27 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 12:57:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:57:27 2025 ] Training epoch: 347
[ Wed Dec  3 13:01:03 2025 ] 	Mean training loss: 0.9256.  Mean training acc: 94.01%.
[ Wed Dec  3 13:01:03 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:01:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:01:03 2025 ] Training epoch: 348
[ Wed Dec  3 13:04:47 2025 ] 	Mean training loss: 0.9306.  Mean training acc: 93.65%.
[ Wed Dec  3 13:04:47 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:04:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:04:47 2025 ] Training epoch: 349
[ Wed Dec  3 13:08:24 2025 ] 	Mean training loss: 0.9233.  Mean training acc: 94.31%.
[ Wed Dec  3 13:08:24 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:08:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:08:24 2025 ] Training epoch: 350
[ Wed Dec  3 13:12:07 2025 ] 	Mean training loss: 0.9253.  Mean training acc: 93.96%.
[ Wed Dec  3 13:12:07 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:12:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:12:07 2025 ] Training epoch: 351
[ Wed Dec  3 13:15:44 2025 ] 	Mean training loss: 0.9220.  Mean training acc: 94.30%.
[ Wed Dec  3 13:15:44 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:15:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:15:44 2025 ] Training epoch: 352
[ Wed Dec  3 13:19:27 2025 ] 	Mean training loss: 0.9130.  Mean training acc: 94.49%.
[ Wed Dec  3 13:19:27 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:19:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:19:27 2025 ] Training epoch: 353
[ Wed Dec  3 13:23:05 2025 ] 	Mean training loss: 0.9158.  Mean training acc: 94.29%.
[ Wed Dec  3 13:23:05 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:23:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:23:05 2025 ] Training epoch: 354
[ Wed Dec  3 13:26:47 2025 ] 	Mean training loss: 0.9182.  Mean training acc: 94.19%.
[ Wed Dec  3 13:26:47 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:26:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:26:47 2025 ] Training epoch: 355
[ Wed Dec  3 13:30:26 2025 ] 	Mean training loss: 0.9173.  Mean training acc: 94.14%.
[ Wed Dec  3 13:30:26 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:30:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:30:26 2025 ] Training epoch: 356
[ Wed Dec  3 13:34:07 2025 ] 	Mean training loss: 0.9152.  Mean training acc: 94.32%.
[ Wed Dec  3 13:34:07 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:34:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:34:07 2025 ] Training epoch: 357
[ Wed Dec  3 13:37:46 2025 ] 	Mean training loss: 0.9122.  Mean training acc: 94.54%.
[ Wed Dec  3 13:37:46 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:37:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:37:46 2025 ] Training epoch: 358
[ Wed Dec  3 13:41:28 2025 ] 	Mean training loss: 0.9128.  Mean training acc: 94.64%.
[ Wed Dec  3 13:41:28 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:41:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:41:28 2025 ] Training epoch: 359
[ Wed Dec  3 13:45:07 2025 ] 	Mean training loss: 0.9210.  Mean training acc: 94.35%.
[ Wed Dec  3 13:45:07 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:45:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:45:07 2025 ] Training epoch: 360
[ Wed Dec  3 13:48:48 2025 ] 	Mean training loss: 0.9113.  Mean training acc: 94.66%.
[ Wed Dec  3 13:48:48 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:48:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:48:48 2025 ] Training epoch: 361
[ Wed Dec  3 13:52:28 2025 ] 	Mean training loss: 0.9050.  Mean training acc: 94.78%.
[ Wed Dec  3 13:52:28 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:52:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:52:28 2025 ] Training epoch: 362
[ Wed Dec  3 13:56:08 2025 ] 	Mean training loss: 0.9056.  Mean training acc: 94.81%.
[ Wed Dec  3 13:56:08 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:56:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:56:08 2025 ] Training epoch: 363
[ Wed Dec  3 13:59:48 2025 ] 	Mean training loss: 0.9035.  Mean training acc: 94.96%.
[ Wed Dec  3 13:59:48 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 13:59:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:59:48 2025 ] Training epoch: 364
[ Wed Dec  3 14:03:28 2025 ] 	Mean training loss: 0.8976.  Mean training acc: 95.22%.
[ Wed Dec  3 14:03:28 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:03:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:03:28 2025 ] Training epoch: 365
[ Wed Dec  3 14:07:09 2025 ] 	Mean training loss: 0.9069.  Mean training acc: 94.65%.
[ Wed Dec  3 14:07:09 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:07:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:07:09 2025 ] Training epoch: 366
[ Wed Dec  3 14:10:48 2025 ] 	Mean training loss: 0.8987.  Mean training acc: 94.95%.
[ Wed Dec  3 14:10:48 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:10:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:10:48 2025 ] Training epoch: 367
[ Wed Dec  3 14:14:24 2025 ] 	Mean training loss: 0.8955.  Mean training acc: 95.26%.
[ Wed Dec  3 14:14:24 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:14:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:14:24 2025 ] Training epoch: 368
[ Wed Dec  3 14:18:01 2025 ] 	Mean training loss: 0.9056.  Mean training acc: 94.82%.
[ Wed Dec  3 14:18:01 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:18:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:18:01 2025 ] Training epoch: 369
[ Wed Dec  3 14:20:52 2025 ] 	Mean training loss: 0.9014.  Mean training acc: 95.15%.
[ Wed Dec  3 14:20:52 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:20:52 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:20:52 2025 ] Training epoch: 370
[ Wed Dec  3 14:23:37 2025 ] 	Mean training loss: 0.8870.  Mean training acc: 95.55%.
[ Wed Dec  3 14:23:37 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:23:37 2025 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Dec  3 14:23:37 2025 ] Training epoch: 371
[ Wed Dec  3 14:26:16 2025 ] 	Mean training loss: 0.8931.  Mean training acc: 95.41%.
[ Wed Dec  3 14:26:16 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:26:16 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:26:16 2025 ] Training epoch: 372
[ Wed Dec  3 14:29:03 2025 ] 	Mean training loss: 0.8959.  Mean training acc: 95.01%.
[ Wed Dec  3 14:29:03 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:29:03 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:29:03 2025 ] Training epoch: 373
[ Wed Dec  3 14:31:41 2025 ] 	Mean training loss: 0.8914.  Mean training acc: 95.27%.
[ Wed Dec  3 14:31:41 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:31:41 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:31:41 2025 ] Training epoch: 374
[ Wed Dec  3 14:34:30 2025 ] 	Mean training loss: 0.8884.  Mean training acc: 95.25%.
[ Wed Dec  3 14:34:30 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:34:30 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:34:30 2025 ] Training epoch: 375
[ Wed Dec  3 14:37:08 2025 ] 	Mean training loss: 0.8861.  Mean training acc: 95.48%.
[ Wed Dec  3 14:37:08 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:37:08 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:37:08 2025 ] Training epoch: 376
[ Wed Dec  3 14:39:56 2025 ] 	Mean training loss: 0.8840.  Mean training acc: 95.51%.
[ Wed Dec  3 14:39:56 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:39:56 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:39:56 2025 ] Training epoch: 377
[ Wed Dec  3 14:42:34 2025 ] 	Mean training loss: 0.8885.  Mean training acc: 95.13%.
[ Wed Dec  3 14:42:34 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 14:42:34 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:42:34 2025 ] Training epoch: 378
[ Wed Dec  3 14:45:20 2025 ] 	Mean training loss: 0.8793.  Mean training acc: 95.82%.
[ Wed Dec  3 14:45:20 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 14:45:20 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:45:20 2025 ] Training epoch: 379
[ Wed Dec  3 14:48:01 2025 ] 	Mean training loss: 0.8845.  Mean training acc: 95.47%.
[ Wed Dec  3 14:48:01 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 14:48:01 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:48:01 2025 ] Training epoch: 380
[ Wed Dec  3 14:50:44 2025 ] 	Mean training loss: 0.8813.  Mean training acc: 95.52%.
[ Wed Dec  3 14:50:44 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 14:50:44 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:50:44 2025 ] Training epoch: 381
[ Wed Dec  3 14:53:27 2025 ] 	Mean training loss: 0.8809.  Mean training acc: 95.73%.
[ Wed Dec  3 14:53:27 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 14:53:27 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:53:27 2025 ] Training epoch: 382
[ Wed Dec  3 14:56:08 2025 ] 	Mean training loss: 0.8781.  Mean training acc: 95.67%.
[ Wed Dec  3 14:56:08 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 14:56:08 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:56:08 2025 ] Training epoch: 383
[ Wed Dec  3 14:58:53 2025 ] 	Mean training loss: 0.8798.  Mean training acc: 95.66%.
[ Wed Dec  3 14:58:53 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 14:58:53 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 14:58:53 2025 ] Training epoch: 384
[ Wed Dec  3 15:01:33 2025 ] 	Mean training loss: 0.8713.  Mean training acc: 96.00%.
[ Wed Dec  3 15:01:33 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:01:33 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:01:33 2025 ] Training epoch: 385
[ Wed Dec  3 15:04:20 2025 ] 	Mean training loss: 0.8796.  Mean training acc: 95.60%.
[ Wed Dec  3 15:04:20 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:04:20 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:04:20 2025 ] Training epoch: 386
[ Wed Dec  3 15:06:57 2025 ] 	Mean training loss: 0.8744.  Mean training acc: 95.79%.
[ Wed Dec  3 15:06:57 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:06:57 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:06:57 2025 ] Training epoch: 387
[ Wed Dec  3 15:09:46 2025 ] 	Mean training loss: 0.8785.  Mean training acc: 95.82%.
[ Wed Dec  3 15:09:46 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:09:46 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:09:46 2025 ] Training epoch: 388
[ Wed Dec  3 15:12:23 2025 ] 	Mean training loss: 0.8784.  Mean training acc: 95.64%.
[ Wed Dec  3 15:12:23 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:12:23 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:12:23 2025 ] Training epoch: 389
[ Wed Dec  3 15:15:12 2025 ] 	Mean training loss: 0.8729.  Mean training acc: 95.82%.
[ Wed Dec  3 15:15:12 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:15:12 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:15:12 2025 ] Training epoch: 390
[ Wed Dec  3 15:17:50 2025 ] 	Mean training loss: 0.8700.  Mean training acc: 95.87%.
[ Wed Dec  3 15:17:50 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:17:50 2025 ] 	Time consumption: [Data]11%, [Network]87%
[ Wed Dec  3 15:17:50 2025 ] Training epoch: 391
[ Wed Dec  3 15:20:36 2025 ] 	Mean training loss: 0.8716.  Mean training acc: 95.95%.
[ Wed Dec  3 15:20:36 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:20:36 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:20:36 2025 ] Training epoch: 392
[ Wed Dec  3 15:23:16 2025 ] 	Mean training loss: 0.8708.  Mean training acc: 95.87%.
[ Wed Dec  3 15:23:16 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:23:16 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:23:16 2025 ] Training epoch: 393
[ Wed Dec  3 15:26:00 2025 ] 	Mean training loss: 0.8704.  Mean training acc: 96.06%.
[ Wed Dec  3 15:26:00 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:26:00 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:26:00 2025 ] Training epoch: 394
[ Wed Dec  3 15:28:42 2025 ] 	Mean training loss: 0.8670.  Mean training acc: 96.16%.
[ Wed Dec  3 15:28:42 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:28:42 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:28:42 2025 ] Training epoch: 395
[ Wed Dec  3 15:31:24 2025 ] 	Mean training loss: 0.8646.  Mean training acc: 95.90%.
[ Wed Dec  3 15:31:24 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:31:24 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:31:24 2025 ] Training epoch: 396
[ Wed Dec  3 15:34:09 2025 ] 	Mean training loss: 0.8644.  Mean training acc: 96.31%.
[ Wed Dec  3 15:34:09 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:34:09 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:34:09 2025 ] Training epoch: 397
[ Wed Dec  3 15:36:49 2025 ] 	Mean training loss: 0.8600.  Mean training acc: 96.25%.
[ Wed Dec  3 15:36:49 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:36:49 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:36:49 2025 ] Training epoch: 398
[ Wed Dec  3 15:39:36 2025 ] 	Mean training loss: 0.8610.  Mean training acc: 96.21%.
[ Wed Dec  3 15:39:36 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:39:36 2025 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Dec  3 15:39:36 2025 ] Training epoch: 399
[ Wed Dec  3 15:42:13 2025 ] 	Mean training loss: 0.8639.  Mean training acc: 96.10%.
[ Wed Dec  3 15:42:13 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:42:13 2025 ] 	Time consumption: [Data]11%, [Network]87%
[ Wed Dec  3 15:42:13 2025 ] Training epoch: 400
[ Wed Dec  3 15:45:02 2025 ] 	Mean training loss: 0.8577.  Mean training acc: 96.41%.
[ Wed Dec  3 15:45:02 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:45:02 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:45:02 2025 ] Training epoch: 401
[ Wed Dec  3 15:47:40 2025 ] 	Mean training loss: 0.8586.  Mean training acc: 96.27%.
[ Wed Dec  3 15:47:40 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:47:40 2025 ] 	Time consumption: [Data]11%, [Network]87%
[ Wed Dec  3 15:47:40 2025 ] Training epoch: 402
[ Wed Dec  3 15:50:29 2025 ] 	Mean training loss: 0.8558.  Mean training acc: 96.40%.
[ Wed Dec  3 15:50:29 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:50:29 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:50:29 2025 ] Training epoch: 403
[ Wed Dec  3 15:53:06 2025 ] 	Mean training loss: 0.8524.  Mean training acc: 96.67%.
[ Wed Dec  3 15:53:06 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:53:06 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:53:06 2025 ] Training epoch: 404
[ Wed Dec  3 15:55:53 2025 ] 	Mean training loss: 0.8515.  Mean training acc: 96.66%.
[ Wed Dec  3 15:55:53 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:55:53 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:55:53 2025 ] Training epoch: 405
[ Wed Dec  3 15:58:32 2025 ] 	Mean training loss: 0.8600.  Mean training acc: 96.23%.
[ Wed Dec  3 15:58:32 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 15:58:32 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 15:58:32 2025 ] Training epoch: 406
[ Wed Dec  3 16:01:17 2025 ] 	Mean training loss: 0.8508.  Mean training acc: 96.46%.
[ Wed Dec  3 16:01:17 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:01:17 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:01:17 2025 ] Training epoch: 407
[ Wed Dec  3 16:03:59 2025 ] 	Mean training loss: 0.8493.  Mean training acc: 96.66%.
[ Wed Dec  3 16:03:59 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:03:59 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:03:59 2025 ] Training epoch: 408
[ Wed Dec  3 16:06:41 2025 ] 	Mean training loss: 0.8528.  Mean training acc: 96.81%.
[ Wed Dec  3 16:06:41 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:06:41 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:06:41 2025 ] Training epoch: 409
[ Wed Dec  3 16:09:25 2025 ] 	Mean training loss: 0.8407.  Mean training acc: 96.88%.
[ Wed Dec  3 16:09:25 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:09:25 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:09:25 2025 ] Training epoch: 410
[ Wed Dec  3 16:12:05 2025 ] 	Mean training loss: 0.8419.  Mean training acc: 96.84%.
[ Wed Dec  3 16:12:05 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:12:05 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:12:05 2025 ] Training epoch: 411
[ Wed Dec  3 16:14:51 2025 ] 	Mean training loss: 0.8516.  Mean training acc: 96.46%.
[ Wed Dec  3 16:14:51 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:14:51 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:14:51 2025 ] Training epoch: 412
[ Wed Dec  3 16:17:29 2025 ] 	Mean training loss: 0.8459.  Mean training acc: 96.63%.
[ Wed Dec  3 16:17:29 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:17:29 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:17:29 2025 ] Training epoch: 413
[ Wed Dec  3 16:20:17 2025 ] 	Mean training loss: 0.8452.  Mean training acc: 96.76%.
[ Wed Dec  3 16:20:17 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:20:17 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:20:17 2025 ] Training epoch: 414
[ Wed Dec  3 16:22:54 2025 ] 	Mean training loss: 0.8453.  Mean training acc: 96.83%.
[ Wed Dec  3 16:22:54 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:22:54 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:22:54 2025 ] Training epoch: 415
[ Wed Dec  3 16:25:44 2025 ] 	Mean training loss: 0.8384.  Mean training acc: 96.94%.
[ Wed Dec  3 16:25:44 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:25:44 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:25:44 2025 ] Training epoch: 416
[ Wed Dec  3 16:28:21 2025 ] 	Mean training loss: 0.8393.  Mean training acc: 97.06%.
[ Wed Dec  3 16:28:21 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:28:21 2025 ] 	Time consumption: [Data]11%, [Network]87%
[ Wed Dec  3 16:28:21 2025 ] Training epoch: 417
[ Wed Dec  3 16:31:08 2025 ] 	Mean training loss: 0.8373.  Mean training acc: 97.03%.
[ Wed Dec  3 16:31:08 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:31:08 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:31:08 2025 ] Training epoch: 418
[ Wed Dec  3 16:33:47 2025 ] 	Mean training loss: 0.8378.  Mean training acc: 96.95%.
[ Wed Dec  3 16:33:47 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:33:47 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:33:47 2025 ] Training epoch: 419
[ Wed Dec  3 16:36:32 2025 ] 	Mean training loss: 0.8361.  Mean training acc: 97.24%.
[ Wed Dec  3 16:36:32 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:36:32 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:36:32 2025 ] Training epoch: 420
[ Wed Dec  3 16:39:14 2025 ] 	Mean training loss: 0.8417.  Mean training acc: 96.81%.
[ Wed Dec  3 16:39:14 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:39:14 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:39:14 2025 ] Training epoch: 421
[ Wed Dec  3 16:41:56 2025 ] 	Mean training loss: 0.8377.  Mean training acc: 97.03%.
[ Wed Dec  3 16:41:56 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:41:56 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:41:56 2025 ] Training epoch: 422
[ Wed Dec  3 16:44:39 2025 ] 	Mean training loss: 0.8422.  Mean training acc: 96.89%.
[ Wed Dec  3 16:44:39 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:44:39 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:44:39 2025 ] Training epoch: 423
[ Wed Dec  3 16:47:20 2025 ] 	Mean training loss: 0.8285.  Mean training acc: 97.30%.
[ Wed Dec  3 16:47:20 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:47:20 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:47:20 2025 ] Training epoch: 424
[ Wed Dec  3 16:50:06 2025 ] 	Mean training loss: 0.8312.  Mean training acc: 97.16%.
[ Wed Dec  3 16:50:06 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:50:06 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:50:06 2025 ] Training epoch: 425
[ Wed Dec  3 16:52:44 2025 ] 	Mean training loss: 0.8337.  Mean training acc: 97.15%.
[ Wed Dec  3 16:52:44 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:52:44 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:52:44 2025 ] Training epoch: 426
[ Wed Dec  3 16:55:22 2025 ] 	Mean training loss: 0.8317.  Mean training acc: 97.22%.
[ Wed Dec  3 16:55:22 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:55:22 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:55:22 2025 ] Training epoch: 427
[ Wed Dec  3 16:57:57 2025 ] 	Mean training loss: 0.8284.  Mean training acc: 97.34%.
[ Wed Dec  3 16:57:57 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 16:57:57 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:57:57 2025 ] Training epoch: 428
[ Wed Dec  3 17:00:38 2025 ] 	Mean training loss: 0.8319.  Mean training acc: 97.29%.
[ Wed Dec  3 17:00:38 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 17:00:38 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:00:38 2025 ] Training epoch: 429
[ Wed Dec  3 17:03:11 2025 ] 	Mean training loss: 0.8297.  Mean training acc: 97.25%.
[ Wed Dec  3 17:03:11 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 17:03:11 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 17:03:11 2025 ] Training epoch: 430
[ Wed Dec  3 17:05:54 2025 ] 	Mean training loss: 0.8306.  Mean training acc: 97.12%.
[ Wed Dec  3 17:05:54 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 17:05:54 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:05:54 2025 ] Training epoch: 431
[ Wed Dec  3 17:08:26 2025 ] 	Mean training loss: 0.8313.  Mean training acc: 97.06%.
[ Wed Dec  3 17:08:26 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 17:08:26 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 17:08:26 2025 ] Training epoch: 432
[ Wed Dec  3 17:11:11 2025 ] 	Mean training loss: 0.8242.  Mean training acc: 97.43%.
[ Wed Dec  3 17:11:11 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 17:11:11 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:11:11 2025 ] Training epoch: 433
[ Wed Dec  3 17:13:43 2025 ] 	Mean training loss: 0.8282.  Mean training acc: 97.31%.
[ Wed Dec  3 17:13:43 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 17:13:43 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 17:13:43 2025 ] Training epoch: 434
[ Wed Dec  3 17:16:28 2025 ] 	Mean training loss: 0.8231.  Mean training acc: 97.41%.
[ Wed Dec  3 17:16:28 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 17:16:28 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:16:28 2025 ] Training epoch: 435
[ Wed Dec  3 17:19:01 2025 ] 	Mean training loss: 0.8189.  Mean training acc: 97.59%.
[ Wed Dec  3 17:19:01 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 17:19:01 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 17:19:01 2025 ] Training epoch: 436
[ Wed Dec  3 17:21:43 2025 ] 	Mean training loss: 0.8204.  Mean training acc: 97.71%.
[ Wed Dec  3 17:21:43 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:21:43 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:21:43 2025 ] Training epoch: 437
[ Wed Dec  3 17:24:21 2025 ] 	Mean training loss: 0.8214.  Mean training acc: 97.44%.
[ Wed Dec  3 17:24:21 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:24:21 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:24:21 2025 ] Training epoch: 438
[ Wed Dec  3 17:27:02 2025 ] 	Mean training loss: 0.8196.  Mean training acc: 97.68%.
[ Wed Dec  3 17:27:02 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:27:02 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:27:02 2025 ] Training epoch: 439
[ Wed Dec  3 17:29:41 2025 ] 	Mean training loss: 0.8222.  Mean training acc: 97.31%.
[ Wed Dec  3 17:29:41 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:29:41 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:29:41 2025 ] Training epoch: 440
[ Wed Dec  3 17:32:20 2025 ] 	Mean training loss: 0.8195.  Mean training acc: 97.72%.
[ Wed Dec  3 17:32:20 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:32:20 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:32:20 2025 ] Training epoch: 441
[ Wed Dec  3 17:35:01 2025 ] 	Mean training loss: 0.8192.  Mean training acc: 97.59%.
[ Wed Dec  3 17:35:01 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:35:01 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:35:01 2025 ] Training epoch: 442
[ Wed Dec  3 17:37:37 2025 ] 	Mean training loss: 0.8168.  Mean training acc: 97.54%.
[ Wed Dec  3 17:37:37 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:37:37 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:37:37 2025 ] Training epoch: 443
[ Wed Dec  3 17:40:21 2025 ] 	Mean training loss: 0.8150.  Mean training acc: 97.71%.
[ Wed Dec  3 17:40:21 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:40:21 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:40:21 2025 ] Training epoch: 444
[ Wed Dec  3 17:42:54 2025 ] 	Mean training loss: 0.8142.  Mean training acc: 97.65%.
[ Wed Dec  3 17:42:54 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:42:54 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 17:42:54 2025 ] Training epoch: 445
[ Wed Dec  3 17:45:40 2025 ] 	Mean training loss: 0.8112.  Mean training acc: 97.81%.
[ Wed Dec  3 17:45:40 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:45:40 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:45:40 2025 ] Training epoch: 446
[ Wed Dec  3 17:48:11 2025 ] 	Mean training loss: 0.8134.  Mean training acc: 97.77%.
[ Wed Dec  3 17:48:11 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:48:11 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 17:48:11 2025 ] Training epoch: 447
[ Wed Dec  3 17:50:56 2025 ] 	Mean training loss: 0.8115.  Mean training acc: 97.94%.
[ Wed Dec  3 17:50:56 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:50:56 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 17:50:56 2025 ] Training epoch: 448
[ Wed Dec  3 17:53:28 2025 ] 	Mean training loss: 0.8144.  Mean training acc: 97.65%.
[ Wed Dec  3 17:53:28 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:53:28 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 17:53:28 2025 ] Training epoch: 449
[ Wed Dec  3 17:56:12 2025 ] 	Mean training loss: 0.8182.  Mean training acc: 97.53%.
[ Wed Dec  3 17:56:12 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:56:12 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:56:12 2025 ] Training epoch: 450
[ Wed Dec  3 17:58:45 2025 ] 	Mean training loss: 0.8116.  Mean training acc: 97.65%.
[ Wed Dec  3 17:58:45 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:58:45 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 17:58:45 2025 ] Eval epoch: 450
[ Wed Dec  3 18:01:48 2025 ] 	Mean test loss of 1355 batches: 1.2096683792082585.
[ Wed Dec  3 18:01:48 2025 ] 	Top1: 85.06%
[ Wed Dec  3 18:01:48 2025 ] 	Top5: 96.66%
[ Wed Dec  3 18:01:48 2025 ] Training epoch: 451
[ Wed Dec  3 18:04:22 2025 ] 	Mean training loss: 0.8104.  Mean training acc: 97.88%.
[ Wed Dec  3 18:04:22 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:04:22 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:04:22 2025 ] Eval epoch: 451
[ Wed Dec  3 18:07:24 2025 ] 	Mean test loss of 1355 batches: 1.2000954164790052.
[ Wed Dec  3 18:07:24 2025 ] 	Top1: 85.35%
[ Wed Dec  3 18:07:24 2025 ] 	Top5: 96.67%
[ Wed Dec  3 18:07:24 2025 ] Training epoch: 452
[ Wed Dec  3 18:09:58 2025 ] 	Mean training loss: 0.8107.  Mean training acc: 97.74%.
[ Wed Dec  3 18:09:58 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:09:58 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:09:58 2025 ] Eval epoch: 452
[ Wed Dec  3 18:12:59 2025 ] 	Mean test loss of 1355 batches: 1.1982727563689115.
[ Wed Dec  3 18:12:59 2025 ] 	Top1: 85.43%
[ Wed Dec  3 18:12:59 2025 ] 	Top5: 96.62%
[ Wed Dec  3 18:13:00 2025 ] Training epoch: 453
[ Wed Dec  3 18:15:33 2025 ] 	Mean training loss: 0.8105.  Mean training acc: 97.77%.
[ Wed Dec  3 18:15:33 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:15:33 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:15:33 2025 ] Eval epoch: 453
[ Wed Dec  3 18:18:33 2025 ] 	Mean test loss of 1355 batches: 1.2052123627979376.
[ Wed Dec  3 18:18:33 2025 ] 	Top1: 85.11%
[ Wed Dec  3 18:18:33 2025 ] 	Top5: 96.64%
[ Wed Dec  3 18:18:34 2025 ] Training epoch: 454
[ Wed Dec  3 18:21:08 2025 ] 	Mean training loss: 0.8142.  Mean training acc: 97.59%.
[ Wed Dec  3 18:21:08 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:21:08 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:21:08 2025 ] Eval epoch: 454
[ Wed Dec  3 18:24:06 2025 ] 	Mean test loss of 1355 batches: 1.2097610749001872.
[ Wed Dec  3 18:24:06 2025 ] 	Top1: 85.05%
[ Wed Dec  3 18:24:06 2025 ] 	Top5: 96.71%
[ Wed Dec  3 18:24:06 2025 ] Training epoch: 455
[ Wed Dec  3 18:26:42 2025 ] 	Mean training loss: 0.8023.  Mean training acc: 98.03%.
[ Wed Dec  3 18:26:42 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:26:42 2025 ] 	Time consumption: [Data]11%, [Network]87%
[ Wed Dec  3 18:26:42 2025 ] Eval epoch: 455
[ Wed Dec  3 18:29:38 2025 ] 	Mean test loss of 1355 batches: 1.19616600231051.
[ Wed Dec  3 18:29:38 2025 ] 	Top1: 85.45%
[ Wed Dec  3 18:29:38 2025 ] 	Top5: 96.70%
[ Wed Dec  3 18:29:38 2025 ] Training epoch: 456
[ Wed Dec  3 18:32:14 2025 ] 	Mean training loss: 0.8082.  Mean training acc: 97.96%.
[ Wed Dec  3 18:32:14 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:32:14 2025 ] 	Time consumption: [Data]11%, [Network]87%
[ Wed Dec  3 18:32:14 2025 ] Eval epoch: 456
[ Wed Dec  3 18:35:10 2025 ] 	Mean test loss of 1355 batches: 1.205064185651026.
[ Wed Dec  3 18:35:10 2025 ] 	Top1: 85.26%
[ Wed Dec  3 18:35:10 2025 ] 	Top5: 96.68%
[ Wed Dec  3 18:35:11 2025 ] Training epoch: 457
[ Wed Dec  3 18:37:47 2025 ] 	Mean training loss: 0.8071.  Mean training acc: 98.09%.
[ Wed Dec  3 18:37:47 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:37:47 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:37:47 2025 ] Eval epoch: 457
[ Wed Dec  3 18:40:41 2025 ] 	Mean test loss of 1355 batches: 1.1977208355256113.
[ Wed Dec  3 18:40:42 2025 ] 	Top1: 85.51%
[ Wed Dec  3 18:40:42 2025 ] 	Top5: 96.71%
[ Wed Dec  3 18:40:42 2025 ] Training epoch: 458
[ Wed Dec  3 18:43:19 2025 ] 	Mean training loss: 0.8101.  Mean training acc: 97.93%.
[ Wed Dec  3 18:43:19 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:43:19 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:43:19 2025 ] Eval epoch: 458
[ Wed Dec  3 18:46:12 2025 ] 	Mean test loss of 1355 batches: 1.1954655005923056.
[ Wed Dec  3 18:46:12 2025 ] 	Top1: 85.51%
[ Wed Dec  3 18:46:12 2025 ] 	Top5: 96.78%
[ Wed Dec  3 18:46:12 2025 ] Training epoch: 459
[ Wed Dec  3 18:48:52 2025 ] 	Mean training loss: 0.8096.  Mean training acc: 97.84%.
[ Wed Dec  3 18:48:52 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:48:52 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:48:52 2025 ] Eval epoch: 459
[ Wed Dec  3 18:51:43 2025 ] 	Mean test loss of 1355 batches: 1.1978186653548941.
[ Wed Dec  3 18:51:44 2025 ] 	Top1: 85.35%
[ Wed Dec  3 18:51:44 2025 ] 	Top5: 96.74%
[ Wed Dec  3 18:51:44 2025 ] Training epoch: 460
[ Wed Dec  3 18:54:25 2025 ] 	Mean training loss: 0.8051.  Mean training acc: 97.98%.
[ Wed Dec  3 18:54:25 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:54:25 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:54:25 2025 ] Eval epoch: 460
[ Wed Dec  3 18:57:16 2025 ] 	Mean test loss of 1355 batches: 1.205407975784527.
[ Wed Dec  3 18:57:16 2025 ] 	Top1: 85.17%
[ Wed Dec  3 18:57:16 2025 ] 	Top5: 96.74%
[ Wed Dec  3 18:57:16 2025 ] Training epoch: 461
[ Wed Dec  3 18:59:59 2025 ] 	Mean training loss: 0.8033.  Mean training acc: 98.12%.
[ Wed Dec  3 18:59:59 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:59:59 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:59:59 2025 ] Eval epoch: 461
[ Wed Dec  3 19:02:47 2025 ] 	Mean test loss of 1355 batches: 1.2116600662579835.
[ Wed Dec  3 19:02:47 2025 ] 	Top1: 85.07%
[ Wed Dec  3 19:02:48 2025 ] 	Top5: 96.68%
[ Wed Dec  3 19:02:48 2025 ] Training epoch: 462
[ Wed Dec  3 19:05:32 2025 ] 	Mean training loss: 0.8075.  Mean training acc: 97.89%.
[ Wed Dec  3 19:05:32 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:05:32 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 19:05:32 2025 ] Eval epoch: 462
[ Wed Dec  3 19:08:21 2025 ] 	Mean test loss of 1355 batches: 1.199782824164387.
[ Wed Dec  3 19:08:21 2025 ] 	Top1: 85.35%
[ Wed Dec  3 19:08:21 2025 ] 	Top5: 96.80%
[ Wed Dec  3 19:08:21 2025 ] Training epoch: 463
[ Wed Dec  3 19:10:56 2025 ] 	Mean training loss: 0.8064.  Mean training acc: 98.12%.
[ Wed Dec  3 19:10:56 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:10:56 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 19:10:56 2025 ] Eval epoch: 463
[ Wed Dec  3 19:13:05 2025 ] 	Mean test loss of 1355 batches: 1.2078677982861705.
[ Wed Dec  3 19:13:05 2025 ] 	Top1: 85.21%
[ Wed Dec  3 19:13:05 2025 ] 	Top5: 96.68%
[ Wed Dec  3 19:13:05 2025 ] Training epoch: 464
[ Wed Dec  3 19:14:57 2025 ] 	Mean training loss: 0.8018.  Mean training acc: 98.22%.
[ Wed Dec  3 19:14:57 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:14:57 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:14:57 2025 ] Eval epoch: 464
[ Wed Dec  3 19:16:56 2025 ] 	Mean test loss of 1355 batches: 1.1983906651774896.
[ Wed Dec  3 19:16:56 2025 ] 	Top1: 85.33%
[ Wed Dec  3 19:16:56 2025 ] 	Top5: 96.85%
[ Wed Dec  3 19:16:56 2025 ] Training epoch: 465
[ Wed Dec  3 19:18:47 2025 ] 	Mean training loss: 0.8058.  Mean training acc: 97.87%.
[ Wed Dec  3 19:18:47 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:18:47 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:18:47 2025 ] Eval epoch: 465
[ Wed Dec  3 19:20:44 2025 ] 	Mean test loss of 1355 batches: 1.2046878868803328.
[ Wed Dec  3 19:20:45 2025 ] 	Top1: 85.22%
[ Wed Dec  3 19:20:45 2025 ] 	Top5: 96.70%
[ Wed Dec  3 19:20:45 2025 ] Training epoch: 466
[ Wed Dec  3 19:22:36 2025 ] 	Mean training loss: 0.8040.  Mean training acc: 98.12%.
[ Wed Dec  3 19:22:36 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:22:36 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:22:36 2025 ] Eval epoch: 466
[ Wed Dec  3 19:24:35 2025 ] 	Mean test loss of 1355 batches: 1.1993809048979924.
[ Wed Dec  3 19:24:36 2025 ] 	Top1: 85.42%
[ Wed Dec  3 19:24:36 2025 ] 	Top5: 96.65%
[ Wed Dec  3 19:24:36 2025 ] Training epoch: 467
[ Wed Dec  3 19:26:27 2025 ] 	Mean training loss: 0.8012.  Mean training acc: 98.11%.
[ Wed Dec  3 19:26:27 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:26:27 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:26:27 2025 ] Eval epoch: 467
[ Wed Dec  3 19:28:26 2025 ] 	Mean test loss of 1355 batches: 1.1939049128236805.
[ Wed Dec  3 19:28:26 2025 ] 	Top1: 85.56%
[ Wed Dec  3 19:28:27 2025 ] 	Top5: 96.79%
[ Wed Dec  3 19:28:27 2025 ] Training epoch: 468
[ Wed Dec  3 19:30:17 2025 ] 	Mean training loss: 0.8014.  Mean training acc: 98.14%.
[ Wed Dec  3 19:30:17 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:30:17 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:30:18 2025 ] Eval epoch: 468
[ Wed Dec  3 19:32:14 2025 ] 	Mean test loss of 1355 batches: 1.2041297154233024.
[ Wed Dec  3 19:32:14 2025 ] 	Top1: 85.17%
[ Wed Dec  3 19:32:15 2025 ] 	Top5: 96.70%
[ Wed Dec  3 19:32:15 2025 ] Training epoch: 469
[ Wed Dec  3 19:34:06 2025 ] 	Mean training loss: 0.8039.  Mean training acc: 98.02%.
[ Wed Dec  3 19:34:06 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:34:06 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:34:06 2025 ] Eval epoch: 469
[ Wed Dec  3 19:36:04 2025 ] 	Mean test loss of 1355 batches: 1.2076204473681995.
[ Wed Dec  3 19:36:04 2025 ] 	Top1: 85.12%
[ Wed Dec  3 19:36:04 2025 ] 	Top5: 96.71%
[ Wed Dec  3 19:36:04 2025 ] Training epoch: 470
[ Wed Dec  3 19:37:55 2025 ] 	Mean training loss: 0.8025.  Mean training acc: 98.22%.
[ Wed Dec  3 19:37:55 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:37:55 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:37:55 2025 ] Eval epoch: 470
[ Wed Dec  3 19:39:52 2025 ] 	Mean test loss of 1355 batches: 1.1991953446856285.
[ Wed Dec  3 19:39:52 2025 ] 	Top1: 85.42%
[ Wed Dec  3 19:39:52 2025 ] 	Top5: 96.76%
[ Wed Dec  3 19:39:52 2025 ] Training epoch: 471
[ Wed Dec  3 19:41:44 2025 ] 	Mean training loss: 0.8026.  Mean training acc: 98.03%.
[ Wed Dec  3 19:41:44 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:41:44 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:41:44 2025 ] Eval epoch: 471
[ Wed Dec  3 19:43:41 2025 ] 	Mean test loss of 1355 batches: 1.2062901597621256.
[ Wed Dec  3 19:43:42 2025 ] 	Top1: 85.20%
[ Wed Dec  3 19:43:42 2025 ] 	Top5: 96.65%
[ Wed Dec  3 19:43:42 2025 ] Training epoch: 472
[ Wed Dec  3 19:45:33 2025 ] 	Mean training loss: 0.8009.  Mean training acc: 98.09%.
[ Wed Dec  3 19:45:33 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:45:33 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:45:33 2025 ] Eval epoch: 472
[ Wed Dec  3 19:47:31 2025 ] 	Mean test loss of 1355 batches: 1.2019820271382913.
[ Wed Dec  3 19:47:31 2025 ] 	Top1: 85.30%
[ Wed Dec  3 19:47:31 2025 ] 	Top5: 96.67%
[ Wed Dec  3 19:47:32 2025 ] Training epoch: 473
[ Wed Dec  3 19:49:23 2025 ] 	Mean training loss: 0.7976.  Mean training acc: 98.35%.
[ Wed Dec  3 19:49:24 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:49:24 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:49:24 2025 ] Eval epoch: 473
[ Wed Dec  3 19:51:20 2025 ] 	Mean test loss of 1355 batches: 1.2018466909433203.
[ Wed Dec  3 19:51:20 2025 ] 	Top1: 85.23%
[ Wed Dec  3 19:51:20 2025 ] 	Top5: 96.64%
[ Wed Dec  3 19:51:20 2025 ] Training epoch: 474
[ Wed Dec  3 19:53:14 2025 ] 	Mean training loss: 0.8007.  Mean training acc: 98.24%.
[ Wed Dec  3 19:53:14 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:53:14 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:53:14 2025 ] Eval epoch: 474
[ Wed Dec  3 19:55:09 2025 ] 	Mean test loss of 1355 batches: 1.2054924158592506.
[ Wed Dec  3 19:55:09 2025 ] 	Top1: 85.13%
[ Wed Dec  3 19:55:09 2025 ] 	Top5: 96.74%
[ Wed Dec  3 19:55:09 2025 ] Training epoch: 475
[ Wed Dec  3 19:57:02 2025 ] 	Mean training loss: 0.7996.  Mean training acc: 98.24%.
[ Wed Dec  3 19:57:02 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:57:02 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 19:57:02 2025 ] Eval epoch: 475
[ Wed Dec  3 19:58:58 2025 ] 	Mean test loss of 1355 batches: 1.1995293041436874.
[ Wed Dec  3 19:58:58 2025 ] 	Top1: 85.44%
[ Wed Dec  3 19:58:59 2025 ] 	Top5: 96.70%
[ Wed Dec  3 19:58:59 2025 ] Training epoch: 476
[ Wed Dec  3 20:00:51 2025 ] 	Mean training loss: 0.7994.  Mean training acc: 98.15%.
[ Wed Dec  3 20:00:51 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:00:51 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:00:51 2025 ] Eval epoch: 476
[ Wed Dec  3 20:02:47 2025 ] 	Mean test loss of 1355 batches: 1.1956301108937422.
[ Wed Dec  3 20:02:47 2025 ] 	Top1: 85.50%
[ Wed Dec  3 20:02:47 2025 ] 	Top5: 96.77%
[ Wed Dec  3 20:02:48 2025 ] Training epoch: 477
[ Wed Dec  3 20:04:39 2025 ] 	Mean training loss: 0.8052.  Mean training acc: 98.03%.
[ Wed Dec  3 20:04:39 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:04:39 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:04:39 2025 ] Eval epoch: 477
[ Wed Dec  3 20:06:35 2025 ] 	Mean test loss of 1355 batches: 1.1986131229083916.
[ Wed Dec  3 20:06:35 2025 ] 	Top1: 85.36%
[ Wed Dec  3 20:06:35 2025 ] 	Top5: 96.75%
[ Wed Dec  3 20:06:35 2025 ] Training epoch: 478
[ Wed Dec  3 20:08:27 2025 ] 	Mean training loss: 0.8008.  Mean training acc: 98.17%.
[ Wed Dec  3 20:08:27 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:08:27 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:08:27 2025 ] Eval epoch: 478
[ Wed Dec  3 20:10:23 2025 ] 	Mean test loss of 1355 batches: 1.1948699425507296.
[ Wed Dec  3 20:10:23 2025 ] 	Top1: 85.59%
[ Wed Dec  3 20:10:23 2025 ] 	Top5: 96.74%
[ Wed Dec  3 20:10:23 2025 ] Training epoch: 479
[ Wed Dec  3 20:12:14 2025 ] 	Mean training loss: 0.7985.  Mean training acc: 98.21%.
[ Wed Dec  3 20:12:14 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:12:14 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:12:14 2025 ] Eval epoch: 479
[ Wed Dec  3 20:14:09 2025 ] 	Mean test loss of 1355 batches: 1.194102558746549.
[ Wed Dec  3 20:14:09 2025 ] 	Top1: 85.53%
[ Wed Dec  3 20:14:09 2025 ] 	Top5: 96.70%
[ Wed Dec  3 20:14:09 2025 ] Training epoch: 480
[ Wed Dec  3 20:16:02 2025 ] 	Mean training loss: 0.7987.  Mean training acc: 98.14%.
[ Wed Dec  3 20:16:02 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:16:02 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:16:03 2025 ] Eval epoch: 480
[ Wed Dec  3 20:17:57 2025 ] 	Mean test loss of 1355 batches: 1.2003192591051335.
[ Wed Dec  3 20:17:57 2025 ] 	Top1: 85.43%
[ Wed Dec  3 20:17:58 2025 ] 	Top5: 96.63%
[ Wed Dec  3 20:17:58 2025 ] Training epoch: 481
[ Wed Dec  3 20:19:52 2025 ] 	Mean training loss: 0.7974.  Mean training acc: 98.32%.
[ Wed Dec  3 20:19:52 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:19:52 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:19:52 2025 ] Eval epoch: 481
[ Wed Dec  3 20:21:48 2025 ] 	Mean test loss of 1355 batches: 1.1988468672076715.
[ Wed Dec  3 20:21:48 2025 ] 	Top1: 85.36%
[ Wed Dec  3 20:21:49 2025 ] 	Top5: 96.71%
[ Wed Dec  3 20:21:49 2025 ] Training epoch: 482
[ Wed Dec  3 20:23:41 2025 ] 	Mean training loss: 0.7939.  Mean training acc: 98.32%.
[ Wed Dec  3 20:23:41 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:23:41 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:23:41 2025 ] Eval epoch: 482
[ Wed Dec  3 20:25:35 2025 ] 	Mean test loss of 1355 batches: 1.194250171078967.
[ Wed Dec  3 20:25:35 2025 ] 	Top1: 85.47%
[ Wed Dec  3 20:25:35 2025 ] 	Top5: 96.68%
[ Wed Dec  3 20:25:35 2025 ] Training epoch: 483
[ Wed Dec  3 20:27:29 2025 ] 	Mean training loss: 0.7991.  Mean training acc: 98.17%.
[ Wed Dec  3 20:27:29 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:27:29 2025 ] 	Time consumption: [Data]14%, [Network]86%
[ Wed Dec  3 20:27:29 2025 ] Eval epoch: 483
[ Wed Dec  3 20:29:25 2025 ] 	Mean test loss of 1355 batches: 1.1991199799129444.
[ Wed Dec  3 20:29:25 2025 ] 	Top1: 85.32%
[ Wed Dec  3 20:29:25 2025 ] 	Top5: 96.73%
[ Wed Dec  3 20:29:25 2025 ] Training epoch: 484
[ Wed Dec  3 20:31:18 2025 ] 	Mean training loss: 0.7981.  Mean training acc: 98.17%.
[ Wed Dec  3 20:31:18 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:31:18 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:31:18 2025 ] Eval epoch: 484
[ Wed Dec  3 20:33:15 2025 ] 	Mean test loss of 1355 batches: 1.2000007541417195.
[ Wed Dec  3 20:33:15 2025 ] 	Top1: 85.39%
[ Wed Dec  3 20:33:15 2025 ] 	Top5: 96.74%
[ Wed Dec  3 20:33:16 2025 ] Training epoch: 485
[ Wed Dec  3 20:35:08 2025 ] 	Mean training loss: 0.7965.  Mean training acc: 98.21%.
[ Wed Dec  3 20:35:08 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:35:08 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:35:08 2025 ] Eval epoch: 485
[ Wed Dec  3 20:37:05 2025 ] 	Mean test loss of 1355 batches: 1.2006822904097638.
[ Wed Dec  3 20:37:05 2025 ] 	Top1: 85.44%
[ Wed Dec  3 20:37:05 2025 ] 	Top5: 96.66%
[ Wed Dec  3 20:37:05 2025 ] Training epoch: 486
[ Wed Dec  3 20:38:58 2025 ] 	Mean training loss: 0.7941.  Mean training acc: 98.34%.
[ Wed Dec  3 20:38:58 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:38:58 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:38:58 2025 ] Eval epoch: 486
[ Wed Dec  3 20:40:51 2025 ] 	Mean test loss of 1355 batches: 1.202000343931557.
[ Wed Dec  3 20:40:51 2025 ] 	Top1: 85.39%
[ Wed Dec  3 20:40:51 2025 ] 	Top5: 96.65%
[ Wed Dec  3 20:40:51 2025 ] Training epoch: 487
[ Wed Dec  3 20:42:43 2025 ] 	Mean training loss: 0.7987.  Mean training acc: 98.23%.
[ Wed Dec  3 20:42:43 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:42:43 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:42:43 2025 ] Eval epoch: 487
[ Wed Dec  3 20:44:38 2025 ] 	Mean test loss of 1355 batches: 1.1974980193750444.
[ Wed Dec  3 20:44:39 2025 ] 	Top1: 85.50%
[ Wed Dec  3 20:44:39 2025 ] 	Top5: 96.66%
[ Wed Dec  3 20:44:39 2025 ] Training epoch: 488
[ Wed Dec  3 20:46:34 2025 ] 	Mean training loss: 0.7973.  Mean training acc: 98.25%.
[ Wed Dec  3 20:46:34 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:46:34 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:46:34 2025 ] Eval epoch: 488
[ Wed Dec  3 20:48:29 2025 ] 	Mean test loss of 1355 batches: 1.202686277130873.
[ Wed Dec  3 20:48:29 2025 ] 	Top1: 85.34%
[ Wed Dec  3 20:48:30 2025 ] 	Top5: 96.58%
[ Wed Dec  3 20:48:30 2025 ] Training epoch: 489
[ Wed Dec  3 20:50:23 2025 ] 	Mean training loss: 0.7924.  Mean training acc: 98.40%.
[ Wed Dec  3 20:50:23 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:50:23 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:50:23 2025 ] Eval epoch: 489
[ Wed Dec  3 20:52:13 2025 ] 	Mean test loss of 1355 batches: 1.1996169992478571.
[ Wed Dec  3 20:52:13 2025 ] 	Top1: 85.41%
[ Wed Dec  3 20:52:14 2025 ] 	Top5: 96.65%
[ Wed Dec  3 20:52:14 2025 ] Training epoch: 490
[ Wed Dec  3 20:53:59 2025 ] 	Mean training loss: 0.7935.  Mean training acc: 98.46%.
[ Wed Dec  3 20:53:59 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:53:59 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Wed Dec  3 20:53:59 2025 ] Eval epoch: 490
[ Wed Dec  3 20:55:21 2025 ] 	Mean test loss of 1355 batches: 1.2012250844402947.
[ Wed Dec  3 20:55:21 2025 ] 	Top1: 85.39%
[ Wed Dec  3 20:55:21 2025 ] 	Top5: 96.68%
[ Wed Dec  3 20:55:21 2025 ] Training epoch: 491
[ Wed Dec  3 20:56:26 2025 ] 	Mean training loss: 0.7974.  Mean training acc: 98.20%.
[ Wed Dec  3 20:56:26 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:56:26 2025 ] 	Time consumption: [Data]19%, [Network]80%
[ Wed Dec  3 20:56:26 2025 ] Eval epoch: 491
[ Wed Dec  3 20:57:42 2025 ] 	Mean test loss of 1355 batches: 1.19975015422075.
[ Wed Dec  3 20:57:42 2025 ] 	Top1: 85.50%
[ Wed Dec  3 20:57:42 2025 ] 	Top5: 96.68%
[ Wed Dec  3 20:57:42 2025 ] Training epoch: 492
[ Wed Dec  3 20:58:48 2025 ] 	Mean training loss: 0.7959.  Mean training acc: 98.24%.
[ Wed Dec  3 20:58:48 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 20:58:48 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 20:58:48 2025 ] Eval epoch: 492
[ Wed Dec  3 21:00:03 2025 ] 	Mean test loss of 1355 batches: 1.1943473423099167.
[ Wed Dec  3 21:00:03 2025 ] 	Top1: 85.57%
[ Wed Dec  3 21:00:03 2025 ] 	Top5: 96.72%
[ Wed Dec  3 21:00:03 2025 ] Training epoch: 493
[ Wed Dec  3 21:01:08 2025 ] 	Mean training loss: 0.7997.  Mean training acc: 98.31%.
[ Wed Dec  3 21:01:08 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 21:01:08 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 21:01:08 2025 ] Eval epoch: 493
[ Wed Dec  3 21:02:23 2025 ] 	Mean test loss of 1355 batches: 1.2027781340028967.
[ Wed Dec  3 21:02:23 2025 ] 	Top1: 85.35%
[ Wed Dec  3 21:02:23 2025 ] 	Top5: 96.59%
[ Wed Dec  3 21:02:23 2025 ] Training epoch: 494
[ Wed Dec  3 21:03:30 2025 ] 	Mean training loss: 0.7981.  Mean training acc: 98.30%.
[ Wed Dec  3 21:03:30 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 21:03:30 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 21:03:30 2025 ] Eval epoch: 494
[ Wed Dec  3 21:04:45 2025 ] 	Mean test loss of 1355 batches: 1.1974639914132572.
[ Wed Dec  3 21:04:45 2025 ] 	Top1: 85.52%
[ Wed Dec  3 21:04:45 2025 ] 	Top5: 96.65%
[ Wed Dec  3 21:04:45 2025 ] Training epoch: 495
[ Wed Dec  3 21:05:51 2025 ] 	Mean training loss: 0.7937.  Mean training acc: 98.42%.
[ Wed Dec  3 21:05:51 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 21:05:51 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 21:05:51 2025 ] Eval epoch: 495
[ Wed Dec  3 21:07:06 2025 ] 	Mean test loss of 1355 batches: 1.196796780670701.
[ Wed Dec  3 21:07:06 2025 ] 	Top1: 85.52%
[ Wed Dec  3 21:07:06 2025 ] 	Top5: 96.72%
[ Wed Dec  3 21:07:06 2025 ] Training epoch: 496
[ Wed Dec  3 21:08:11 2025 ] 	Mean training loss: 0.7946.  Mean training acc: 98.37%.
[ Wed Dec  3 21:08:11 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 21:08:11 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 21:08:11 2025 ] Eval epoch: 496
[ Wed Dec  3 21:09:26 2025 ] 	Mean test loss of 1355 batches: 1.190918993993879.
[ Wed Dec  3 21:09:26 2025 ] 	Top1: 85.68%
[ Wed Dec  3 21:09:26 2025 ] 	Top5: 96.82%
[ Wed Dec  3 21:09:26 2025 ] Training epoch: 497
[ Wed Dec  3 21:10:32 2025 ] 	Mean training loss: 0.7971.  Mean training acc: 98.30%.
[ Wed Dec  3 21:10:32 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 21:10:32 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 21:10:32 2025 ] Eval epoch: 497
[ Wed Dec  3 21:11:47 2025 ] 	Mean test loss of 1355 batches: 1.1930355193430207.
[ Wed Dec  3 21:11:48 2025 ] 	Top1: 85.70%
[ Wed Dec  3 21:11:48 2025 ] 	Top5: 96.74%
[ Wed Dec  3 21:11:48 2025 ] Training epoch: 498
[ Wed Dec  3 21:12:54 2025 ] 	Mean training loss: 0.7969.  Mean training acc: 98.20%.
[ Wed Dec  3 21:12:54 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 21:12:54 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 21:12:54 2025 ] Eval epoch: 498
[ Wed Dec  3 21:14:09 2025 ] 	Mean test loss of 1355 batches: 1.1976677840046337.
[ Wed Dec  3 21:14:09 2025 ] 	Top1: 85.50%
[ Wed Dec  3 21:14:10 2025 ] 	Top5: 96.70%
[ Wed Dec  3 21:14:10 2025 ] Training epoch: 499
[ Wed Dec  3 21:15:15 2025 ] 	Mean training loss: 0.7945.  Mean training acc: 98.22%.
[ Wed Dec  3 21:15:15 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 21:15:15 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 21:15:15 2025 ] Eval epoch: 499
[ Wed Dec  3 21:16:30 2025 ] 	Mean test loss of 1355 batches: 1.2004923070048934.
[ Wed Dec  3 21:16:30 2025 ] 	Top1: 85.33%
[ Wed Dec  3 21:16:30 2025 ] 	Top5: 96.72%
[ Wed Dec  3 21:16:30 2025 ] Training epoch: 500
[ Wed Dec  3 21:17:35 2025 ] 	Mean training loss: 0.7929.  Mean training acc: 98.40%.
[ Wed Dec  3 21:17:35 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 21:17:35 2025 ] 	Time consumption: [Data]20%, [Network]80%
[ Wed Dec  3 21:17:35 2025 ] Eval epoch: 500
[ Wed Dec  3 21:18:51 2025 ] 	Mean test loss of 1355 batches: 1.1981948284645363.
[ Wed Dec  3 21:18:51 2025 ] 	Top1: 85.40%
[ Wed Dec  3 21:18:51 2025 ] 	Top5: 96.69%
[ Wed Dec  3 21:20:07 2025 ] Best accuracy: 0.8570044296788483
[ Wed Dec  3 21:20:07 2025 ] Epoch number: 497
[ Wed Dec  3 21:20:07 2025 ] Model name: ./work_dir7/ntu/cs/SkateFormer_j/
[ Wed Dec  3 21:20:07 2025 ] Model total number of params: 3616083
[ Wed Dec  3 21:20:07 2025 ] Weight decay: 0.1
[ Wed Dec  3 21:20:07 2025 ] Base LR: 0.001
[ Wed Dec  3 21:20:07 2025 ] Batch Size: 32
[ Wed Dec  3 21:20:07 2025 ] Test Batch Size: 32
[ Wed Dec  3 21:20:07 2025 ] seed: 1
