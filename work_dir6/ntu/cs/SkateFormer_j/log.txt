[ Tue Dec  2 14:29:26 2025 ] using warm up, epoch: 25
[ Tue Dec  2 14:40:47 2025 ] Parameters:
{'work_dir': './work_dir6/ntu/cs/SkateFormer_j/', 'model_saved_name': './work_dir6/ntu/cs/SkateFormer_j/runs', 'config': './config/train/ntu_cs/SkateFormer_j.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 0, 'train_feeder_args': {'data_path': './data/ntu/random_split_predefined6/NTU60_CS.npz', 'split': 'train', 'debug': False, 'window_size': 64, 'p_interval': [0.5, 1], 'aug_method': 'a123489', 'intra_p': 0.5, 'inter_p': 0.2, 'thres': 64, 'uniform': True, 'partition': True}, 'test_feeder_args': {'data_path': './data/ntu/random_split_predefined6/NTU60_CS.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'thres': 64, 'uniform': True, 'partition': True, 'debug': False}, 'model': 'model.SkateFormer.SkateFormer_', 'model_args': {'num_classes': 60, 'num_people': 2, 'num_points': 24, 'kernel_size': 7, 'num_heads': 32, 'attn_drop': 0.5, 'head_drop': 0.0, 'rel': True, 'drop_path': 0.2, 'type_1_size': [8, 8], 'type_2_size': [8, 12], 'type_3_size': [8, 8], 'type_4_size': [8, 12], 'mlp_ratio': 4.0, 'index_t': True}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.001, 'min_lr': 1e-05, 'warmup_lr': 1e-07, 'warmup_prefix': False, 'warm_up_epoch': 25, 'grad_clip': True, 'grad_max': 1.0, 'device': [0], 'optimizer': 'AdamW', 'lr_scheduler': 'cosine', 'nesterov': True, 'batch_size': 32, 'test_batch_size': 32, 'start_epoch': 0, 'num_epoch': 500, 'weight_decay': 0.1, 'lr_ratio': 0.001, 'lr_decay_rate': 0.1, 'loss_type': 'LSCE'}

[ Tue Dec  2 14:40:47 2025 ] # Parameters: 3616083
[ Tue Dec  2 14:40:47 2025 ] Training epoch: 1
[ Tue Dec  2 14:57:42 2025 ] 	Mean training loss: 4.0062.  Mean training acc: 3.31%.
[ Tue Dec  2 14:57:42 2025 ] 	Learning Rate: 0.0000
[ Tue Dec  2 14:57:42 2025 ] 	Time consumption: [Data]01%, [Network]99%
[ Tue Dec  2 14:57:42 2025 ] Training epoch: 2
[ Tue Dec  2 14:59:20 2025 ] 	Mean training loss: 3.7274.  Mean training acc: 7.51%.
[ Tue Dec  2 14:59:20 2025 ] 	Learning Rate: 0.0001
[ Tue Dec  2 14:59:20 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Dec  2 14:59:20 2025 ] Training epoch: 3
[ Tue Dec  2 15:00:56 2025 ] 	Mean training loss: 3.4959.  Mean training acc: 11.67%.
[ Tue Dec  2 15:00:56 2025 ] 	Learning Rate: 0.0001
[ Tue Dec  2 15:00:56 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Dec  2 15:00:56 2025 ] Training epoch: 4
[ Tue Dec  2 15:02:33 2025 ] 	Mean training loss: 3.1451.  Mean training acc: 19.99%.
[ Tue Dec  2 15:02:33 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:02:33 2025 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Dec  2 15:02:33 2025 ] Training epoch: 5
[ Tue Dec  2 15:04:11 2025 ] 	Mean training loss: 2.8825.  Mean training acc: 27.99%.
[ Tue Dec  2 15:04:11 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:04:11 2025 ] 	Time consumption: [Data]14%, [Network]86%
[ Tue Dec  2 15:04:11 2025 ] Training epoch: 6
[ Tue Dec  2 15:05:47 2025 ] 	Mean training loss: 2.7096.  Mean training acc: 33.07%.
[ Tue Dec  2 15:05:47 2025 ] 	Learning Rate: 0.0002
[ Tue Dec  2 15:05:47 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Dec  2 15:05:47 2025 ] Training epoch: 7
[ Tue Dec  2 15:07:25 2025 ] 	Mean training loss: 2.5931.  Mean training acc: 37.50%.
[ Tue Dec  2 15:07:25 2025 ] 	Learning Rate: 0.0003
[ Tue Dec  2 15:07:25 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Dec  2 15:07:25 2025 ] Training epoch: 8
[ Tue Dec  2 15:09:00 2025 ] 	Mean training loss: 2.5070.  Mean training acc: 39.57%.
[ Tue Dec  2 15:09:00 2025 ] 	Learning Rate: 0.0003
[ Tue Dec  2 15:09:00 2025 ] 	Time consumption: [Data]14%, [Network]85%
[ Tue Dec  2 15:09:00 2025 ] Training epoch: 9
[ Tue Dec  2 15:10:54 2025 ] 	Mean training loss: 2.4194.  Mean training acc: 43.24%.
[ Tue Dec  2 15:10:54 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:10:54 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Tue Dec  2 15:10:54 2025 ] Training epoch: 10
[ Tue Dec  2 15:14:06 2025 ] 	Mean training loss: 2.3649.  Mean training acc: 44.97%.
[ Tue Dec  2 15:14:06 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:14:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:14:06 2025 ] Training epoch: 11
[ Tue Dec  2 15:17:17 2025 ] 	Mean training loss: 2.2906.  Mean training acc: 46.90%.
[ Tue Dec  2 15:17:17 2025 ] 	Learning Rate: 0.0004
[ Tue Dec  2 15:17:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:17:17 2025 ] Training epoch: 12
[ Tue Dec  2 15:20:29 2025 ] 	Mean training loss: 2.2617.  Mean training acc: 47.86%.
[ Tue Dec  2 15:20:29 2025 ] 	Learning Rate: 0.0005
[ Tue Dec  2 15:20:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:20:29 2025 ] Training epoch: 13
[ Tue Dec  2 15:23:41 2025 ] 	Mean training loss: 2.1991.  Mean training acc: 49.71%.
[ Tue Dec  2 15:23:41 2025 ] 	Learning Rate: 0.0005
[ Tue Dec  2 15:23:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:23:41 2025 ] Training epoch: 14
[ Tue Dec  2 15:26:52 2025 ] 	Mean training loss: 2.1775.  Mean training acc: 50.73%.
[ Tue Dec  2 15:26:52 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 15:26:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:26:52 2025 ] Training epoch: 15
[ Tue Dec  2 15:30:04 2025 ] 	Mean training loss: 2.1462.  Mean training acc: 51.95%.
[ Tue Dec  2 15:30:04 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 15:30:04 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:30:04 2025 ] Training epoch: 16
[ Tue Dec  2 15:33:15 2025 ] 	Mean training loss: 2.1249.  Mean training acc: 52.94%.
[ Tue Dec  2 15:33:15 2025 ] 	Learning Rate: 0.0006
[ Tue Dec  2 15:33:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:33:15 2025 ] Training epoch: 17
[ Tue Dec  2 15:36:27 2025 ] 	Mean training loss: 2.0829.  Mean training acc: 54.22%.
[ Tue Dec  2 15:36:27 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 15:36:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:36:27 2025 ] Training epoch: 18
[ Tue Dec  2 15:39:38 2025 ] 	Mean training loss: 2.0516.  Mean training acc: 55.32%.
[ Tue Dec  2 15:39:38 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 15:39:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:39:38 2025 ] Training epoch: 19
[ Tue Dec  2 15:42:50 2025 ] 	Mean training loss: 2.0324.  Mean training acc: 55.93%.
[ Tue Dec  2 15:42:50 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 15:42:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:42:50 2025 ] Training epoch: 20
[ Tue Dec  2 15:46:01 2025 ] 	Mean training loss: 2.0071.  Mean training acc: 56.95%.
[ Tue Dec  2 15:46:01 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 15:46:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:46:01 2025 ] Training epoch: 21
[ Tue Dec  2 15:49:13 2025 ] 	Mean training loss: 2.0024.  Mean training acc: 56.61%.
[ Tue Dec  2 15:49:13 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 15:49:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:49:13 2025 ] Training epoch: 22
[ Tue Dec  2 15:52:24 2025 ] 	Mean training loss: 1.9810.  Mean training acc: 57.92%.
[ Tue Dec  2 15:52:24 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 15:52:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:52:24 2025 ] Training epoch: 23
[ Tue Dec  2 15:55:36 2025 ] 	Mean training loss: 1.9654.  Mean training acc: 58.00%.
[ Tue Dec  2 15:55:36 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 15:55:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:55:36 2025 ] Training epoch: 24
[ Tue Dec  2 15:58:47 2025 ] 	Mean training loss: 1.9405.  Mean training acc: 58.57%.
[ Tue Dec  2 15:58:47 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 15:58:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 15:58:47 2025 ] Training epoch: 25
[ Tue Dec  2 16:01:59 2025 ] 	Mean training loss: 1.9357.  Mean training acc: 59.43%.
[ Tue Dec  2 16:01:59 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:01:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:01:59 2025 ] Training epoch: 26
[ Tue Dec  2 16:05:11 2025 ] 	Mean training loss: 1.9004.  Mean training acc: 60.44%.
[ Tue Dec  2 16:05:11 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:05:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:05:11 2025 ] Training epoch: 27
[ Tue Dec  2 16:08:22 2025 ] 	Mean training loss: 1.8828.  Mean training acc: 60.68%.
[ Tue Dec  2 16:08:22 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:08:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:08:22 2025 ] Training epoch: 28
[ Tue Dec  2 16:11:34 2025 ] 	Mean training loss: 1.8504.  Mean training acc: 61.71%.
[ Tue Dec  2 16:11:34 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:11:34 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 16:11:34 2025 ] Training epoch: 29
[ Tue Dec  2 16:14:45 2025 ] 	Mean training loss: 1.8167.  Mean training acc: 63.09%.
[ Tue Dec  2 16:14:45 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:14:45 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:14:45 2025 ] Training epoch: 30
[ Tue Dec  2 16:17:57 2025 ] 	Mean training loss: 1.8074.  Mean training acc: 63.89%.
[ Tue Dec  2 16:17:57 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:17:57 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:17:57 2025 ] Training epoch: 31
[ Tue Dec  2 16:21:09 2025 ] 	Mean training loss: 1.7683.  Mean training acc: 65.03%.
[ Tue Dec  2 16:21:09 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:21:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:21:09 2025 ] Training epoch: 32
[ Tue Dec  2 16:24:20 2025 ] 	Mean training loss: 1.7531.  Mean training acc: 65.49%.
[ Tue Dec  2 16:24:20 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:24:20 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:24:20 2025 ] Training epoch: 33
[ Tue Dec  2 16:27:32 2025 ] 	Mean training loss: 1.7374.  Mean training acc: 65.96%.
[ Tue Dec  2 16:27:32 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:27:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:27:32 2025 ] Training epoch: 34
[ Tue Dec  2 16:30:43 2025 ] 	Mean training loss: 1.7311.  Mean training acc: 66.54%.
[ Tue Dec  2 16:30:43 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:30:43 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:30:43 2025 ] Training epoch: 35
[ Tue Dec  2 16:33:54 2025 ] 	Mean training loss: 1.7002.  Mean training acc: 67.54%.
[ Tue Dec  2 16:33:54 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:33:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:33:54 2025 ] Training epoch: 36
[ Tue Dec  2 16:37:06 2025 ] 	Mean training loss: 1.6882.  Mean training acc: 67.62%.
[ Tue Dec  2 16:37:06 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:37:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:37:06 2025 ] Training epoch: 37
[ Tue Dec  2 16:40:17 2025 ] 	Mean training loss: 1.6741.  Mean training acc: 67.83%.
[ Tue Dec  2 16:40:17 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:40:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:40:17 2025 ] Training epoch: 38
[ Tue Dec  2 16:43:29 2025 ] 	Mean training loss: 1.6587.  Mean training acc: 68.70%.
[ Tue Dec  2 16:43:29 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:43:29 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:43:29 2025 ] Training epoch: 39
[ Tue Dec  2 16:46:40 2025 ] 	Mean training loss: 1.6301.  Mean training acc: 69.44%.
[ Tue Dec  2 16:46:40 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:46:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:46:40 2025 ] Training epoch: 40
[ Tue Dec  2 16:49:52 2025 ] 	Mean training loss: 1.6291.  Mean training acc: 69.18%.
[ Tue Dec  2 16:49:52 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:49:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:49:52 2025 ] Training epoch: 41
[ Tue Dec  2 16:53:04 2025 ] 	Mean training loss: 1.6186.  Mean training acc: 69.82%.
[ Tue Dec  2 16:53:04 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:53:04 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 16:53:04 2025 ] Training epoch: 42
[ Tue Dec  2 16:56:15 2025 ] 	Mean training loss: 1.6073.  Mean training acc: 70.60%.
[ Tue Dec  2 16:56:15 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:56:15 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:56:15 2025 ] Training epoch: 43
[ Tue Dec  2 16:59:27 2025 ] 	Mean training loss: 1.5858.  Mean training acc: 70.76%.
[ Tue Dec  2 16:59:27 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 16:59:27 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 16:59:27 2025 ] Training epoch: 44
[ Tue Dec  2 17:02:38 2025 ] 	Mean training loss: 1.5742.  Mean training acc: 71.60%.
[ Tue Dec  2 17:02:38 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:02:38 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:02:38 2025 ] Training epoch: 45
[ Tue Dec  2 17:05:50 2025 ] 	Mean training loss: 1.5606.  Mean training acc: 71.72%.
[ Tue Dec  2 17:05:50 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:05:50 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:05:50 2025 ] Training epoch: 46
[ Tue Dec  2 17:09:01 2025 ] 	Mean training loss: 1.5555.  Mean training acc: 72.09%.
[ Tue Dec  2 17:09:01 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:09:01 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:09:01 2025 ] Training epoch: 47
[ Tue Dec  2 17:12:13 2025 ] 	Mean training loss: 1.5647.  Mean training acc: 71.98%.
[ Tue Dec  2 17:12:13 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:12:13 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:12:13 2025 ] Training epoch: 48
[ Tue Dec  2 17:15:24 2025 ] 	Mean training loss: 1.5557.  Mean training acc: 72.35%.
[ Tue Dec  2 17:15:24 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:15:24 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:15:24 2025 ] Training epoch: 49
[ Tue Dec  2 17:18:36 2025 ] 	Mean training loss: 1.5296.  Mean training acc: 73.61%.
[ Tue Dec  2 17:18:36 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:18:36 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:18:36 2025 ] Training epoch: 50
[ Tue Dec  2 17:21:47 2025 ] 	Mean training loss: 1.5263.  Mean training acc: 73.38%.
[ Tue Dec  2 17:21:47 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:21:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:21:47 2025 ] Training epoch: 51
[ Tue Dec  2 17:24:58 2025 ] 	Mean training loss: 1.5125.  Mean training acc: 73.84%.
[ Tue Dec  2 17:24:58 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:24:58 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:24:58 2025 ] Training epoch: 52
[ Tue Dec  2 17:28:10 2025 ] 	Mean training loss: 1.5026.  Mean training acc: 73.63%.
[ Tue Dec  2 17:28:10 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:28:10 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:28:10 2025 ] Training epoch: 53
[ Tue Dec  2 17:31:22 2025 ] 	Mean training loss: 1.5024.  Mean training acc: 74.13%.
[ Tue Dec  2 17:31:22 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:31:22 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:31:22 2025 ] Training epoch: 54
[ Tue Dec  2 17:34:33 2025 ] 	Mean training loss: 1.4882.  Mean training acc: 74.73%.
[ Tue Dec  2 17:34:33 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:34:33 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:34:33 2025 ] Training epoch: 55
[ Tue Dec  2 17:37:45 2025 ] 	Mean training loss: 1.4980.  Mean training acc: 73.80%.
[ Tue Dec  2 17:37:45 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:37:45 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:37:45 2025 ] Training epoch: 56
[ Tue Dec  2 17:40:56 2025 ] 	Mean training loss: 1.4785.  Mean training acc: 75.14%.
[ Tue Dec  2 17:40:56 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:40:56 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:40:56 2025 ] Training epoch: 57
[ Tue Dec  2 17:44:08 2025 ] 	Mean training loss: 1.4702.  Mean training acc: 75.39%.
[ Tue Dec  2 17:44:08 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:44:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:44:08 2025 ] Training epoch: 58
[ Tue Dec  2 17:47:20 2025 ] 	Mean training loss: 1.4615.  Mean training acc: 75.11%.
[ Tue Dec  2 17:47:20 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:47:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:47:20 2025 ] Training epoch: 59
[ Tue Dec  2 17:50:31 2025 ] 	Mean training loss: 1.4619.  Mean training acc: 75.21%.
[ Tue Dec  2 17:50:31 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:50:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 17:50:31 2025 ] Training epoch: 60
[ Tue Dec  2 17:53:43 2025 ] 	Mean training loss: 1.4541.  Mean training acc: 75.69%.
[ Tue Dec  2 17:53:43 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:53:43 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 17:53:43 2025 ] Training epoch: 61
[ Tue Dec  2 17:56:54 2025 ] 	Mean training loss: 1.4581.  Mean training acc: 75.57%.
[ Tue Dec  2 17:56:54 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 17:56:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 17:56:54 2025 ] Training epoch: 62
[ Tue Dec  2 18:00:06 2025 ] 	Mean training loss: 1.4491.  Mean training acc: 75.95%.
[ Tue Dec  2 18:00:06 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:00:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:00:06 2025 ] Training epoch: 63
[ Tue Dec  2 18:03:18 2025 ] 	Mean training loss: 1.4331.  Mean training acc: 76.22%.
[ Tue Dec  2 18:03:18 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:03:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:03:18 2025 ] Training epoch: 64
[ Tue Dec  2 18:06:29 2025 ] 	Mean training loss: 1.4301.  Mean training acc: 76.57%.
[ Tue Dec  2 18:06:29 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:06:29 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:06:29 2025 ] Training epoch: 65
[ Tue Dec  2 18:09:40 2025 ] 	Mean training loss: 1.4317.  Mean training acc: 76.38%.
[ Tue Dec  2 18:09:40 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:09:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:09:40 2025 ] Training epoch: 66
[ Tue Dec  2 18:12:52 2025 ] 	Mean training loss: 1.4344.  Mean training acc: 76.07%.
[ Tue Dec  2 18:12:52 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:12:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:12:52 2025 ] Training epoch: 67
[ Tue Dec  2 18:16:03 2025 ] 	Mean training loss: 1.4216.  Mean training acc: 76.85%.
[ Tue Dec  2 18:16:03 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:16:03 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:16:03 2025 ] Training epoch: 68
[ Tue Dec  2 18:19:15 2025 ] 	Mean training loss: 1.4183.  Mean training acc: 76.90%.
[ Tue Dec  2 18:19:15 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:19:15 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:19:15 2025 ] Training epoch: 69
[ Tue Dec  2 18:22:27 2025 ] 	Mean training loss: 1.4212.  Mean training acc: 76.59%.
[ Tue Dec  2 18:22:27 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:22:27 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:22:27 2025 ] Training epoch: 70
[ Tue Dec  2 18:25:38 2025 ] 	Mean training loss: 1.4013.  Mean training acc: 77.75%.
[ Tue Dec  2 18:25:38 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:25:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:25:38 2025 ] Training epoch: 71
[ Tue Dec  2 18:28:50 2025 ] 	Mean training loss: 1.3942.  Mean training acc: 77.35%.
[ Tue Dec  2 18:28:50 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:28:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:28:50 2025 ] Training epoch: 72
[ Tue Dec  2 18:32:02 2025 ] 	Mean training loss: 1.4078.  Mean training acc: 77.19%.
[ Tue Dec  2 18:32:02 2025 ] 	Learning Rate: 0.0010
[ Tue Dec  2 18:32:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:32:02 2025 ] Training epoch: 73
[ Tue Dec  2 18:35:13 2025 ] 	Mean training loss: 1.3961.  Mean training acc: 77.85%.
[ Tue Dec  2 18:35:13 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:35:13 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:35:13 2025 ] Training epoch: 74
[ Tue Dec  2 18:38:24 2025 ] 	Mean training loss: 1.3902.  Mean training acc: 77.60%.
[ Tue Dec  2 18:38:24 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:38:24 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:38:24 2025 ] Training epoch: 75
[ Tue Dec  2 18:41:36 2025 ] 	Mean training loss: 1.3915.  Mean training acc: 77.85%.
[ Tue Dec  2 18:41:36 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:41:36 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 18:41:36 2025 ] Training epoch: 76
[ Tue Dec  2 18:44:47 2025 ] 	Mean training loss: 1.3820.  Mean training acc: 78.31%.
[ Tue Dec  2 18:44:47 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:44:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 18:44:47 2025 ] Training epoch: 77
[ Tue Dec  2 18:47:59 2025 ] 	Mean training loss: 1.3651.  Mean training acc: 79.14%.
[ Tue Dec  2 18:47:59 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:47:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:47:59 2025 ] Training epoch: 78
[ Tue Dec  2 18:51:10 2025 ] 	Mean training loss: 1.3702.  Mean training acc: 78.57%.
[ Tue Dec  2 18:51:10 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:51:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:51:10 2025 ] Training epoch: 79
[ Tue Dec  2 18:54:22 2025 ] 	Mean training loss: 1.3756.  Mean training acc: 78.44%.
[ Tue Dec  2 18:54:22 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:54:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:54:22 2025 ] Training epoch: 80
[ Tue Dec  2 18:57:34 2025 ] 	Mean training loss: 1.3580.  Mean training acc: 79.13%.
[ Tue Dec  2 18:57:34 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 18:57:34 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 18:57:34 2025 ] Training epoch: 81
[ Tue Dec  2 19:00:45 2025 ] 	Mean training loss: 1.3666.  Mean training acc: 78.67%.
[ Tue Dec  2 19:00:45 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:00:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:00:45 2025 ] Training epoch: 82
[ Tue Dec  2 19:03:57 2025 ] 	Mean training loss: 1.3612.  Mean training acc: 79.18%.
[ Tue Dec  2 19:03:57 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:03:57 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:03:57 2025 ] Training epoch: 83
[ Tue Dec  2 19:07:08 2025 ] 	Mean training loss: 1.3544.  Mean training acc: 79.10%.
[ Tue Dec  2 19:07:08 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:07:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:07:08 2025 ] Training epoch: 84
[ Tue Dec  2 19:10:20 2025 ] 	Mean training loss: 1.3551.  Mean training acc: 79.38%.
[ Tue Dec  2 19:10:20 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:10:20 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:10:20 2025 ] Training epoch: 85
[ Tue Dec  2 19:13:31 2025 ] 	Mean training loss: 1.3445.  Mean training acc: 79.62%.
[ Tue Dec  2 19:13:31 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:13:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:13:31 2025 ] Training epoch: 86
[ Tue Dec  2 19:16:43 2025 ] 	Mean training loss: 1.3386.  Mean training acc: 79.71%.
[ Tue Dec  2 19:16:43 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:16:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:16:43 2025 ] Training epoch: 87
[ Tue Dec  2 19:19:54 2025 ] 	Mean training loss: 1.3433.  Mean training acc: 79.73%.
[ Tue Dec  2 19:19:54 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:19:54 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:19:54 2025 ] Training epoch: 88
[ Tue Dec  2 19:23:06 2025 ] 	Mean training loss: 1.3429.  Mean training acc: 80.00%.
[ Tue Dec  2 19:23:06 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:23:06 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:23:06 2025 ] Training epoch: 89
[ Tue Dec  2 19:26:17 2025 ] 	Mean training loss: 1.3441.  Mean training acc: 79.34%.
[ Tue Dec  2 19:26:17 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:26:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:26:17 2025 ] Training epoch: 90
[ Tue Dec  2 19:29:28 2025 ] 	Mean training loss: 1.3300.  Mean training acc: 80.23%.
[ Tue Dec  2 19:29:28 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:29:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:29:28 2025 ] Training epoch: 91
[ Tue Dec  2 19:32:39 2025 ] 	Mean training loss: 1.3322.  Mean training acc: 79.39%.
[ Tue Dec  2 19:32:39 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:32:39 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 19:32:39 2025 ] Training epoch: 92
[ Tue Dec  2 19:35:51 2025 ] 	Mean training loss: 1.3149.  Mean training acc: 80.42%.
[ Tue Dec  2 19:35:51 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:35:51 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:35:51 2025 ] Training epoch: 93
[ Tue Dec  2 19:39:02 2025 ] 	Mean training loss: 1.3170.  Mean training acc: 80.52%.
[ Tue Dec  2 19:39:02 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:39:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:39:02 2025 ] Training epoch: 94
[ Tue Dec  2 19:42:14 2025 ] 	Mean training loss: 1.3252.  Mean training acc: 80.33%.
[ Tue Dec  2 19:42:14 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:42:14 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:42:14 2025 ] Training epoch: 95
[ Tue Dec  2 19:45:25 2025 ] 	Mean training loss: 1.3074.  Mean training acc: 81.04%.
[ Tue Dec  2 19:45:25 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:45:25 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 19:45:25 2025 ] Training epoch: 96
[ Tue Dec  2 19:48:37 2025 ] 	Mean training loss: 1.3099.  Mean training acc: 80.47%.
[ Tue Dec  2 19:48:37 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:48:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:48:37 2025 ] Training epoch: 97
[ Tue Dec  2 19:51:48 2025 ] 	Mean training loss: 1.3227.  Mean training acc: 80.46%.
[ Tue Dec  2 19:51:48 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:51:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:51:48 2025 ] Training epoch: 98
[ Tue Dec  2 19:55:00 2025 ] 	Mean training loss: 1.3163.  Mean training acc: 80.69%.
[ Tue Dec  2 19:55:00 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:55:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:55:00 2025 ] Training epoch: 99
[ Tue Dec  2 19:58:11 2025 ] 	Mean training loss: 1.3086.  Mean training acc: 80.85%.
[ Tue Dec  2 19:58:11 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 19:58:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 19:58:11 2025 ] Training epoch: 100
[ Tue Dec  2 20:01:23 2025 ] 	Mean training loss: 1.3038.  Mean training acc: 80.99%.
[ Tue Dec  2 20:01:23 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:01:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:01:23 2025 ] Training epoch: 101
[ Tue Dec  2 20:04:35 2025 ] 	Mean training loss: 1.3035.  Mean training acc: 80.79%.
[ Tue Dec  2 20:04:35 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:04:35 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:04:35 2025 ] Training epoch: 102
[ Tue Dec  2 20:07:46 2025 ] 	Mean training loss: 1.3052.  Mean training acc: 80.92%.
[ Tue Dec  2 20:07:46 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:07:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:07:46 2025 ] Training epoch: 103
[ Tue Dec  2 20:10:58 2025 ] 	Mean training loss: 1.3049.  Mean training acc: 80.76%.
[ Tue Dec  2 20:10:58 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:10:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:10:58 2025 ] Training epoch: 104
[ Tue Dec  2 20:14:09 2025 ] 	Mean training loss: 1.2833.  Mean training acc: 81.88%.
[ Tue Dec  2 20:14:09 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:14:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:14:09 2025 ] Training epoch: 105
[ Tue Dec  2 20:17:20 2025 ] 	Mean training loss: 1.2919.  Mean training acc: 81.41%.
[ Tue Dec  2 20:17:20 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:17:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:17:20 2025 ] Training epoch: 106
[ Tue Dec  2 20:20:32 2025 ] 	Mean training loss: 1.2946.  Mean training acc: 81.25%.
[ Tue Dec  2 20:20:32 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:20:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:20:32 2025 ] Training epoch: 107
[ Tue Dec  2 20:23:44 2025 ] 	Mean training loss: 1.2830.  Mean training acc: 81.96%.
[ Tue Dec  2 20:23:44 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:23:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:23:44 2025 ] Training epoch: 108
[ Tue Dec  2 20:26:55 2025 ] 	Mean training loss: 1.2723.  Mean training acc: 82.02%.
[ Tue Dec  2 20:26:55 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:26:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:26:55 2025 ] Training epoch: 109
[ Tue Dec  2 20:30:07 2025 ] 	Mean training loss: 1.2859.  Mean training acc: 82.00%.
[ Tue Dec  2 20:30:07 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:30:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:30:07 2025 ] Training epoch: 110
[ Tue Dec  2 20:33:18 2025 ] 	Mean training loss: 1.2744.  Mean training acc: 81.98%.
[ Tue Dec  2 20:33:18 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:33:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:33:18 2025 ] Training epoch: 111
[ Tue Dec  2 20:36:30 2025 ] 	Mean training loss: 1.2728.  Mean training acc: 81.76%.
[ Tue Dec  2 20:36:30 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:36:30 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:36:30 2025 ] Training epoch: 112
[ Tue Dec  2 20:39:41 2025 ] 	Mean training loss: 1.2688.  Mean training acc: 82.46%.
[ Tue Dec  2 20:39:41 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:39:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:39:41 2025 ] Training epoch: 113
[ Tue Dec  2 20:42:52 2025 ] 	Mean training loss: 1.2766.  Mean training acc: 82.00%.
[ Tue Dec  2 20:42:52 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:42:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:42:52 2025 ] Training epoch: 114
[ Tue Dec  2 20:46:04 2025 ] 	Mean training loss: 1.2651.  Mean training acc: 82.32%.
[ Tue Dec  2 20:46:04 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:46:04 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:46:04 2025 ] Training epoch: 115
[ Tue Dec  2 20:49:15 2025 ] 	Mean training loss: 1.2688.  Mean training acc: 82.10%.
[ Tue Dec  2 20:49:15 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:49:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:49:15 2025 ] Training epoch: 116
[ Tue Dec  2 20:52:27 2025 ] 	Mean training loss: 1.2609.  Mean training acc: 82.36%.
[ Tue Dec  2 20:52:27 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:52:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:52:27 2025 ] Training epoch: 117
[ Tue Dec  2 20:55:38 2025 ] 	Mean training loss: 1.2835.  Mean training acc: 81.95%.
[ Tue Dec  2 20:55:38 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:55:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:55:38 2025 ] Training epoch: 118
[ Tue Dec  2 20:58:50 2025 ] 	Mean training loss: 1.2592.  Mean training acc: 82.37%.
[ Tue Dec  2 20:58:50 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 20:58:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 20:58:50 2025 ] Training epoch: 119
[ Tue Dec  2 21:02:01 2025 ] 	Mean training loss: 1.2682.  Mean training acc: 82.22%.
[ Tue Dec  2 21:02:01 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:02:01 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:02:01 2025 ] Training epoch: 120
[ Tue Dec  2 21:05:13 2025 ] 	Mean training loss: 1.2597.  Mean training acc: 82.24%.
[ Tue Dec  2 21:05:13 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:05:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:05:13 2025 ] Training epoch: 121
[ Tue Dec  2 21:08:25 2025 ] 	Mean training loss: 1.2632.  Mean training acc: 82.61%.
[ Tue Dec  2 21:08:25 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:08:25 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:08:25 2025 ] Training epoch: 122
[ Tue Dec  2 21:11:36 2025 ] 	Mean training loss: 1.2467.  Mean training acc: 83.06%.
[ Tue Dec  2 21:11:36 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:11:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:11:36 2025 ] Training epoch: 123
[ Tue Dec  2 21:14:47 2025 ] 	Mean training loss: 1.2525.  Mean training acc: 83.19%.
[ Tue Dec  2 21:14:47 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:14:47 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 21:14:47 2025 ] Training epoch: 124
[ Tue Dec  2 21:17:59 2025 ] 	Mean training loss: 1.2322.  Mean training acc: 83.57%.
[ Tue Dec  2 21:17:59 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:17:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:17:59 2025 ] Training epoch: 125
[ Tue Dec  2 21:21:10 2025 ] 	Mean training loss: 1.2419.  Mean training acc: 83.34%.
[ Tue Dec  2 21:21:10 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:21:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:21:10 2025 ] Training epoch: 126
[ Tue Dec  2 21:24:22 2025 ] 	Mean training loss: 1.2431.  Mean training acc: 83.16%.
[ Tue Dec  2 21:24:22 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:24:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:24:22 2025 ] Training epoch: 127
[ Tue Dec  2 21:27:33 2025 ] 	Mean training loss: 1.2354.  Mean training acc: 83.28%.
[ Tue Dec  2 21:27:33 2025 ] 	Learning Rate: 0.0009
[ Tue Dec  2 21:27:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:27:33 2025 ] Training epoch: 128
[ Tue Dec  2 21:30:45 2025 ] 	Mean training loss: 1.2378.  Mean training acc: 83.74%.
[ Tue Dec  2 21:30:45 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:30:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:30:45 2025 ] Training epoch: 129
[ Tue Dec  2 21:33:56 2025 ] 	Mean training loss: 1.2320.  Mean training acc: 83.72%.
[ Tue Dec  2 21:33:56 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:33:56 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:33:56 2025 ] Training epoch: 130
[ Tue Dec  2 21:37:08 2025 ] 	Mean training loss: 1.2308.  Mean training acc: 83.63%.
[ Tue Dec  2 21:37:08 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:37:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:37:08 2025 ] Training epoch: 131
[ Tue Dec  2 21:40:19 2025 ] 	Mean training loss: 1.2298.  Mean training acc: 83.66%.
[ Tue Dec  2 21:40:19 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:40:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:40:19 2025 ] Training epoch: 132
[ Tue Dec  2 21:43:31 2025 ] 	Mean training loss: 1.2268.  Mean training acc: 83.62%.
[ Tue Dec  2 21:43:31 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:43:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:43:31 2025 ] Training epoch: 133
[ Tue Dec  2 21:46:42 2025 ] 	Mean training loss: 1.2304.  Mean training acc: 83.47%.
[ Tue Dec  2 21:46:42 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:46:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:46:42 2025 ] Training epoch: 134
[ Tue Dec  2 21:49:54 2025 ] 	Mean training loss: 1.2309.  Mean training acc: 83.67%.
[ Tue Dec  2 21:49:54 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:49:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:49:54 2025 ] Training epoch: 135
[ Tue Dec  2 21:53:05 2025 ] 	Mean training loss: 1.2200.  Mean training acc: 84.10%.
[ Tue Dec  2 21:53:05 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:53:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:53:05 2025 ] Training epoch: 136
[ Tue Dec  2 21:56:17 2025 ] 	Mean training loss: 1.2128.  Mean training acc: 84.35%.
[ Tue Dec  2 21:56:17 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:56:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:56:17 2025 ] Training epoch: 137
[ Tue Dec  2 21:59:28 2025 ] 	Mean training loss: 1.2209.  Mean training acc: 83.95%.
[ Tue Dec  2 21:59:28 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 21:59:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 21:59:29 2025 ] Training epoch: 138
[ Tue Dec  2 22:02:40 2025 ] 	Mean training loss: 1.2241.  Mean training acc: 83.90%.
[ Tue Dec  2 22:02:40 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:02:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:02:40 2025 ] Training epoch: 139
[ Tue Dec  2 22:05:52 2025 ] 	Mean training loss: 1.2059.  Mean training acc: 84.44%.
[ Tue Dec  2 22:05:52 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:05:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:05:52 2025 ] Training epoch: 140
[ Tue Dec  2 22:09:03 2025 ] 	Mean training loss: 1.2168.  Mean training acc: 84.01%.
[ Tue Dec  2 22:09:03 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:09:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:09:03 2025 ] Training epoch: 141
[ Tue Dec  2 22:12:15 2025 ] 	Mean training loss: 1.2172.  Mean training acc: 83.95%.
[ Tue Dec  2 22:12:15 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:12:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:12:15 2025 ] Training epoch: 142
[ Tue Dec  2 22:15:26 2025 ] 	Mean training loss: 1.2159.  Mean training acc: 83.71%.
[ Tue Dec  2 22:15:26 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:15:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:15:26 2025 ] Training epoch: 143
[ Tue Dec  2 22:18:38 2025 ] 	Mean training loss: 1.2058.  Mean training acc: 84.78%.
[ Tue Dec  2 22:18:38 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:18:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:18:38 2025 ] Training epoch: 144
[ Tue Dec  2 22:21:49 2025 ] 	Mean training loss: 1.2026.  Mean training acc: 84.33%.
[ Tue Dec  2 22:21:49 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:21:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:21:49 2025 ] Training epoch: 145
[ Tue Dec  2 22:25:01 2025 ] 	Mean training loss: 1.2011.  Mean training acc: 84.90%.
[ Tue Dec  2 22:25:01 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:25:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:25:01 2025 ] Training epoch: 146
[ Tue Dec  2 22:28:12 2025 ] 	Mean training loss: 1.1998.  Mean training acc: 84.71%.
[ Tue Dec  2 22:28:12 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:28:12 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:28:12 2025 ] Training epoch: 147
[ Tue Dec  2 22:31:24 2025 ] 	Mean training loss: 1.2073.  Mean training acc: 84.65%.
[ Tue Dec  2 22:31:24 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:31:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:31:24 2025 ] Training epoch: 148
[ Tue Dec  2 22:34:35 2025 ] 	Mean training loss: 1.1992.  Mean training acc: 84.87%.
[ Tue Dec  2 22:34:35 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:34:35 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:34:35 2025 ] Training epoch: 149
[ Tue Dec  2 22:37:47 2025 ] 	Mean training loss: 1.1959.  Mean training acc: 84.61%.
[ Tue Dec  2 22:37:47 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:37:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:37:47 2025 ] Training epoch: 150
[ Tue Dec  2 22:40:58 2025 ] 	Mean training loss: 1.1973.  Mean training acc: 84.48%.
[ Tue Dec  2 22:40:58 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:40:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:40:58 2025 ] Training epoch: 151
[ Tue Dec  2 22:44:10 2025 ] 	Mean training loss: 1.1873.  Mean training acc: 85.60%.
[ Tue Dec  2 22:44:10 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:44:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:44:10 2025 ] Training epoch: 152
[ Tue Dec  2 22:47:22 2025 ] 	Mean training loss: 1.1830.  Mean training acc: 85.51%.
[ Tue Dec  2 22:47:22 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:47:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 22:47:22 2025 ] Training epoch: 153
[ Tue Dec  2 22:50:33 2025 ] 	Mean training loss: 1.1882.  Mean training acc: 85.21%.
[ Tue Dec  2 22:50:33 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:50:33 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:50:33 2025 ] Training epoch: 154
[ Tue Dec  2 22:53:45 2025 ] 	Mean training loss: 1.1785.  Mean training acc: 85.29%.
[ Tue Dec  2 22:53:45 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:53:45 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 22:53:45 2025 ] Training epoch: 155
[ Tue Dec  2 22:56:56 2025 ] 	Mean training loss: 1.1797.  Mean training acc: 85.21%.
[ Tue Dec  2 22:56:56 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 22:56:56 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 22:56:56 2025 ] Training epoch: 156
[ Tue Dec  2 23:00:08 2025 ] 	Mean training loss: 1.1809.  Mean training acc: 85.68%.
[ Tue Dec  2 23:00:08 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:00:08 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:00:08 2025 ] Training epoch: 157
[ Tue Dec  2 23:03:19 2025 ] 	Mean training loss: 1.1787.  Mean training acc: 84.93%.
[ Tue Dec  2 23:03:19 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:03:19 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:03:19 2025 ] Training epoch: 158
[ Tue Dec  2 23:06:31 2025 ] 	Mean training loss: 1.1863.  Mean training acc: 85.19%.
[ Tue Dec  2 23:06:31 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:06:31 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:06:31 2025 ] Training epoch: 159
[ Tue Dec  2 23:09:42 2025 ] 	Mean training loss: 1.1749.  Mean training acc: 85.43%.
[ Tue Dec  2 23:09:42 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:09:42 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:09:42 2025 ] Training epoch: 160
[ Tue Dec  2 23:12:54 2025 ] 	Mean training loss: 1.1857.  Mean training acc: 85.64%.
[ Tue Dec  2 23:12:54 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:12:54 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:12:54 2025 ] Training epoch: 161
[ Tue Dec  2 23:16:06 2025 ] 	Mean training loss: 1.1764.  Mean training acc: 85.48%.
[ Tue Dec  2 23:16:06 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:16:06 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Dec  2 23:16:06 2025 ] Training epoch: 162
[ Tue Dec  2 23:19:17 2025 ] 	Mean training loss: 1.1722.  Mean training acc: 85.61%.
[ Tue Dec  2 23:19:17 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:19:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:19:17 2025 ] Training epoch: 163
[ Tue Dec  2 23:22:29 2025 ] 	Mean training loss: 1.1739.  Mean training acc: 85.58%.
[ Tue Dec  2 23:22:29 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:22:29 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:22:29 2025 ] Training epoch: 164
[ Tue Dec  2 23:25:40 2025 ] 	Mean training loss: 1.1647.  Mean training acc: 86.01%.
[ Tue Dec  2 23:25:40 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:25:40 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Tue Dec  2 23:25:40 2025 ] Training epoch: 165
[ Tue Dec  2 23:28:52 2025 ] 	Mean training loss: 1.1635.  Mean training acc: 85.88%.
[ Tue Dec  2 23:28:52 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:28:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:28:52 2025 ] Training epoch: 166
[ Tue Dec  2 23:32:03 2025 ] 	Mean training loss: 1.1662.  Mean training acc: 85.68%.
[ Tue Dec  2 23:32:03 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:32:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:32:03 2025 ] Training epoch: 167
[ Tue Dec  2 23:35:15 2025 ] 	Mean training loss: 1.1677.  Mean training acc: 85.77%.
[ Tue Dec  2 23:35:15 2025 ] 	Learning Rate: 0.0008
[ Tue Dec  2 23:35:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:35:15 2025 ] Training epoch: 168
[ Tue Dec  2 23:38:26 2025 ] 	Mean training loss: 1.1567.  Mean training acc: 85.77%.
[ Tue Dec  2 23:38:26 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 23:38:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:38:26 2025 ] Training epoch: 169
[ Tue Dec  2 23:41:38 2025 ] 	Mean training loss: 1.1572.  Mean training acc: 86.17%.
[ Tue Dec  2 23:41:38 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 23:41:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:41:38 2025 ] Training epoch: 170
[ Tue Dec  2 23:44:49 2025 ] 	Mean training loss: 1.1643.  Mean training acc: 86.00%.
[ Tue Dec  2 23:44:49 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 23:44:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:44:49 2025 ] Training epoch: 171
[ Tue Dec  2 23:48:01 2025 ] 	Mean training loss: 1.1649.  Mean training acc: 85.87%.
[ Tue Dec  2 23:48:01 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 23:48:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:48:01 2025 ] Training epoch: 172
[ Tue Dec  2 23:51:12 2025 ] 	Mean training loss: 1.1582.  Mean training acc: 86.06%.
[ Tue Dec  2 23:51:12 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 23:51:12 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:51:12 2025 ] Training epoch: 173
[ Tue Dec  2 23:54:24 2025 ] 	Mean training loss: 1.1530.  Mean training acc: 86.48%.
[ Tue Dec  2 23:54:24 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 23:54:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:54:24 2025 ] Training epoch: 174
[ Tue Dec  2 23:57:35 2025 ] 	Mean training loss: 1.1583.  Mean training acc: 85.74%.
[ Tue Dec  2 23:57:35 2025 ] 	Learning Rate: 0.0007
[ Tue Dec  2 23:57:35 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Tue Dec  2 23:57:35 2025 ] Training epoch: 175
[ Wed Dec  3 00:00:47 2025 ] 	Mean training loss: 1.1609.  Mean training acc: 86.01%.
[ Wed Dec  3 00:00:47 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:00:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:00:47 2025 ] Training epoch: 176
[ Wed Dec  3 00:03:58 2025 ] 	Mean training loss: 1.1473.  Mean training acc: 86.61%.
[ Wed Dec  3 00:03:58 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:03:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:03:58 2025 ] Training epoch: 177
[ Wed Dec  3 00:07:10 2025 ] 	Mean training loss: 1.1493.  Mean training acc: 86.65%.
[ Wed Dec  3 00:07:10 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:07:10 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:07:10 2025 ] Training epoch: 178
[ Wed Dec  3 00:10:21 2025 ] 	Mean training loss: 1.1445.  Mean training acc: 86.49%.
[ Wed Dec  3 00:10:21 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:10:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:10:21 2025 ] Training epoch: 179
[ Wed Dec  3 00:13:33 2025 ] 	Mean training loss: 1.1384.  Mean training acc: 86.83%.
[ Wed Dec  3 00:13:33 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:13:33 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:13:33 2025 ] Training epoch: 180
[ Wed Dec  3 00:16:44 2025 ] 	Mean training loss: 1.1436.  Mean training acc: 86.75%.
[ Wed Dec  3 00:16:44 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:16:44 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:16:44 2025 ] Training epoch: 181
[ Wed Dec  3 00:19:56 2025 ] 	Mean training loss: 1.1428.  Mean training acc: 86.76%.
[ Wed Dec  3 00:19:56 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:19:56 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:19:56 2025 ] Training epoch: 182
[ Wed Dec  3 00:23:07 2025 ] 	Mean training loss: 1.1414.  Mean training acc: 86.91%.
[ Wed Dec  3 00:23:07 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:23:07 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:23:07 2025 ] Training epoch: 183
[ Wed Dec  3 00:26:19 2025 ] 	Mean training loss: 1.1395.  Mean training acc: 86.86%.
[ Wed Dec  3 00:26:19 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:26:19 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:26:19 2025 ] Training epoch: 184
[ Wed Dec  3 00:29:30 2025 ] 	Mean training loss: 1.1295.  Mean training acc: 87.30%.
[ Wed Dec  3 00:29:30 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:29:30 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:29:30 2025 ] Training epoch: 185
[ Wed Dec  3 00:32:42 2025 ] 	Mean training loss: 1.1304.  Mean training acc: 87.26%.
[ Wed Dec  3 00:32:42 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:32:42 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:32:42 2025 ] Training epoch: 186
[ Wed Dec  3 00:35:54 2025 ] 	Mean training loss: 1.1356.  Mean training acc: 86.98%.
[ Wed Dec  3 00:35:54 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:35:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:35:54 2025 ] Training epoch: 187
[ Wed Dec  3 00:39:05 2025 ] 	Mean training loss: 1.1274.  Mean training acc: 87.22%.
[ Wed Dec  3 00:39:05 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:39:05 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:39:05 2025 ] Training epoch: 188
[ Wed Dec  3 00:42:17 2025 ] 	Mean training loss: 1.1312.  Mean training acc: 87.03%.
[ Wed Dec  3 00:42:17 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:42:17 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 00:42:17 2025 ] Training epoch: 189
[ Wed Dec  3 00:45:28 2025 ] 	Mean training loss: 1.1223.  Mean training acc: 87.53%.
[ Wed Dec  3 00:45:28 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:45:28 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:45:28 2025 ] Training epoch: 190
[ Wed Dec  3 00:48:40 2025 ] 	Mean training loss: 1.1307.  Mean training acc: 87.20%.
[ Wed Dec  3 00:48:40 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:48:40 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:48:40 2025 ] Training epoch: 191
[ Wed Dec  3 00:51:51 2025 ] 	Mean training loss: 1.1265.  Mean training acc: 87.17%.
[ Wed Dec  3 00:51:51 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:51:51 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:51:51 2025 ] Training epoch: 192
[ Wed Dec  3 00:55:03 2025 ] 	Mean training loss: 1.1194.  Mean training acc: 87.43%.
[ Wed Dec  3 00:55:03 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:55:03 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 00:55:03 2025 ] Training epoch: 193
[ Wed Dec  3 00:58:14 2025 ] 	Mean training loss: 1.1214.  Mean training acc: 87.28%.
[ Wed Dec  3 00:58:14 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 00:58:14 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 00:58:14 2025 ] Training epoch: 194
[ Wed Dec  3 01:01:25 2025 ] 	Mean training loss: 1.1132.  Mean training acc: 87.75%.
[ Wed Dec  3 01:01:25 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:01:25 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:01:25 2025 ] Training epoch: 195
[ Wed Dec  3 01:04:37 2025 ] 	Mean training loss: 1.1242.  Mean training acc: 87.37%.
[ Wed Dec  3 01:04:37 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:04:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:04:37 2025 ] Training epoch: 196
[ Wed Dec  3 01:07:48 2025 ] 	Mean training loss: 1.1306.  Mean training acc: 87.03%.
[ Wed Dec  3 01:07:48 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:07:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:07:48 2025 ] Training epoch: 197
[ Wed Dec  3 01:11:00 2025 ] 	Mean training loss: 1.1177.  Mean training acc: 87.56%.
[ Wed Dec  3 01:11:00 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:11:00 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:11:00 2025 ] Training epoch: 198
[ Wed Dec  3 01:14:11 2025 ] 	Mean training loss: 1.1105.  Mean training acc: 87.96%.
[ Wed Dec  3 01:14:11 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:14:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:14:11 2025 ] Training epoch: 199
[ Wed Dec  3 01:17:23 2025 ] 	Mean training loss: 1.1146.  Mean training acc: 87.72%.
[ Wed Dec  3 01:17:23 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:17:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:17:23 2025 ] Training epoch: 200
[ Wed Dec  3 01:20:34 2025 ] 	Mean training loss: 1.1141.  Mean training acc: 87.87%.
[ Wed Dec  3 01:20:34 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:20:34 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:20:34 2025 ] Training epoch: 201
[ Wed Dec  3 01:23:46 2025 ] 	Mean training loss: 1.1061.  Mean training acc: 88.07%.
[ Wed Dec  3 01:23:46 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:23:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:23:46 2025 ] Training epoch: 202
[ Wed Dec  3 01:26:58 2025 ] 	Mean training loss: 1.0980.  Mean training acc: 88.28%.
[ Wed Dec  3 01:26:58 2025 ] 	Learning Rate: 0.0007
[ Wed Dec  3 01:26:58 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 01:26:58 2025 ] Training epoch: 203
[ Wed Dec  3 01:30:09 2025 ] 	Mean training loss: 1.1158.  Mean training acc: 87.65%.
[ Wed Dec  3 01:30:09 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:30:09 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:30:09 2025 ] Training epoch: 204
[ Wed Dec  3 01:33:21 2025 ] 	Mean training loss: 1.1109.  Mean training acc: 88.05%.
[ Wed Dec  3 01:33:21 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:33:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:33:21 2025 ] Training epoch: 205
[ Wed Dec  3 01:36:32 2025 ] 	Mean training loss: 1.1020.  Mean training acc: 87.91%.
[ Wed Dec  3 01:36:32 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:36:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:36:32 2025 ] Training epoch: 206
[ Wed Dec  3 01:39:43 2025 ] 	Mean training loss: 1.0978.  Mean training acc: 88.45%.
[ Wed Dec  3 01:39:43 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:39:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:39:43 2025 ] Training epoch: 207
[ Wed Dec  3 01:42:55 2025 ] 	Mean training loss: 1.1053.  Mean training acc: 87.96%.
[ Wed Dec  3 01:42:55 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:42:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:42:55 2025 ] Training epoch: 208
[ Wed Dec  3 01:46:06 2025 ] 	Mean training loss: 1.1005.  Mean training acc: 88.06%.
[ Wed Dec  3 01:46:06 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:46:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:46:06 2025 ] Training epoch: 209
[ Wed Dec  3 01:49:18 2025 ] 	Mean training loss: 1.0958.  Mean training acc: 88.49%.
[ Wed Dec  3 01:49:18 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:49:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:49:18 2025 ] Training epoch: 210
[ Wed Dec  3 01:52:29 2025 ] 	Mean training loss: 1.0913.  Mean training acc: 88.76%.
[ Wed Dec  3 01:52:29 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:52:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:52:29 2025 ] Training epoch: 211
[ Wed Dec  3 01:55:41 2025 ] 	Mean training loss: 1.0989.  Mean training acc: 88.27%.
[ Wed Dec  3 01:55:41 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:55:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 01:55:41 2025 ] Training epoch: 212
[ Wed Dec  3 01:58:52 2025 ] 	Mean training loss: 1.0978.  Mean training acc: 88.44%.
[ Wed Dec  3 01:58:52 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 01:58:52 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 01:58:52 2025 ] Training epoch: 213
[ Wed Dec  3 02:02:04 2025 ] 	Mean training loss: 1.0826.  Mean training acc: 88.61%.
[ Wed Dec  3 02:02:04 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:02:04 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:02:04 2025 ] Training epoch: 214
[ Wed Dec  3 02:05:15 2025 ] 	Mean training loss: 1.0861.  Mean training acc: 88.85%.
[ Wed Dec  3 02:05:15 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:05:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:05:15 2025 ] Training epoch: 215
[ Wed Dec  3 02:08:27 2025 ] 	Mean training loss: 1.0862.  Mean training acc: 88.84%.
[ Wed Dec  3 02:08:27 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:08:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:08:27 2025 ] Training epoch: 216
[ Wed Dec  3 02:11:38 2025 ] 	Mean training loss: 1.0882.  Mean training acc: 88.67%.
[ Wed Dec  3 02:11:38 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:11:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:11:38 2025 ] Training epoch: 217
[ Wed Dec  3 02:14:50 2025 ] 	Mean training loss: 1.0846.  Mean training acc: 88.70%.
[ Wed Dec  3 02:14:50 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:14:50 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:14:50 2025 ] Training epoch: 218
[ Wed Dec  3 02:18:01 2025 ] 	Mean training loss: 1.0889.  Mean training acc: 88.90%.
[ Wed Dec  3 02:18:01 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:18:01 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:18:01 2025 ] Training epoch: 219
[ Wed Dec  3 02:21:13 2025 ] 	Mean training loss: 1.0847.  Mean training acc: 88.66%.
[ Wed Dec  3 02:21:13 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:21:13 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:21:13 2025 ] Training epoch: 220
[ Wed Dec  3 02:24:24 2025 ] 	Mean training loss: 1.0842.  Mean training acc: 88.89%.
[ Wed Dec  3 02:24:24 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:24:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:24:24 2025 ] Training epoch: 221
[ Wed Dec  3 02:27:36 2025 ] 	Mean training loss: 1.0792.  Mean training acc: 88.98%.
[ Wed Dec  3 02:27:36 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:27:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:27:36 2025 ] Training epoch: 222
[ Wed Dec  3 02:30:47 2025 ] 	Mean training loss: 1.0830.  Mean training acc: 88.75%.
[ Wed Dec  3 02:30:47 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:30:47 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 02:30:47 2025 ] Training epoch: 223
[ Wed Dec  3 02:33:58 2025 ] 	Mean training loss: 1.0799.  Mean training acc: 88.93%.
[ Wed Dec  3 02:33:58 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:33:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:33:58 2025 ] Training epoch: 224
[ Wed Dec  3 02:37:10 2025 ] 	Mean training loss: 1.0752.  Mean training acc: 88.90%.
[ Wed Dec  3 02:37:10 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:37:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:37:10 2025 ] Training epoch: 225
[ Wed Dec  3 02:40:22 2025 ] 	Mean training loss: 1.0784.  Mean training acc: 88.76%.
[ Wed Dec  3 02:40:22 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:40:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:40:22 2025 ] Training epoch: 226
[ Wed Dec  3 02:43:33 2025 ] 	Mean training loss: 1.0714.  Mean training acc: 89.13%.
[ Wed Dec  3 02:43:33 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:43:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:43:33 2025 ] Training epoch: 227
[ Wed Dec  3 02:46:45 2025 ] 	Mean training loss: 1.0775.  Mean training acc: 88.70%.
[ Wed Dec  3 02:46:45 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:46:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:46:45 2025 ] Training epoch: 228
[ Wed Dec  3 02:49:56 2025 ] 	Mean training loss: 1.0630.  Mean training acc: 89.43%.
[ Wed Dec  3 02:49:56 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:49:56 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:49:56 2025 ] Training epoch: 229
[ Wed Dec  3 02:53:08 2025 ] 	Mean training loss: 1.0662.  Mean training acc: 89.30%.
[ Wed Dec  3 02:53:08 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:53:08 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 02:53:08 2025 ] Training epoch: 230
[ Wed Dec  3 02:56:19 2025 ] 	Mean training loss: 1.0646.  Mean training acc: 89.55%.
[ Wed Dec  3 02:56:19 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:56:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:56:19 2025 ] Training epoch: 231
[ Wed Dec  3 02:59:30 2025 ] 	Mean training loss: 1.0606.  Mean training acc: 89.61%.
[ Wed Dec  3 02:59:30 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 02:59:30 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 02:59:30 2025 ] Training epoch: 232
[ Wed Dec  3 03:02:42 2025 ] 	Mean training loss: 1.0724.  Mean training acc: 89.41%.
[ Wed Dec  3 03:02:42 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 03:02:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:02:42 2025 ] Training epoch: 233
[ Wed Dec  3 03:05:53 2025 ] 	Mean training loss: 1.0664.  Mean training acc: 89.39%.
[ Wed Dec  3 03:05:53 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 03:05:53 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:05:53 2025 ] Training epoch: 234
[ Wed Dec  3 03:09:05 2025 ] 	Mean training loss: 1.0576.  Mean training acc: 89.69%.
[ Wed Dec  3 03:09:05 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 03:09:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:09:05 2025 ] Training epoch: 235
[ Wed Dec  3 03:12:16 2025 ] 	Mean training loss: 1.0577.  Mean training acc: 89.79%.
[ Wed Dec  3 03:12:16 2025 ] 	Learning Rate: 0.0006
[ Wed Dec  3 03:12:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:12:16 2025 ] Training epoch: 236
[ Wed Dec  3 03:15:28 2025 ] 	Mean training loss: 1.0659.  Mean training acc: 89.13%.
[ Wed Dec  3 03:15:28 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:15:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:15:28 2025 ] Training epoch: 237
[ Wed Dec  3 03:18:39 2025 ] 	Mean training loss: 1.0551.  Mean training acc: 89.82%.
[ Wed Dec  3 03:18:39 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:18:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:18:39 2025 ] Training epoch: 238
[ Wed Dec  3 03:21:51 2025 ] 	Mean training loss: 1.0595.  Mean training acc: 89.72%.
[ Wed Dec  3 03:21:51 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:21:51 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:21:51 2025 ] Training epoch: 239
[ Wed Dec  3 03:25:02 2025 ] 	Mean training loss: 1.0637.  Mean training acc: 89.79%.
[ Wed Dec  3 03:25:02 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:25:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:25:02 2025 ] Training epoch: 240
[ Wed Dec  3 03:28:14 2025 ] 	Mean training loss: 1.0625.  Mean training acc: 89.27%.
[ Wed Dec  3 03:28:14 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:28:14 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:28:14 2025 ] Training epoch: 241
[ Wed Dec  3 03:31:25 2025 ] 	Mean training loss: 1.0526.  Mean training acc: 89.75%.
[ Wed Dec  3 03:31:25 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:31:25 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:31:25 2025 ] Training epoch: 242
[ Wed Dec  3 03:34:37 2025 ] 	Mean training loss: 1.0612.  Mean training acc: 89.54%.
[ Wed Dec  3 03:34:37 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:34:37 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:34:37 2025 ] Training epoch: 243
[ Wed Dec  3 03:37:48 2025 ] 	Mean training loss: 1.0492.  Mean training acc: 90.22%.
[ Wed Dec  3 03:37:48 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:37:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:37:48 2025 ] Training epoch: 244
[ Wed Dec  3 03:40:59 2025 ] 	Mean training loss: 1.0416.  Mean training acc: 90.18%.
[ Wed Dec  3 03:40:59 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:40:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:40:59 2025 ] Training epoch: 245
[ Wed Dec  3 03:44:11 2025 ] 	Mean training loss: 1.0490.  Mean training acc: 89.97%.
[ Wed Dec  3 03:44:11 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:44:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:44:11 2025 ] Training epoch: 246
[ Wed Dec  3 03:47:22 2025 ] 	Mean training loss: 1.0424.  Mean training acc: 90.15%.
[ Wed Dec  3 03:47:22 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:47:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 03:47:22 2025 ] Training epoch: 247
[ Wed Dec  3 03:50:34 2025 ] 	Mean training loss: 1.0451.  Mean training acc: 90.25%.
[ Wed Dec  3 03:50:34 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:50:34 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:50:34 2025 ] Training epoch: 248
[ Wed Dec  3 03:53:46 2025 ] 	Mean training loss: 1.0461.  Mean training acc: 90.13%.
[ Wed Dec  3 03:53:46 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:53:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 03:53:46 2025 ] Training epoch: 249
[ Wed Dec  3 03:56:57 2025 ] 	Mean training loss: 1.0341.  Mean training acc: 90.70%.
[ Wed Dec  3 03:56:57 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 03:56:57 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 03:56:57 2025 ] Training epoch: 250
[ Wed Dec  3 04:00:09 2025 ] 	Mean training loss: 1.0381.  Mean training acc: 90.12%.
[ Wed Dec  3 04:00:09 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:00:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:00:09 2025 ] Training epoch: 251
[ Wed Dec  3 04:03:20 2025 ] 	Mean training loss: 1.0373.  Mean training acc: 90.37%.
[ Wed Dec  3 04:03:20 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:03:20 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:03:20 2025 ] Training epoch: 252
[ Wed Dec  3 04:06:32 2025 ] 	Mean training loss: 1.0305.  Mean training acc: 90.44%.
[ Wed Dec  3 04:06:32 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:06:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:06:32 2025 ] Training epoch: 253
[ Wed Dec  3 04:09:43 2025 ] 	Mean training loss: 1.0461.  Mean training acc: 89.89%.
[ Wed Dec  3 04:09:43 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:09:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:09:43 2025 ] Training epoch: 254
[ Wed Dec  3 04:12:54 2025 ] 	Mean training loss: 1.0348.  Mean training acc: 90.66%.
[ Wed Dec  3 04:12:54 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:12:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:12:54 2025 ] Training epoch: 255
[ Wed Dec  3 04:16:06 2025 ] 	Mean training loss: 1.0298.  Mean training acc: 90.76%.
[ Wed Dec  3 04:16:06 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:16:06 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:16:06 2025 ] Training epoch: 256
[ Wed Dec  3 04:19:17 2025 ] 	Mean training loss: 1.0353.  Mean training acc: 90.35%.
[ Wed Dec  3 04:19:17 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:19:17 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:19:17 2025 ] Training epoch: 257
[ Wed Dec  3 04:22:29 2025 ] 	Mean training loss: 1.0231.  Mean training acc: 90.74%.
[ Wed Dec  3 04:22:29 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:22:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:22:29 2025 ] Training epoch: 258
[ Wed Dec  3 04:25:40 2025 ] 	Mean training loss: 1.0246.  Mean training acc: 90.62%.
[ Wed Dec  3 04:25:40 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:25:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:25:40 2025 ] Training epoch: 259
[ Wed Dec  3 04:28:52 2025 ] 	Mean training loss: 1.0190.  Mean training acc: 91.07%.
[ Wed Dec  3 04:28:52 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:28:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:28:52 2025 ] Training epoch: 260
[ Wed Dec  3 04:32:03 2025 ] 	Mean training loss: 1.0250.  Mean training acc: 91.00%.
[ Wed Dec  3 04:32:03 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:32:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:32:03 2025 ] Training epoch: 261
[ Wed Dec  3 04:35:15 2025 ] 	Mean training loss: 1.0329.  Mean training acc: 90.42%.
[ Wed Dec  3 04:35:15 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:35:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 04:35:15 2025 ] Training epoch: 262
[ Wed Dec  3 04:38:26 2025 ] 	Mean training loss: 1.0202.  Mean training acc: 90.91%.
[ Wed Dec  3 04:38:26 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:38:26 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:38:26 2025 ] Training epoch: 263
[ Wed Dec  3 04:41:38 2025 ] 	Mean training loss: 1.0190.  Mean training acc: 90.57%.
[ Wed Dec  3 04:41:38 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:41:38 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:41:38 2025 ] Training epoch: 264
[ Wed Dec  3 04:44:49 2025 ] 	Mean training loss: 1.0244.  Mean training acc: 91.15%.
[ Wed Dec  3 04:44:49 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:44:49 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:44:49 2025 ] Training epoch: 265
[ Wed Dec  3 04:48:01 2025 ] 	Mean training loss: 1.0177.  Mean training acc: 91.39%.
[ Wed Dec  3 04:48:01 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:48:01 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:48:01 2025 ] Training epoch: 266
[ Wed Dec  3 04:51:12 2025 ] 	Mean training loss: 1.0261.  Mean training acc: 90.99%.
[ Wed Dec  3 04:51:12 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:51:12 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:51:12 2025 ] Training epoch: 267
[ Wed Dec  3 04:54:24 2025 ] 	Mean training loss: 1.0204.  Mean training acc: 91.18%.
[ Wed Dec  3 04:54:24 2025 ] 	Learning Rate: 0.0005
[ Wed Dec  3 04:54:24 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 04:54:24 2025 ] Training epoch: 268
[ Wed Dec  3 04:57:35 2025 ] 	Mean training loss: 0.9992.  Mean training acc: 91.82%.
[ Wed Dec  3 04:57:35 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 04:57:35 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 04:57:35 2025 ] Training epoch: 269
[ Wed Dec  3 05:00:47 2025 ] 	Mean training loss: 1.0152.  Mean training acc: 91.27%.
[ Wed Dec  3 05:00:47 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:00:47 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 05:00:47 2025 ] Training epoch: 270
[ Wed Dec  3 05:03:58 2025 ] 	Mean training loss: 1.0174.  Mean training acc: 90.93%.
[ Wed Dec  3 05:03:58 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:03:58 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:03:58 2025 ] Training epoch: 271
[ Wed Dec  3 05:07:10 2025 ] 	Mean training loss: 1.0056.  Mean training acc: 91.23%.
[ Wed Dec  3 05:07:10 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:07:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:07:10 2025 ] Training epoch: 272
[ Wed Dec  3 05:10:21 2025 ] 	Mean training loss: 1.0119.  Mean training acc: 91.37%.
[ Wed Dec  3 05:10:21 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:10:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:10:21 2025 ] Training epoch: 273
[ Wed Dec  3 05:13:33 2025 ] 	Mean training loss: 1.0074.  Mean training acc: 91.42%.
[ Wed Dec  3 05:13:33 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:13:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:13:33 2025 ] Training epoch: 274
[ Wed Dec  3 05:16:44 2025 ] 	Mean training loss: 1.0056.  Mean training acc: 91.50%.
[ Wed Dec  3 05:16:44 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:16:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:16:44 2025 ] Training epoch: 275
[ Wed Dec  3 05:19:55 2025 ] 	Mean training loss: 1.0116.  Mean training acc: 91.03%.
[ Wed Dec  3 05:19:55 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:19:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:19:55 2025 ] Training epoch: 276
[ Wed Dec  3 05:23:07 2025 ] 	Mean training loss: 1.0043.  Mean training acc: 91.58%.
[ Wed Dec  3 05:23:07 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:23:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:23:07 2025 ] Training epoch: 277
[ Wed Dec  3 05:26:19 2025 ] 	Mean training loss: 0.9984.  Mean training acc: 91.81%.
[ Wed Dec  3 05:26:19 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:26:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:26:19 2025 ] Training epoch: 278
[ Wed Dec  3 05:29:30 2025 ] 	Mean training loss: 0.9975.  Mean training acc: 91.90%.
[ Wed Dec  3 05:29:30 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:29:30 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:29:30 2025 ] Training epoch: 279
[ Wed Dec  3 05:32:42 2025 ] 	Mean training loss: 0.9929.  Mean training acc: 92.13%.
[ Wed Dec  3 05:32:42 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:32:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:32:42 2025 ] Training epoch: 280
[ Wed Dec  3 05:35:53 2025 ] 	Mean training loss: 0.9980.  Mean training acc: 91.97%.
[ Wed Dec  3 05:35:53 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:35:53 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:35:53 2025 ] Training epoch: 281
[ Wed Dec  3 05:39:05 2025 ] 	Mean training loss: 0.9908.  Mean training acc: 92.09%.
[ Wed Dec  3 05:39:05 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:39:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:39:05 2025 ] Training epoch: 282
[ Wed Dec  3 05:42:16 2025 ] 	Mean training loss: 1.0021.  Mean training acc: 91.35%.
[ Wed Dec  3 05:42:16 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:42:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:42:16 2025 ] Training epoch: 283
[ Wed Dec  3 05:45:27 2025 ] 	Mean training loss: 0.9947.  Mean training acc: 91.97%.
[ Wed Dec  3 05:45:27 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:45:27 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:45:27 2025 ] Training epoch: 284
[ Wed Dec  3 05:48:39 2025 ] 	Mean training loss: 0.9928.  Mean training acc: 91.86%.
[ Wed Dec  3 05:48:39 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:48:39 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:48:39 2025 ] Training epoch: 285
[ Wed Dec  3 05:51:50 2025 ] 	Mean training loss: 0.9938.  Mean training acc: 91.76%.
[ Wed Dec  3 05:51:50 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:51:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 05:51:50 2025 ] Training epoch: 286
[ Wed Dec  3 05:55:02 2025 ] 	Mean training loss: 0.9847.  Mean training acc: 92.13%.
[ Wed Dec  3 05:55:02 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:55:02 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:55:02 2025 ] Training epoch: 287
[ Wed Dec  3 05:58:13 2025 ] 	Mean training loss: 0.9865.  Mean training acc: 92.27%.
[ Wed Dec  3 05:58:13 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 05:58:13 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 05:58:13 2025 ] Training epoch: 288
[ Wed Dec  3 06:01:25 2025 ] 	Mean training loss: 0.9918.  Mean training acc: 92.14%.
[ Wed Dec  3 06:01:25 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:01:25 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:01:25 2025 ] Training epoch: 289
[ Wed Dec  3 06:04:37 2025 ] 	Mean training loss: 0.9878.  Mean training acc: 92.01%.
[ Wed Dec  3 06:04:37 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:04:37 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:04:37 2025 ] Training epoch: 290
[ Wed Dec  3 06:07:48 2025 ] 	Mean training loss: 0.9866.  Mean training acc: 92.10%.
[ Wed Dec  3 06:07:48 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:07:48 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:07:48 2025 ] Training epoch: 291
[ Wed Dec  3 06:11:00 2025 ] 	Mean training loss: 0.9853.  Mean training acc: 92.15%.
[ Wed Dec  3 06:11:00 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:11:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:11:00 2025 ] Training epoch: 292
[ Wed Dec  3 06:14:11 2025 ] 	Mean training loss: 0.9815.  Mean training acc: 92.30%.
[ Wed Dec  3 06:14:11 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:14:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 06:14:11 2025 ] Training epoch: 293
[ Wed Dec  3 06:17:23 2025 ] 	Mean training loss: 0.9872.  Mean training acc: 92.34%.
[ Wed Dec  3 06:17:23 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:17:23 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:17:23 2025 ] Training epoch: 294
[ Wed Dec  3 06:20:34 2025 ] 	Mean training loss: 0.9822.  Mean training acc: 92.11%.
[ Wed Dec  3 06:20:34 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:20:34 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:20:34 2025 ] Training epoch: 295
[ Wed Dec  3 06:23:46 2025 ] 	Mean training loss: 0.9776.  Mean training acc: 92.44%.
[ Wed Dec  3 06:23:46 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:23:46 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:23:46 2025 ] Training epoch: 296
[ Wed Dec  3 06:26:57 2025 ] 	Mean training loss: 0.9782.  Mean training acc: 92.46%.
[ Wed Dec  3 06:26:57 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:26:57 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:26:57 2025 ] Training epoch: 297
[ Wed Dec  3 06:30:09 2025 ] 	Mean training loss: 0.9777.  Mean training acc: 92.45%.
[ Wed Dec  3 06:30:09 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:30:09 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:30:09 2025 ] Training epoch: 298
[ Wed Dec  3 06:33:20 2025 ] 	Mean training loss: 0.9770.  Mean training acc: 92.66%.
[ Wed Dec  3 06:33:20 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:33:20 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:33:20 2025 ] Training epoch: 299
[ Wed Dec  3 06:36:32 2025 ] 	Mean training loss: 0.9673.  Mean training acc: 92.90%.
[ Wed Dec  3 06:36:32 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:36:32 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:36:32 2025 ] Training epoch: 300
[ Wed Dec  3 06:39:43 2025 ] 	Mean training loss: 0.9697.  Mean training acc: 92.76%.
[ Wed Dec  3 06:39:43 2025 ] 	Learning Rate: 0.0004
[ Wed Dec  3 06:39:43 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:39:43 2025 ] Training epoch: 301
[ Wed Dec  3 06:42:55 2025 ] 	Mean training loss: 0.9694.  Mean training acc: 92.74%.
[ Wed Dec  3 06:42:55 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 06:42:55 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:42:55 2025 ] Training epoch: 302
[ Wed Dec  3 06:46:06 2025 ] 	Mean training loss: 0.9720.  Mean training acc: 92.55%.
[ Wed Dec  3 06:46:06 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 06:46:06 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:46:06 2025 ] Training epoch: 303
[ Wed Dec  3 06:49:18 2025 ] 	Mean training loss: 0.9711.  Mean training acc: 92.77%.
[ Wed Dec  3 06:49:18 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 06:49:18 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:49:18 2025 ] Training epoch: 304
[ Wed Dec  3 06:52:29 2025 ] 	Mean training loss: 0.9561.  Mean training acc: 93.16%.
[ Wed Dec  3 06:52:29 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 06:52:29 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:52:29 2025 ] Training epoch: 305
[ Wed Dec  3 06:55:41 2025 ] 	Mean training loss: 0.9646.  Mean training acc: 92.73%.
[ Wed Dec  3 06:55:41 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 06:55:41 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 06:55:41 2025 ] Training epoch: 306
[ Wed Dec  3 06:58:52 2025 ] 	Mean training loss: 0.9555.  Mean training acc: 93.08%.
[ Wed Dec  3 06:58:52 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 06:58:52 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 06:58:52 2025 ] Training epoch: 307
[ Wed Dec  3 07:02:03 2025 ] 	Mean training loss: 0.9581.  Mean training acc: 92.96%.
[ Wed Dec  3 07:02:03 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:02:03 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:02:03 2025 ] Training epoch: 308
[ Wed Dec  3 07:05:15 2025 ] 	Mean training loss: 0.9663.  Mean training acc: 93.00%.
[ Wed Dec  3 07:05:15 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:05:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:05:15 2025 ] Training epoch: 309
[ Wed Dec  3 07:08:26 2025 ] 	Mean training loss: 0.9520.  Mean training acc: 93.43%.
[ Wed Dec  3 07:08:26 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:08:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:08:26 2025 ] Training epoch: 310
[ Wed Dec  3 07:11:38 2025 ] 	Mean training loss: 0.9658.  Mean training acc: 92.88%.
[ Wed Dec  3 07:11:38 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:11:38 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:11:38 2025 ] Training epoch: 311
[ Wed Dec  3 07:14:49 2025 ] 	Mean training loss: 0.9547.  Mean training acc: 93.25%.
[ Wed Dec  3 07:14:49 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:14:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:14:49 2025 ] Training epoch: 312
[ Wed Dec  3 07:18:01 2025 ] 	Mean training loss: 0.9549.  Mean training acc: 93.33%.
[ Wed Dec  3 07:18:01 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:18:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:18:01 2025 ] Training epoch: 313
[ Wed Dec  3 07:21:12 2025 ] 	Mean training loss: 0.9523.  Mean training acc: 93.19%.
[ Wed Dec  3 07:21:12 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:21:12 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:21:12 2025 ] Training epoch: 314
[ Wed Dec  3 07:24:23 2025 ] 	Mean training loss: 0.9553.  Mean training acc: 93.08%.
[ Wed Dec  3 07:24:23 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:24:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:24:23 2025 ] Training epoch: 315
[ Wed Dec  3 07:27:35 2025 ] 	Mean training loss: 0.9478.  Mean training acc: 93.63%.
[ Wed Dec  3 07:27:35 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:27:35 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:27:35 2025 ] Training epoch: 316
[ Wed Dec  3 07:30:46 2025 ] 	Mean training loss: 0.9492.  Mean training acc: 93.42%.
[ Wed Dec  3 07:30:46 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:30:46 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:30:46 2025 ] Training epoch: 317
[ Wed Dec  3 07:33:58 2025 ] 	Mean training loss: 0.9512.  Mean training acc: 93.06%.
[ Wed Dec  3 07:33:58 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:33:58 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 07:33:58 2025 ] Training epoch: 318
[ Wed Dec  3 07:37:09 2025 ] 	Mean training loss: 0.9482.  Mean training acc: 93.64%.
[ Wed Dec  3 07:37:09 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:37:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:37:09 2025 ] Training epoch: 319
[ Wed Dec  3 07:40:21 2025 ] 	Mean training loss: 0.9437.  Mean training acc: 93.52%.
[ Wed Dec  3 07:40:21 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:40:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:40:21 2025 ] Training epoch: 320
[ Wed Dec  3 07:43:32 2025 ] 	Mean training loss: 0.9392.  Mean training acc: 93.77%.
[ Wed Dec  3 07:43:32 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:43:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:43:32 2025 ] Training epoch: 321
[ Wed Dec  3 07:46:43 2025 ] 	Mean training loss: 0.9508.  Mean training acc: 93.52%.
[ Wed Dec  3 07:46:43 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:46:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:46:43 2025 ] Training epoch: 322
[ Wed Dec  3 07:49:55 2025 ] 	Mean training loss: 0.9439.  Mean training acc: 93.83%.
[ Wed Dec  3 07:49:55 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:49:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:49:55 2025 ] Training epoch: 323
[ Wed Dec  3 07:53:06 2025 ] 	Mean training loss: 0.9381.  Mean training acc: 93.78%.
[ Wed Dec  3 07:53:06 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:53:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:53:06 2025 ] Training epoch: 324
[ Wed Dec  3 07:56:18 2025 ] 	Mean training loss: 0.9387.  Mean training acc: 93.78%.
[ Wed Dec  3 07:56:18 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:56:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 07:56:18 2025 ] Training epoch: 325
[ Wed Dec  3 07:59:29 2025 ] 	Mean training loss: 0.9331.  Mean training acc: 94.08%.
[ Wed Dec  3 07:59:29 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 07:59:29 2025 ] 	Time consumption: [Data]08%, [Network]91%
[ Wed Dec  3 07:59:29 2025 ] Training epoch: 326
[ Wed Dec  3 08:02:40 2025 ] 	Mean training loss: 0.9347.  Mean training acc: 93.95%.
[ Wed Dec  3 08:02:40 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:02:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:02:40 2025 ] Training epoch: 327
[ Wed Dec  3 08:05:52 2025 ] 	Mean training loss: 0.9322.  Mean training acc: 93.63%.
[ Wed Dec  3 08:05:52 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:05:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:05:52 2025 ] Training epoch: 328
[ Wed Dec  3 08:08:59 2025 ] 	Mean training loss: 0.9337.  Mean training acc: 93.94%.
[ Wed Dec  3 08:08:59 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:08:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:08:59 2025 ] Training epoch: 329
[ Wed Dec  3 08:12:00 2025 ] 	Mean training loss: 0.9251.  Mean training acc: 94.02%.
[ Wed Dec  3 08:12:00 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:12:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:12:00 2025 ] Training epoch: 330
[ Wed Dec  3 08:15:09 2025 ] 	Mean training loss: 0.9230.  Mean training acc: 94.54%.
[ Wed Dec  3 08:15:09 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:15:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:15:09 2025 ] Training epoch: 331
[ Wed Dec  3 08:18:10 2025 ] 	Mean training loss: 0.9268.  Mean training acc: 94.30%.
[ Wed Dec  3 08:18:10 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:18:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:18:10 2025 ] Training epoch: 332
[ Wed Dec  3 08:21:16 2025 ] 	Mean training loss: 0.9325.  Mean training acc: 94.12%.
[ Wed Dec  3 08:21:16 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:21:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:21:16 2025 ] Training epoch: 333
[ Wed Dec  3 08:24:20 2025 ] 	Mean training loss: 0.9250.  Mean training acc: 94.28%.
[ Wed Dec  3 08:24:20 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:24:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:24:20 2025 ] Training epoch: 334
[ Wed Dec  3 08:27:22 2025 ] 	Mean training loss: 0.9325.  Mean training acc: 94.02%.
[ Wed Dec  3 08:27:22 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:27:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:27:22 2025 ] Training epoch: 335
[ Wed Dec  3 08:30:29 2025 ] 	Mean training loss: 0.9212.  Mean training acc: 94.23%.
[ Wed Dec  3 08:30:29 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:30:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:30:29 2025 ] Training epoch: 336
[ Wed Dec  3 08:33:31 2025 ] 	Mean training loss: 0.9273.  Mean training acc: 94.25%.
[ Wed Dec  3 08:33:31 2025 ] 	Learning Rate: 0.0003
[ Wed Dec  3 08:33:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:33:31 2025 ] Training epoch: 337
[ Wed Dec  3 08:36:39 2025 ] 	Mean training loss: 0.9257.  Mean training acc: 94.25%.
[ Wed Dec  3 08:36:39 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 08:36:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:36:39 2025 ] Training epoch: 338
[ Wed Dec  3 08:39:40 2025 ] 	Mean training loss: 0.9235.  Mean training acc: 94.26%.
[ Wed Dec  3 08:39:40 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 08:39:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:39:40 2025 ] Training epoch: 339
[ Wed Dec  3 08:42:45 2025 ] 	Mean training loss: 0.9160.  Mean training acc: 94.61%.
[ Wed Dec  3 08:42:45 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 08:42:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:42:45 2025 ] Training epoch: 340
[ Wed Dec  3 08:45:50 2025 ] 	Mean training loss: 0.9227.  Mean training acc: 94.31%.
[ Wed Dec  3 08:45:50 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 08:45:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:45:50 2025 ] Training epoch: 341
[ Wed Dec  3 08:48:51 2025 ] 	Mean training loss: 0.9136.  Mean training acc: 94.44%.
[ Wed Dec  3 08:48:51 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 08:48:51 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:48:51 2025 ] Training epoch: 342
[ Wed Dec  3 08:51:59 2025 ] 	Mean training loss: 0.9150.  Mean training acc: 94.54%.
[ Wed Dec  3 08:51:59 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 08:51:59 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:51:59 2025 ] Training epoch: 343
[ Wed Dec  3 08:55:01 2025 ] 	Mean training loss: 0.9118.  Mean training acc: 94.38%.
[ Wed Dec  3 08:55:01 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 08:55:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:55:01 2025 ] Training epoch: 344
[ Wed Dec  3 08:58:09 2025 ] 	Mean training loss: 0.9088.  Mean training acc: 94.76%.
[ Wed Dec  3 08:58:09 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 08:58:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 08:58:09 2025 ] Training epoch: 345
[ Wed Dec  3 09:01:11 2025 ] 	Mean training loss: 0.9105.  Mean training acc: 94.94%.
[ Wed Dec  3 09:01:11 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:01:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:01:11 2025 ] Training epoch: 346
[ Wed Dec  3 09:04:15 2025 ] 	Mean training loss: 0.9081.  Mean training acc: 94.79%.
[ Wed Dec  3 09:04:15 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:04:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:04:16 2025 ] Training epoch: 347
[ Wed Dec  3 09:07:20 2025 ] 	Mean training loss: 0.9063.  Mean training acc: 94.58%.
[ Wed Dec  3 09:07:20 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:07:20 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:07:20 2025 ] Training epoch: 348
[ Wed Dec  3 09:10:22 2025 ] 	Mean training loss: 0.9103.  Mean training acc: 94.57%.
[ Wed Dec  3 09:10:22 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:10:22 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:10:22 2025 ] Training epoch: 349
[ Wed Dec  3 09:13:30 2025 ] 	Mean training loss: 0.9103.  Mean training acc: 94.70%.
[ Wed Dec  3 09:13:30 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:13:30 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:13:30 2025 ] Training epoch: 350
[ Wed Dec  3 09:16:31 2025 ] 	Mean training loss: 0.9026.  Mean training acc: 95.05%.
[ Wed Dec  3 09:16:31 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:16:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:16:31 2025 ] Training epoch: 351
[ Wed Dec  3 09:19:39 2025 ] 	Mean training loss: 0.8986.  Mean training acc: 95.16%.
[ Wed Dec  3 09:19:39 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:19:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:19:39 2025 ] Training epoch: 352
[ Wed Dec  3 09:22:41 2025 ] 	Mean training loss: 0.9073.  Mean training acc: 94.82%.
[ Wed Dec  3 09:22:41 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:22:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:22:41 2025 ] Training epoch: 353
[ Wed Dec  3 09:25:45 2025 ] 	Mean training loss: 0.8971.  Mean training acc: 95.43%.
[ Wed Dec  3 09:25:45 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:25:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:25:45 2025 ] Training epoch: 354
[ Wed Dec  3 09:28:51 2025 ] 	Mean training loss: 0.8989.  Mean training acc: 95.09%.
[ Wed Dec  3 09:28:51 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:28:51 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:28:51 2025 ] Training epoch: 355
[ Wed Dec  3 09:31:52 2025 ] 	Mean training loss: 0.8931.  Mean training acc: 95.34%.
[ Wed Dec  3 09:31:52 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:31:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:31:52 2025 ] Training epoch: 356
[ Wed Dec  3 09:35:00 2025 ] 	Mean training loss: 0.9029.  Mean training acc: 95.15%.
[ Wed Dec  3 09:35:00 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:35:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:35:00 2025 ] Training epoch: 357
[ Wed Dec  3 09:38:02 2025 ] 	Mean training loss: 0.8973.  Mean training acc: 94.98%.
[ Wed Dec  3 09:38:02 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:38:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:38:02 2025 ] Training epoch: 358
[ Wed Dec  3 09:41:09 2025 ] 	Mean training loss: 0.8965.  Mean training acc: 95.22%.
[ Wed Dec  3 09:41:09 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:41:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:41:09 2025 ] Training epoch: 359
[ Wed Dec  3 09:44:12 2025 ] 	Mean training loss: 0.8902.  Mean training acc: 95.54%.
[ Wed Dec  3 09:44:12 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:44:12 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:44:12 2025 ] Training epoch: 360
[ Wed Dec  3 09:47:16 2025 ] 	Mean training loss: 0.8901.  Mean training acc: 95.41%.
[ Wed Dec  3 09:47:16 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:47:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:47:16 2025 ] Training epoch: 361
[ Wed Dec  3 09:50:21 2025 ] 	Mean training loss: 0.8908.  Mean training acc: 95.33%.
[ Wed Dec  3 09:50:21 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:50:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:50:21 2025 ] Training epoch: 362
[ Wed Dec  3 09:53:23 2025 ] 	Mean training loss: 0.8918.  Mean training acc: 95.24%.
[ Wed Dec  3 09:53:23 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:53:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:53:23 2025 ] Training epoch: 363
[ Wed Dec  3 09:56:31 2025 ] 	Mean training loss: 0.8795.  Mean training acc: 95.57%.
[ Wed Dec  3 09:56:31 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:56:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:56:31 2025 ] Training epoch: 364
[ Wed Dec  3 09:59:32 2025 ] 	Mean training loss: 0.8798.  Mean training acc: 95.75%.
[ Wed Dec  3 09:59:32 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 09:59:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 09:59:32 2025 ] Training epoch: 365
[ Wed Dec  3 10:02:40 2025 ] 	Mean training loss: 0.8817.  Mean training acc: 95.76%.
[ Wed Dec  3 10:02:40 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:02:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:02:40 2025 ] Training epoch: 366
[ Wed Dec  3 10:05:42 2025 ] 	Mean training loss: 0.8846.  Mean training acc: 95.47%.
[ Wed Dec  3 10:05:42 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:05:42 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:05:42 2025 ] Training epoch: 367
[ Wed Dec  3 10:08:46 2025 ] 	Mean training loss: 0.8764.  Mean training acc: 95.85%.
[ Wed Dec  3 10:08:46 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:08:46 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:08:46 2025 ] Training epoch: 368
[ Wed Dec  3 10:11:52 2025 ] 	Mean training loss: 0.8843.  Mean training acc: 95.67%.
[ Wed Dec  3 10:11:52 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:11:52 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:11:52 2025 ] Training epoch: 369
[ Wed Dec  3 10:14:53 2025 ] 	Mean training loss: 0.8770.  Mean training acc: 95.87%.
[ Wed Dec  3 10:14:53 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:14:53 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:14:53 2025 ] Training epoch: 370
[ Wed Dec  3 10:18:02 2025 ] 	Mean training loss: 0.8836.  Mean training acc: 95.54%.
[ Wed Dec  3 10:18:02 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:18:02 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:18:02 2025 ] Training epoch: 371
[ Wed Dec  3 10:21:03 2025 ] 	Mean training loss: 0.8809.  Mean training acc: 95.83%.
[ Wed Dec  3 10:21:03 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:21:03 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:21:03 2025 ] Training epoch: 372
[ Wed Dec  3 10:24:10 2025 ] 	Mean training loss: 0.8813.  Mean training acc: 95.58%.
[ Wed Dec  3 10:24:10 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:24:10 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:24:10 2025 ] Training epoch: 373
[ Wed Dec  3 10:27:13 2025 ] 	Mean training loss: 0.8802.  Mean training acc: 95.71%.
[ Wed Dec  3 10:27:13 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:27:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:27:13 2025 ] Training epoch: 374
[ Wed Dec  3 10:30:17 2025 ] 	Mean training loss: 0.8720.  Mean training acc: 96.03%.
[ Wed Dec  3 10:30:17 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:30:17 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:30:17 2025 ] Training epoch: 375
[ Wed Dec  3 10:33:23 2025 ] 	Mean training loss: 0.8740.  Mean training acc: 96.14%.
[ Wed Dec  3 10:33:23 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:33:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:33:23 2025 ] Training epoch: 376
[ Wed Dec  3 10:36:24 2025 ] 	Mean training loss: 0.8774.  Mean training acc: 95.70%.
[ Wed Dec  3 10:36:24 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:36:24 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:36:24 2025 ] Training epoch: 377
[ Wed Dec  3 10:39:33 2025 ] 	Mean training loss: 0.8642.  Mean training acc: 96.41%.
[ Wed Dec  3 10:39:33 2025 ] 	Learning Rate: 0.0002
[ Wed Dec  3 10:39:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:39:33 2025 ] Training epoch: 378
[ Wed Dec  3 10:42:34 2025 ] 	Mean training loss: 0.8686.  Mean training acc: 96.08%.
[ Wed Dec  3 10:42:34 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 10:42:34 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:42:34 2025 ] Training epoch: 379
[ Wed Dec  3 10:45:41 2025 ] 	Mean training loss: 0.8625.  Mean training acc: 96.39%.
[ Wed Dec  3 10:45:41 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 10:45:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:45:41 2025 ] Training epoch: 380
[ Wed Dec  3 10:48:44 2025 ] 	Mean training loss: 0.8663.  Mean training acc: 96.29%.
[ Wed Dec  3 10:48:44 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 10:48:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:48:44 2025 ] Training epoch: 381
[ Wed Dec  3 10:51:47 2025 ] 	Mean training loss: 0.8641.  Mean training acc: 96.16%.
[ Wed Dec  3 10:51:47 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 10:51:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:51:47 2025 ] Training epoch: 382
[ Wed Dec  3 10:54:54 2025 ] 	Mean training loss: 0.8624.  Mean training acc: 96.41%.
[ Wed Dec  3 10:54:54 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 10:54:54 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:54:54 2025 ] Training epoch: 383
[ Wed Dec  3 10:57:55 2025 ] 	Mean training loss: 0.8643.  Mean training acc: 96.22%.
[ Wed Dec  3 10:57:55 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 10:57:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 10:57:55 2025 ] Training epoch: 384
[ Wed Dec  3 11:01:03 2025 ] 	Mean training loss: 0.8599.  Mean training acc: 96.41%.
[ Wed Dec  3 11:01:03 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:01:03 2025 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Dec  3 11:01:03 2025 ] Training epoch: 385
[ Wed Dec  3 11:04:05 2025 ] 	Mean training loss: 0.8726.  Mean training acc: 96.00%.
[ Wed Dec  3 11:04:05 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:04:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:04:05 2025 ] Training epoch: 386
[ Wed Dec  3 11:07:11 2025 ] 	Mean training loss: 0.8628.  Mean training acc: 96.21%.
[ Wed Dec  3 11:07:11 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:07:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:07:11 2025 ] Training epoch: 387
[ Wed Dec  3 11:10:15 2025 ] 	Mean training loss: 0.8537.  Mean training acc: 96.52%.
[ Wed Dec  3 11:10:15 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:10:15 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:10:15 2025 ] Training epoch: 388
[ Wed Dec  3 11:13:18 2025 ] 	Mean training loss: 0.8567.  Mean training acc: 96.43%.
[ Wed Dec  3 11:13:18 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:13:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:13:18 2025 ] Training epoch: 389
[ Wed Dec  3 11:16:25 2025 ] 	Mean training loss: 0.8593.  Mean training acc: 96.52%.
[ Wed Dec  3 11:16:25 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:16:25 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:16:25 2025 ] Training epoch: 390
[ Wed Dec  3 11:19:26 2025 ] 	Mean training loss: 0.8548.  Mean training acc: 96.78%.
[ Wed Dec  3 11:19:26 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:19:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:19:26 2025 ] Training epoch: 391
[ Wed Dec  3 11:22:34 2025 ] 	Mean training loss: 0.8499.  Mean training acc: 96.78%.
[ Wed Dec  3 11:22:34 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:22:34 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:22:34 2025 ] Training epoch: 392
[ Wed Dec  3 11:25:36 2025 ] 	Mean training loss: 0.8518.  Mean training acc: 96.59%.
[ Wed Dec  3 11:25:36 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:25:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:25:36 2025 ] Training epoch: 393
[ Wed Dec  3 11:28:41 2025 ] 	Mean training loss: 0.8475.  Mean training acc: 96.60%.
[ Wed Dec  3 11:28:41 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:28:41 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:28:41 2025 ] Training epoch: 394
[ Wed Dec  3 11:31:45 2025 ] 	Mean training loss: 0.8541.  Mean training acc: 96.67%.
[ Wed Dec  3 11:31:45 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:31:45 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:31:45 2025 ] Training epoch: 395
[ Wed Dec  3 11:34:48 2025 ] 	Mean training loss: 0.8510.  Mean training acc: 96.59%.
[ Wed Dec  3 11:34:48 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:34:48 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:34:48 2025 ] Training epoch: 396
[ Wed Dec  3 11:37:55 2025 ] 	Mean training loss: 0.8569.  Mean training acc: 96.57%.
[ Wed Dec  3 11:37:55 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:37:55 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:37:55 2025 ] Training epoch: 397
[ Wed Dec  3 11:40:56 2025 ] 	Mean training loss: 0.8503.  Mean training acc: 96.71%.
[ Wed Dec  3 11:40:56 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:40:56 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:40:56 2025 ] Training epoch: 398
[ Wed Dec  3 11:44:05 2025 ] 	Mean training loss: 0.8473.  Mean training acc: 96.84%.
[ Wed Dec  3 11:44:05 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:44:05 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:44:05 2025 ] Training epoch: 399
[ Wed Dec  3 11:47:06 2025 ] 	Mean training loss: 0.8470.  Mean training acc: 96.72%.
[ Wed Dec  3 11:47:06 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:47:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:47:06 2025 ] Training epoch: 400
[ Wed Dec  3 11:50:12 2025 ] 	Mean training loss: 0.8419.  Mean training acc: 96.81%.
[ Wed Dec  3 11:50:12 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:50:12 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:50:12 2025 ] Training epoch: 401
[ Wed Dec  3 11:53:16 2025 ] 	Mean training loss: 0.8430.  Mean training acc: 97.07%.
[ Wed Dec  3 11:53:16 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:53:16 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:53:16 2025 ] Training epoch: 402
[ Wed Dec  3 11:56:18 2025 ] 	Mean training loss: 0.8361.  Mean training acc: 97.16%.
[ Wed Dec  3 11:56:18 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:56:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:56:18 2025 ] Training epoch: 403
[ Wed Dec  3 11:59:26 2025 ] 	Mean training loss: 0.8469.  Mean training acc: 96.78%.
[ Wed Dec  3 11:59:26 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 11:59:26 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 11:59:26 2025 ] Training epoch: 404
[ Wed Dec  3 12:02:28 2025 ] 	Mean training loss: 0.8434.  Mean training acc: 96.74%.
[ Wed Dec  3 12:02:28 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:02:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:02:28 2025 ] Training epoch: 405
[ Wed Dec  3 12:05:36 2025 ] 	Mean training loss: 0.8443.  Mean training acc: 96.86%.
[ Wed Dec  3 12:05:36 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:05:36 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:05:36 2025 ] Training epoch: 406
[ Wed Dec  3 12:08:38 2025 ] 	Mean training loss: 0.8434.  Mean training acc: 96.89%.
[ Wed Dec  3 12:08:38 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:08:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:08:38 2025 ] Training epoch: 407
[ Wed Dec  3 12:11:43 2025 ] 	Mean training loss: 0.8356.  Mean training acc: 97.06%.
[ Wed Dec  3 12:11:43 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:11:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:11:43 2025 ] Training epoch: 408
[ Wed Dec  3 12:14:47 2025 ] 	Mean training loss: 0.8358.  Mean training acc: 97.02%.
[ Wed Dec  3 12:14:47 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:14:47 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:14:47 2025 ] Training epoch: 409
[ Wed Dec  3 12:17:49 2025 ] 	Mean training loss: 0.8378.  Mean training acc: 97.07%.
[ Wed Dec  3 12:17:49 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:17:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:17:49 2025 ] Training epoch: 410
[ Wed Dec  3 12:20:57 2025 ] 	Mean training loss: 0.8326.  Mean training acc: 97.30%.
[ Wed Dec  3 12:20:57 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:20:57 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:20:57 2025 ] Training epoch: 411
[ Wed Dec  3 12:23:58 2025 ] 	Mean training loss: 0.8307.  Mean training acc: 97.28%.
[ Wed Dec  3 12:23:58 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:23:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:23:58 2025 ] Training epoch: 412
[ Wed Dec  3 12:27:06 2025 ] 	Mean training loss: 0.8357.  Mean training acc: 97.17%.
[ Wed Dec  3 12:27:06 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:27:06 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:27:06 2025 ] Training epoch: 413
[ Wed Dec  3 12:30:08 2025 ] 	Mean training loss: 0.8319.  Mean training acc: 97.18%.
[ Wed Dec  3 12:30:08 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:30:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:30:08 2025 ] Training epoch: 414
[ Wed Dec  3 12:33:12 2025 ] 	Mean training loss: 0.8339.  Mean training acc: 97.34%.
[ Wed Dec  3 12:33:12 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:33:12 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:33:12 2025 ] Training epoch: 415
[ Wed Dec  3 12:36:18 2025 ] 	Mean training loss: 0.8302.  Mean training acc: 97.42%.
[ Wed Dec  3 12:36:18 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:36:18 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:36:18 2025 ] Training epoch: 416
[ Wed Dec  3 12:39:19 2025 ] 	Mean training loss: 0.8272.  Mean training acc: 97.42%.
[ Wed Dec  3 12:39:19 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:39:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:39:19 2025 ] Training epoch: 417
[ Wed Dec  3 12:42:28 2025 ] 	Mean training loss: 0.8298.  Mean training acc: 97.22%.
[ Wed Dec  3 12:42:28 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:42:28 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:42:28 2025 ] Training epoch: 418
[ Wed Dec  3 12:45:29 2025 ] 	Mean training loss: 0.8275.  Mean training acc: 97.36%.
[ Wed Dec  3 12:45:29 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:45:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:45:29 2025 ] Training epoch: 419
[ Wed Dec  3 12:48:37 2025 ] 	Mean training loss: 0.8285.  Mean training acc: 97.39%.
[ Wed Dec  3 12:48:37 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:48:37 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:48:37 2025 ] Training epoch: 420
[ Wed Dec  3 12:51:39 2025 ] 	Mean training loss: 0.8269.  Mean training acc: 97.46%.
[ Wed Dec  3 12:51:39 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:51:39 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:51:39 2025 ] Training epoch: 421
[ Wed Dec  3 12:54:43 2025 ] 	Mean training loss: 0.8272.  Mean training acc: 97.30%.
[ Wed Dec  3 12:54:43 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:54:43 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:54:43 2025 ] Training epoch: 422
[ Wed Dec  3 12:57:49 2025 ] 	Mean training loss: 0.8245.  Mean training acc: 97.49%.
[ Wed Dec  3 12:57:49 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 12:57:49 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 12:57:49 2025 ] Training epoch: 423
[ Wed Dec  3 13:00:50 2025 ] 	Mean training loss: 0.8252.  Mean training acc: 97.45%.
[ Wed Dec  3 13:00:50 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:00:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:00:50 2025 ] Training epoch: 424
[ Wed Dec  3 13:03:58 2025 ] 	Mean training loss: 0.8282.  Mean training acc: 97.43%.
[ Wed Dec  3 13:03:58 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:03:58 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:03:58 2025 ] Training epoch: 425
[ Wed Dec  3 13:07:00 2025 ] 	Mean training loss: 0.8192.  Mean training acc: 97.52%.
[ Wed Dec  3 13:07:00 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:07:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:07:00 2025 ] Training epoch: 426
[ Wed Dec  3 13:10:07 2025 ] 	Mean training loss: 0.8159.  Mean training acc: 97.77%.
[ Wed Dec  3 13:10:07 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:10:07 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:10:07 2025 ] Training epoch: 427
[ Wed Dec  3 13:13:09 2025 ] 	Mean training loss: 0.8244.  Mean training acc: 97.34%.
[ Wed Dec  3 13:13:09 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:13:09 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:13:09 2025 ] Training epoch: 428
[ Wed Dec  3 13:16:13 2025 ] 	Mean training loss: 0.8213.  Mean training acc: 97.53%.
[ Wed Dec  3 13:16:13 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:16:13 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:16:13 2025 ] Training epoch: 429
[ Wed Dec  3 13:19:19 2025 ] 	Mean training loss: 0.8242.  Mean training acc: 97.43%.
[ Wed Dec  3 13:19:19 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:19:19 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:19:19 2025 ] Training epoch: 430
[ Wed Dec  3 13:22:21 2025 ] 	Mean training loss: 0.8200.  Mean training acc: 97.51%.
[ Wed Dec  3 13:22:21 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:22:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:22:21 2025 ] Training epoch: 431
[ Wed Dec  3 13:25:29 2025 ] 	Mean training loss: 0.8163.  Mean training acc: 97.86%.
[ Wed Dec  3 13:25:29 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:25:29 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:25:29 2025 ] Training epoch: 432
[ Wed Dec  3 13:28:31 2025 ] 	Mean training loss: 0.8096.  Mean training acc: 98.09%.
[ Wed Dec  3 13:28:31 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:28:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:28:31 2025 ] Training epoch: 433
[ Wed Dec  3 13:31:38 2025 ] 	Mean training loss: 0.8182.  Mean training acc: 97.73%.
[ Wed Dec  3 13:31:38 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:31:38 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:31:38 2025 ] Training epoch: 434
[ Wed Dec  3 13:34:40 2025 ] 	Mean training loss: 0.8140.  Mean training acc: 97.80%.
[ Wed Dec  3 13:34:40 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:34:40 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:34:40 2025 ] Training epoch: 435
[ Wed Dec  3 13:37:44 2025 ] 	Mean training loss: 0.8131.  Mean training acc: 97.90%.
[ Wed Dec  3 13:37:44 2025 ] 	Learning Rate: 0.0001
[ Wed Dec  3 13:37:44 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:37:44 2025 ] Training epoch: 436
[ Wed Dec  3 13:40:50 2025 ] 	Mean training loss: 0.8143.  Mean training acc: 97.88%.
[ Wed Dec  3 13:40:50 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:40:50 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:40:50 2025 ] Training epoch: 437
[ Wed Dec  3 13:43:51 2025 ] 	Mean training loss: 0.8099.  Mean training acc: 97.98%.
[ Wed Dec  3 13:43:51 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:43:51 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:43:51 2025 ] Training epoch: 438
[ Wed Dec  3 13:47:00 2025 ] 	Mean training loss: 0.8118.  Mean training acc: 97.88%.
[ Wed Dec  3 13:47:00 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:47:00 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:47:00 2025 ] Training epoch: 439
[ Wed Dec  3 13:50:01 2025 ] 	Mean training loss: 0.8204.  Mean training acc: 97.35%.
[ Wed Dec  3 13:50:01 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:50:01 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:50:01 2025 ] Training epoch: 440
[ Wed Dec  3 13:53:08 2025 ] 	Mean training loss: 0.8126.  Mean training acc: 97.57%.
[ Wed Dec  3 13:53:08 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:53:08 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:53:08 2025 ] Training epoch: 441
[ Wed Dec  3 13:56:11 2025 ] 	Mean training loss: 0.8120.  Mean training acc: 97.79%.
[ Wed Dec  3 13:56:11 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:56:11 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:56:11 2025 ] Training epoch: 442
[ Wed Dec  3 13:59:14 2025 ] 	Mean training loss: 0.8118.  Mean training acc: 98.01%.
[ Wed Dec  3 13:59:14 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 13:59:14 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 13:59:14 2025 ] Training epoch: 443
[ Wed Dec  3 14:02:21 2025 ] 	Mean training loss: 0.8162.  Mean training acc: 97.79%.
[ Wed Dec  3 14:02:21 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:02:21 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:02:21 2025 ] Training epoch: 444
[ Wed Dec  3 14:05:23 2025 ] 	Mean training loss: 0.8101.  Mean training acc: 97.86%.
[ Wed Dec  3 14:05:23 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:05:23 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:05:23 2025 ] Training epoch: 445
[ Wed Dec  3 14:08:31 2025 ] 	Mean training loss: 0.8170.  Mean training acc: 97.67%.
[ Wed Dec  3 14:08:31 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:08:31 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:08:31 2025 ] Training epoch: 446
[ Wed Dec  3 14:11:32 2025 ] 	Mean training loss: 0.8081.  Mean training acc: 98.04%.
[ Wed Dec  3 14:11:32 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:11:32 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:11:32 2025 ] Training epoch: 447
[ Wed Dec  3 14:14:33 2025 ] 	Mean training loss: 0.8026.  Mean training acc: 98.03%.
[ Wed Dec  3 14:14:33 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:14:33 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:14:33 2025 ] Training epoch: 448
[ Wed Dec  3 14:17:35 2025 ] 	Mean training loss: 0.8076.  Mean training acc: 97.96%.
[ Wed Dec  3 14:17:35 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:17:35 2025 ] 	Time consumption: [Data]09%, [Network]90%
[ Wed Dec  3 14:17:35 2025 ] Training epoch: 449
[ Wed Dec  3 14:20:04 2025 ] 	Mean training loss: 0.8102.  Mean training acc: 97.87%.
[ Wed Dec  3 14:20:04 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:20:04 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:20:04 2025 ] Training epoch: 450
[ Wed Dec  3 14:22:27 2025 ] 	Mean training loss: 0.8029.  Mean training acc: 98.11%.
[ Wed Dec  3 14:22:27 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:22:27 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:22:27 2025 ] Eval epoch: 450
[ Wed Dec  3 14:25:55 2025 ] 	Mean test loss of 1422 batches: 1.2659833763638293.
[ Wed Dec  3 14:25:56 2025 ] 	Top1: 83.69%
[ Wed Dec  3 14:25:56 2025 ] 	Top5: 95.91%
[ Wed Dec  3 14:25:56 2025 ] Training epoch: 451
[ Wed Dec  3 14:28:19 2025 ] 	Mean training loss: 0.8024.  Mean training acc: 98.10%.
[ Wed Dec  3 14:28:19 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:28:19 2025 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Dec  3 14:28:19 2025 ] Eval epoch: 451
[ Wed Dec  3 14:31:47 2025 ] 	Mean test loss of 1422 batches: 1.263190903660282.
[ Wed Dec  3 14:31:47 2025 ] 	Top1: 83.73%
[ Wed Dec  3 14:31:47 2025 ] 	Top5: 96.03%
[ Wed Dec  3 14:31:47 2025 ] Training epoch: 452
[ Wed Dec  3 14:34:11 2025 ] 	Mean training loss: 0.8024.  Mean training acc: 98.12%.
[ Wed Dec  3 14:34:11 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:34:11 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:34:11 2025 ] Eval epoch: 452
[ Wed Dec  3 14:37:39 2025 ] 	Mean test loss of 1422 batches: 1.2635733461329706.
[ Wed Dec  3 14:37:39 2025 ] 	Top1: 83.51%
[ Wed Dec  3 14:37:39 2025 ] 	Top5: 96.12%
[ Wed Dec  3 14:37:40 2025 ] Training epoch: 453
[ Wed Dec  3 14:40:03 2025 ] 	Mean training loss: 0.8008.  Mean training acc: 98.28%.
[ Wed Dec  3 14:40:03 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:40:03 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:40:03 2025 ] Eval epoch: 453
[ Wed Dec  3 14:43:31 2025 ] 	Mean test loss of 1422 batches: 1.2799947399714158.
[ Wed Dec  3 14:43:31 2025 ] 	Top1: 83.26%
[ Wed Dec  3 14:43:31 2025 ] 	Top5: 95.98%
[ Wed Dec  3 14:43:31 2025 ] Training epoch: 454
[ Wed Dec  3 14:45:55 2025 ] 	Mean training loss: 0.8031.  Mean training acc: 98.03%.
[ Wed Dec  3 14:45:55 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:45:55 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:45:55 2025 ] Eval epoch: 454
[ Wed Dec  3 14:49:23 2025 ] 	Mean test loss of 1422 batches: 1.248777034078134.
[ Wed Dec  3 14:49:23 2025 ] 	Top1: 83.89%
[ Wed Dec  3 14:49:23 2025 ] 	Top5: 96.18%
[ Wed Dec  3 14:49:23 2025 ] Training epoch: 455
[ Wed Dec  3 14:51:47 2025 ] 	Mean training loss: 0.8020.  Mean training acc: 97.99%.
[ Wed Dec  3 14:51:47 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:51:47 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:51:47 2025 ] Eval epoch: 455
[ Wed Dec  3 14:55:14 2025 ] 	Mean test loss of 1422 batches: 1.27105893423118.
[ Wed Dec  3 14:55:14 2025 ] 	Top1: 83.47%
[ Wed Dec  3 14:55:15 2025 ] 	Top5: 96.03%
[ Wed Dec  3 14:55:15 2025 ] Training epoch: 456
[ Wed Dec  3 14:57:38 2025 ] 	Mean training loss: 0.8031.  Mean training acc: 98.03%.
[ Wed Dec  3 14:57:38 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 14:57:38 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 14:57:38 2025 ] Eval epoch: 456
[ Wed Dec  3 15:01:06 2025 ] 	Mean test loss of 1422 batches: 1.2602238115211413.
[ Wed Dec  3 15:01:06 2025 ] 	Top1: 83.71%
[ Wed Dec  3 15:01:06 2025 ] 	Top5: 96.13%
[ Wed Dec  3 15:01:06 2025 ] Training epoch: 457
[ Wed Dec  3 15:03:30 2025 ] 	Mean training loss: 0.8019.  Mean training acc: 97.99%.
[ Wed Dec  3 15:03:30 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:03:30 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:03:30 2025 ] Eval epoch: 457
[ Wed Dec  3 15:06:57 2025 ] 	Mean test loss of 1422 batches: 1.2680744427333568.
[ Wed Dec  3 15:06:57 2025 ] 	Top1: 83.47%
[ Wed Dec  3 15:06:58 2025 ] 	Top5: 96.04%
[ Wed Dec  3 15:06:58 2025 ] Training epoch: 458
[ Wed Dec  3 15:09:21 2025 ] 	Mean training loss: 0.8003.  Mean training acc: 98.17%.
[ Wed Dec  3 15:09:21 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:09:21 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:09:21 2025 ] Eval epoch: 458
[ Wed Dec  3 15:12:50 2025 ] 	Mean test loss of 1422 batches: 1.2604946030929958.
[ Wed Dec  3 15:12:50 2025 ] 	Top1: 83.74%
[ Wed Dec  3 15:12:50 2025 ] 	Top5: 96.12%
[ Wed Dec  3 15:12:50 2025 ] Training epoch: 459
[ Wed Dec  3 15:15:13 2025 ] 	Mean training loss: 0.7996.  Mean training acc: 98.23%.
[ Wed Dec  3 15:15:13 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:15:13 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:15:13 2025 ] Eval epoch: 459
[ Wed Dec  3 15:18:42 2025 ] 	Mean test loss of 1422 batches: 1.25509790227383.
[ Wed Dec  3 15:18:42 2025 ] 	Top1: 83.89%
[ Wed Dec  3 15:18:42 2025 ] 	Top5: 96.23%
[ Wed Dec  3 15:18:42 2025 ] Training epoch: 460
[ Wed Dec  3 15:21:06 2025 ] 	Mean training loss: 0.7963.  Mean training acc: 98.17%.
[ Wed Dec  3 15:21:06 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:21:06 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:21:06 2025 ] Eval epoch: 460
[ Wed Dec  3 15:24:34 2025 ] 	Mean test loss of 1422 batches: 1.2613642372914005.
[ Wed Dec  3 15:24:35 2025 ] 	Top1: 83.67%
[ Wed Dec  3 15:24:35 2025 ] 	Top5: 96.12%
[ Wed Dec  3 15:24:35 2025 ] Training epoch: 461
[ Wed Dec  3 15:26:58 2025 ] 	Mean training loss: 0.8046.  Mean training acc: 97.91%.
[ Wed Dec  3 15:26:58 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:26:58 2025 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Dec  3 15:26:58 2025 ] Eval epoch: 461
[ Wed Dec  3 15:30:26 2025 ] 	Mean test loss of 1422 batches: 1.2592031681168767.
[ Wed Dec  3 15:30:26 2025 ] 	Top1: 83.66%
[ Wed Dec  3 15:30:27 2025 ] 	Top5: 96.22%
[ Wed Dec  3 15:30:27 2025 ] Training epoch: 462
[ Wed Dec  3 15:32:50 2025 ] 	Mean training loss: 0.8044.  Mean training acc: 98.09%.
[ Wed Dec  3 15:32:50 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:32:50 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:32:50 2025 ] Eval epoch: 462
[ Wed Dec  3 15:36:17 2025 ] 	Mean test loss of 1422 batches: 1.25533535732834.
[ Wed Dec  3 15:36:17 2025 ] 	Top1: 83.63%
[ Wed Dec  3 15:36:17 2025 ] 	Top5: 96.20%
[ Wed Dec  3 15:36:18 2025 ] Training epoch: 463
[ Wed Dec  3 15:38:41 2025 ] 	Mean training loss: 0.8011.  Mean training acc: 98.18%.
[ Wed Dec  3 15:38:41 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:38:41 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:38:41 2025 ] Eval epoch: 463
[ Wed Dec  3 15:42:09 2025 ] 	Mean test loss of 1422 batches: 1.247961714675155.
[ Wed Dec  3 15:42:09 2025 ] 	Top1: 84.10%
[ Wed Dec  3 15:42:09 2025 ] 	Top5: 96.18%
[ Wed Dec  3 15:42:10 2025 ] Training epoch: 464
[ Wed Dec  3 15:44:33 2025 ] 	Mean training loss: 0.7961.  Mean training acc: 98.20%.
[ Wed Dec  3 15:44:33 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:44:33 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:44:33 2025 ] Eval epoch: 464
[ Wed Dec  3 15:48:01 2025 ] 	Mean test loss of 1422 batches: 1.2491923570213774.
[ Wed Dec  3 15:48:01 2025 ] 	Top1: 84.15%
[ Wed Dec  3 15:48:01 2025 ] 	Top5: 96.18%
[ Wed Dec  3 15:48:01 2025 ] Training epoch: 465
[ Wed Dec  3 15:50:25 2025 ] 	Mean training loss: 0.7973.  Mean training acc: 98.37%.
[ Wed Dec  3 15:50:25 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:50:25 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:50:25 2025 ] Eval epoch: 465
[ Wed Dec  3 15:53:52 2025 ] 	Mean test loss of 1422 batches: 1.2500802831810738.
[ Wed Dec  3 15:53:52 2025 ] 	Top1: 84.06%
[ Wed Dec  3 15:53:52 2025 ] 	Top5: 96.14%
[ Wed Dec  3 15:53:53 2025 ] Training epoch: 466
[ Wed Dec  3 15:56:16 2025 ] 	Mean training loss: 0.8011.  Mean training acc: 98.20%.
[ Wed Dec  3 15:56:16 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 15:56:16 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 15:56:16 2025 ] Eval epoch: 466
[ Wed Dec  3 15:59:44 2025 ] 	Mean test loss of 1422 batches: 1.2558406436745124.
[ Wed Dec  3 15:59:44 2025 ] 	Top1: 83.93%
[ Wed Dec  3 15:59:44 2025 ] 	Top5: 96.15%
[ Wed Dec  3 15:59:45 2025 ] Training epoch: 467
[ Wed Dec  3 16:02:08 2025 ] 	Mean training loss: 0.7970.  Mean training acc: 98.34%.
[ Wed Dec  3 16:02:08 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:02:08 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:02:08 2025 ] Eval epoch: 467
[ Wed Dec  3 16:05:37 2025 ] 	Mean test loss of 1422 batches: 1.270984272497448.
[ Wed Dec  3 16:05:37 2025 ] 	Top1: 83.42%
[ Wed Dec  3 16:05:37 2025 ] 	Top5: 96.07%
[ Wed Dec  3 16:05:37 2025 ] Training epoch: 468
[ Wed Dec  3 16:08:01 2025 ] 	Mean training loss: 0.7959.  Mean training acc: 98.25%.
[ Wed Dec  3 16:08:01 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:08:01 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:08:01 2025 ] Eval epoch: 468
[ Wed Dec  3 16:11:29 2025 ] 	Mean test loss of 1422 batches: 1.2600806475775486.
[ Wed Dec  3 16:11:29 2025 ] 	Top1: 83.83%
[ Wed Dec  3 16:11:29 2025 ] 	Top5: 96.11%
[ Wed Dec  3 16:11:29 2025 ] Training epoch: 469
[ Wed Dec  3 16:13:53 2025 ] 	Mean training loss: 0.7991.  Mean training acc: 98.13%.
[ Wed Dec  3 16:13:53 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:13:53 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:13:53 2025 ] Eval epoch: 469
[ Wed Dec  3 16:17:21 2025 ] 	Mean test loss of 1422 batches: 1.261120934820041.
[ Wed Dec  3 16:17:21 2025 ] 	Top1: 83.61%
[ Wed Dec  3 16:17:21 2025 ] 	Top5: 96.09%
[ Wed Dec  3 16:17:22 2025 ] Training epoch: 470
[ Wed Dec  3 16:19:45 2025 ] 	Mean training loss: 0.7947.  Mean training acc: 98.41%.
[ Wed Dec  3 16:19:45 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:19:45 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:19:45 2025 ] Eval epoch: 470
[ Wed Dec  3 16:23:13 2025 ] 	Mean test loss of 1422 batches: 1.2556068698146003.
[ Wed Dec  3 16:23:14 2025 ] 	Top1: 83.92%
[ Wed Dec  3 16:23:14 2025 ] 	Top5: 96.17%
[ Wed Dec  3 16:23:14 2025 ] Training epoch: 471
[ Wed Dec  3 16:25:38 2025 ] 	Mean training loss: 0.7926.  Mean training acc: 98.34%.
[ Wed Dec  3 16:25:38 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:25:38 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:25:38 2025 ] Eval epoch: 471
[ Wed Dec  3 16:29:05 2025 ] 	Mean test loss of 1422 batches: 1.266906731951924.
[ Wed Dec  3 16:29:06 2025 ] 	Top1: 83.62%
[ Wed Dec  3 16:29:06 2025 ] 	Top5: 96.00%
[ Wed Dec  3 16:29:06 2025 ] Training epoch: 472
[ Wed Dec  3 16:31:29 2025 ] 	Mean training loss: 0.7978.  Mean training acc: 98.22%.
[ Wed Dec  3 16:31:29 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:31:29 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:31:29 2025 ] Eval epoch: 472
[ Wed Dec  3 16:34:58 2025 ] 	Mean test loss of 1422 batches: 1.2677947370395715.
[ Wed Dec  3 16:34:58 2025 ] 	Top1: 83.61%
[ Wed Dec  3 16:34:58 2025 ] 	Top5: 95.98%
[ Wed Dec  3 16:34:58 2025 ] Training epoch: 473
[ Wed Dec  3 16:37:22 2025 ] 	Mean training loss: 0.7981.  Mean training acc: 98.39%.
[ Wed Dec  3 16:37:22 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:37:22 2025 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Dec  3 16:37:22 2025 ] Eval epoch: 473
[ Wed Dec  3 16:40:50 2025 ] 	Mean test loss of 1422 batches: 1.2563602989316824.
[ Wed Dec  3 16:40:50 2025 ] 	Top1: 83.96%
[ Wed Dec  3 16:40:51 2025 ] 	Top5: 96.17%
[ Wed Dec  3 16:40:51 2025 ] Training epoch: 474
[ Wed Dec  3 16:43:14 2025 ] 	Mean training loss: 0.7923.  Mean training acc: 98.47%.
[ Wed Dec  3 16:43:14 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:43:14 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:43:14 2025 ] Eval epoch: 474
[ Wed Dec  3 16:46:42 2025 ] 	Mean test loss of 1422 batches: 1.266334278464485.
[ Wed Dec  3 16:46:42 2025 ] 	Top1: 83.72%
[ Wed Dec  3 16:46:42 2025 ] 	Top5: 95.95%
[ Wed Dec  3 16:46:42 2025 ] Training epoch: 475
[ Wed Dec  3 16:49:06 2025 ] 	Mean training loss: 0.7946.  Mean training acc: 98.32%.
[ Wed Dec  3 16:49:06 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:49:06 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 16:49:06 2025 ] Eval epoch: 475
[ Wed Dec  3 16:52:34 2025 ] 	Mean test loss of 1422 batches: 1.2767778172690825.
[ Wed Dec  3 16:52:34 2025 ] 	Top1: 83.43%
[ Wed Dec  3 16:52:35 2025 ] 	Top5: 95.94%
[ Wed Dec  3 16:52:35 2025 ] Training epoch: 476
[ Wed Dec  3 16:54:49 2025 ] 	Mean training loss: 0.7936.  Mean training acc: 98.33%.
[ Wed Dec  3 16:54:49 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 16:54:49 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 16:54:50 2025 ] Eval epoch: 476
[ Wed Dec  3 16:58:07 2025 ] 	Mean test loss of 1422 batches: 1.2632157358690657.
[ Wed Dec  3 16:58:07 2025 ] 	Top1: 83.92%
[ Wed Dec  3 16:58:07 2025 ] 	Top5: 96.06%
[ Wed Dec  3 16:58:07 2025 ] Training epoch: 477
[ Wed Dec  3 17:00:23 2025 ] 	Mean training loss: 0.7930.  Mean training acc: 98.38%.
[ Wed Dec  3 17:00:23 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:00:23 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:00:23 2025 ] Eval epoch: 477
[ Wed Dec  3 17:03:39 2025 ] 	Mean test loss of 1422 batches: 1.2605803958893493.
[ Wed Dec  3 17:03:40 2025 ] 	Top1: 83.80%
[ Wed Dec  3 17:03:40 2025 ] 	Top5: 96.14%
[ Wed Dec  3 17:03:40 2025 ] Training epoch: 478
[ Wed Dec  3 17:05:57 2025 ] 	Mean training loss: 0.7953.  Mean training acc: 98.21%.
[ Wed Dec  3 17:05:57 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:05:57 2025 ] 	Time consumption: [Data]10%, [Network]88%
[ Wed Dec  3 17:05:57 2025 ] Eval epoch: 478
[ Wed Dec  3 17:09:11 2025 ] 	Mean test loss of 1422 batches: 1.2691657589290044.
[ Wed Dec  3 17:09:11 2025 ] 	Top1: 83.56%
[ Wed Dec  3 17:09:11 2025 ] 	Top5: 96.03%
[ Wed Dec  3 17:09:11 2025 ] Training epoch: 479
[ Wed Dec  3 17:11:30 2025 ] 	Mean training loss: 0.7908.  Mean training acc: 98.46%.
[ Wed Dec  3 17:11:30 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:11:30 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:11:31 2025 ] Eval epoch: 479
[ Wed Dec  3 17:14:42 2025 ] 	Mean test loss of 1422 batches: 1.251921017294024.
[ Wed Dec  3 17:14:43 2025 ] 	Top1: 84.00%
[ Wed Dec  3 17:14:43 2025 ] 	Top5: 96.17%
[ Wed Dec  3 17:14:43 2025 ] Training epoch: 480
[ Wed Dec  3 17:17:03 2025 ] 	Mean training loss: 0.7964.  Mean training acc: 98.31%.
[ Wed Dec  3 17:17:03 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:17:03 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:17:04 2025 ] Eval epoch: 480
[ Wed Dec  3 17:20:14 2025 ] 	Mean test loss of 1422 batches: 1.2541916707816172.
[ Wed Dec  3 17:20:14 2025 ] 	Top1: 83.90%
[ Wed Dec  3 17:20:14 2025 ] 	Top5: 96.20%
[ Wed Dec  3 17:20:14 2025 ] Training epoch: 481
[ Wed Dec  3 17:22:37 2025 ] 	Mean training loss: 0.7900.  Mean training acc: 98.50%.
[ Wed Dec  3 17:22:37 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:22:37 2025 ] 	Time consumption: [Data]11%, [Network]89%
[ Wed Dec  3 17:22:37 2025 ] Eval epoch: 481
[ Wed Dec  3 17:25:45 2025 ] 	Mean test loss of 1422 batches: 1.2648740601942006.
[ Wed Dec  3 17:25:45 2025 ] 	Top1: 83.60%
[ Wed Dec  3 17:25:45 2025 ] 	Top5: 96.09%
[ Wed Dec  3 17:25:45 2025 ] Training epoch: 482
[ Wed Dec  3 17:28:09 2025 ] 	Mean training loss: 0.7916.  Mean training acc: 98.46%.
[ Wed Dec  3 17:28:09 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:28:09 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 17:28:09 2025 ] Eval epoch: 482
[ Wed Dec  3 17:31:16 2025 ] 	Mean test loss of 1422 batches: 1.2633294795971213.
[ Wed Dec  3 17:31:16 2025 ] 	Top1: 83.73%
[ Wed Dec  3 17:31:17 2025 ] 	Top5: 96.05%
[ Wed Dec  3 17:31:17 2025 ] Training epoch: 483
[ Wed Dec  3 17:33:40 2025 ] 	Mean training loss: 0.7897.  Mean training acc: 98.52%.
[ Wed Dec  3 17:33:40 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:33:40 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 17:33:40 2025 ] Eval epoch: 483
[ Wed Dec  3 17:36:49 2025 ] 	Mean test loss of 1422 batches: 1.2598598491290451.
[ Wed Dec  3 17:36:49 2025 ] 	Top1: 83.89%
[ Wed Dec  3 17:36:49 2025 ] 	Top5: 96.06%
[ Wed Dec  3 17:36:49 2025 ] Training epoch: 484
[ Wed Dec  3 17:39:12 2025 ] 	Mean training loss: 0.7937.  Mean training acc: 98.18%.
[ Wed Dec  3 17:39:12 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:39:12 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 17:39:12 2025 ] Eval epoch: 484
[ Wed Dec  3 17:42:22 2025 ] 	Mean test loss of 1422 batches: 1.2587396844529903.
[ Wed Dec  3 17:42:22 2025 ] 	Top1: 83.87%
[ Wed Dec  3 17:42:22 2025 ] 	Top5: 96.09%
[ Wed Dec  3 17:42:22 2025 ] Training epoch: 485
[ Wed Dec  3 17:44:44 2025 ] 	Mean training loss: 0.7897.  Mean training acc: 98.51%.
[ Wed Dec  3 17:44:44 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:44:44 2025 ] 	Time consumption: [Data]10%, [Network]89%
[ Wed Dec  3 17:44:44 2025 ] Eval epoch: 485
[ Wed Dec  3 17:47:56 2025 ] 	Mean test loss of 1422 batches: 1.2600910867735975.
[ Wed Dec  3 17:47:56 2025 ] 	Top1: 83.81%
[ Wed Dec  3 17:47:56 2025 ] 	Top5: 96.04%
[ Wed Dec  3 17:47:56 2025 ] Training epoch: 486
[ Wed Dec  3 17:50:15 2025 ] 	Mean training loss: 0.7848.  Mean training acc: 98.65%.
[ Wed Dec  3 17:50:15 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:50:15 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:50:15 2025 ] Eval epoch: 486
[ Wed Dec  3 17:53:29 2025 ] 	Mean test loss of 1422 batches: 1.259056370972581.
[ Wed Dec  3 17:53:29 2025 ] 	Top1: 83.85%
[ Wed Dec  3 17:53:29 2025 ] 	Top5: 96.11%
[ Wed Dec  3 17:53:30 2025 ] Training epoch: 487
[ Wed Dec  3 17:55:48 2025 ] 	Mean training loss: 0.7928.  Mean training acc: 98.27%.
[ Wed Dec  3 17:55:48 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 17:55:48 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 17:55:48 2025 ] Eval epoch: 487
[ Wed Dec  3 17:59:02 2025 ] 	Mean test loss of 1422 batches: 1.2578684524560948.
[ Wed Dec  3 17:59:02 2025 ] 	Top1: 83.89%
[ Wed Dec  3 17:59:02 2025 ] 	Top5: 96.04%
[ Wed Dec  3 17:59:02 2025 ] Training epoch: 488
[ Wed Dec  3 18:01:11 2025 ] 	Mean training loss: 0.7881.  Mean training acc: 98.63%.
[ Wed Dec  3 18:01:11 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:01:11 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:01:12 2025 ] Eval epoch: 488
[ Wed Dec  3 18:04:23 2025 ] 	Mean test loss of 1422 batches: 1.2617938920918397.
[ Wed Dec  3 18:04:23 2025 ] 	Top1: 83.74%
[ Wed Dec  3 18:04:23 2025 ] 	Top5: 96.03%
[ Wed Dec  3 18:04:24 2025 ] Training epoch: 489
[ Wed Dec  3 18:06:32 2025 ] 	Mean training loss: 0.7895.  Mean training acc: 98.52%.
[ Wed Dec  3 18:06:32 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:06:32 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:06:32 2025 ] Eval epoch: 489
[ Wed Dec  3 18:09:44 2025 ] 	Mean test loss of 1422 batches: 1.2606692068519807.
[ Wed Dec  3 18:09:44 2025 ] 	Top1: 83.87%
[ Wed Dec  3 18:09:44 2025 ] 	Top5: 96.04%
[ Wed Dec  3 18:09:44 2025 ] Training epoch: 490
[ Wed Dec  3 18:11:54 2025 ] 	Mean training loss: 0.7937.  Mean training acc: 98.34%.
[ Wed Dec  3 18:11:54 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:11:54 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:11:54 2025 ] Eval epoch: 490
[ Wed Dec  3 18:15:05 2025 ] 	Mean test loss of 1422 batches: 1.2662997591176952.
[ Wed Dec  3 18:15:06 2025 ] 	Top1: 83.56%
[ Wed Dec  3 18:15:06 2025 ] 	Top5: 96.05%
[ Wed Dec  3 18:15:06 2025 ] Training epoch: 491
[ Wed Dec  3 18:17:14 2025 ] 	Mean training loss: 0.7905.  Mean training acc: 98.53%.
[ Wed Dec  3 18:17:14 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:17:14 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:17:14 2025 ] Eval epoch: 491
[ Wed Dec  3 18:20:26 2025 ] 	Mean test loss of 1422 batches: 1.2593690010230416.
[ Wed Dec  3 18:20:26 2025 ] 	Top1: 83.73%
[ Wed Dec  3 18:20:26 2025 ] 	Top5: 96.13%
[ Wed Dec  3 18:20:26 2025 ] Training epoch: 492
[ Wed Dec  3 18:22:35 2025 ] 	Mean training loss: 0.7872.  Mean training acc: 98.57%.
[ Wed Dec  3 18:22:35 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:22:35 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:22:35 2025 ] Eval epoch: 492
[ Wed Dec  3 18:25:47 2025 ] 	Mean test loss of 1422 batches: 1.262556054337283.
[ Wed Dec  3 18:25:47 2025 ] 	Top1: 83.79%
[ Wed Dec  3 18:25:47 2025 ] 	Top5: 96.04%
[ Wed Dec  3 18:25:48 2025 ] Training epoch: 493
[ Wed Dec  3 18:27:57 2025 ] 	Mean training loss: 0.7924.  Mean training acc: 98.38%.
[ Wed Dec  3 18:27:57 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:27:57 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:27:57 2025 ] Eval epoch: 493
[ Wed Dec  3 18:31:08 2025 ] 	Mean test loss of 1422 batches: 1.2556780763651583.
[ Wed Dec  3 18:31:09 2025 ] 	Top1: 84.00%
[ Wed Dec  3 18:31:09 2025 ] 	Top5: 96.14%
[ Wed Dec  3 18:31:09 2025 ] Training epoch: 494
[ Wed Dec  3 18:33:18 2025 ] 	Mean training loss: 0.7915.  Mean training acc: 98.50%.
[ Wed Dec  3 18:33:18 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:33:18 2025 ] 	Time consumption: [Data]11%, [Network]87%
[ Wed Dec  3 18:33:18 2025 ] Eval epoch: 494
[ Wed Dec  3 18:36:29 2025 ] 	Mean test loss of 1422 batches: 1.2554365668954057.
[ Wed Dec  3 18:36:29 2025 ] 	Top1: 83.92%
[ Wed Dec  3 18:36:29 2025 ] 	Top5: 96.14%
[ Wed Dec  3 18:36:29 2025 ] Training epoch: 495
[ Wed Dec  3 18:38:39 2025 ] 	Mean training loss: 0.7847.  Mean training acc: 98.58%.
[ Wed Dec  3 18:38:39 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:38:39 2025 ] 	Time consumption: [Data]12%, [Network]87%
[ Wed Dec  3 18:38:39 2025 ] Eval epoch: 495
[ Wed Dec  3 18:41:49 2025 ] 	Mean test loss of 1422 batches: 1.2489407845941778.
[ Wed Dec  3 18:41:49 2025 ] 	Top1: 84.10%
[ Wed Dec  3 18:41:49 2025 ] 	Top5: 96.18%
[ Wed Dec  3 18:41:49 2025 ] Training epoch: 496
[ Wed Dec  3 18:44:00 2025 ] 	Mean training loss: 0.7906.  Mean training acc: 98.50%.
[ Wed Dec  3 18:44:00 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:44:00 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:44:00 2025 ] Eval epoch: 496
[ Wed Dec  3 18:47:07 2025 ] 	Mean test loss of 1422 batches: 1.254859207803187.
[ Wed Dec  3 18:47:07 2025 ] 	Top1: 84.08%
[ Wed Dec  3 18:47:08 2025 ] 	Top5: 96.08%
[ Wed Dec  3 18:47:08 2025 ] Training epoch: 497
[ Wed Dec  3 18:49:21 2025 ] 	Mean training loss: 0.7853.  Mean training acc: 98.65%.
[ Wed Dec  3 18:49:21 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:49:21 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:49:21 2025 ] Eval epoch: 497
[ Wed Dec  3 18:52:26 2025 ] 	Mean test loss of 1422 batches: 1.2592177505902264.
[ Wed Dec  3 18:52:26 2025 ] 	Top1: 83.85%
[ Wed Dec  3 18:52:26 2025 ] 	Top5: 96.12%
[ Wed Dec  3 18:52:26 2025 ] Training epoch: 498
[ Wed Dec  3 18:54:41 2025 ] 	Mean training loss: 0.7895.  Mean training acc: 98.47%.
[ Wed Dec  3 18:54:41 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 18:54:41 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 18:54:41 2025 ] Eval epoch: 498
[ Wed Dec  3 18:57:43 2025 ] 	Mean test loss of 1422 batches: 1.2614661435453869.
[ Wed Dec  3 18:57:43 2025 ] 	Top1: 83.87%
[ Wed Dec  3 18:57:43 2025 ] 	Top5: 96.08%
[ Wed Dec  3 18:57:44 2025 ] Training epoch: 499
[ Wed Dec  3 19:00:01 2025 ] 	Mean training loss: 0.7888.  Mean training acc: 98.49%.
[ Wed Dec  3 19:00:01 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:00:01 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 19:00:01 2025 ] Eval epoch: 499
[ Wed Dec  3 19:03:00 2025 ] 	Mean test loss of 1422 batches: 1.2617772433241377.
[ Wed Dec  3 19:03:00 2025 ] 	Top1: 83.91%
[ Wed Dec  3 19:03:00 2025 ] 	Top5: 96.00%
[ Wed Dec  3 19:03:00 2025 ] Training epoch: 500
[ Wed Dec  3 19:05:20 2025 ] 	Mean training loss: 0.7868.  Mean training acc: 98.61%.
[ Wed Dec  3 19:05:20 2025 ] 	Learning Rate: 0.0000
[ Wed Dec  3 19:05:20 2025 ] 	Time consumption: [Data]11%, [Network]88%
[ Wed Dec  3 19:05:20 2025 ] Eval epoch: 500
[ Wed Dec  3 19:08:17 2025 ] 	Mean test loss of 1422 batches: 1.2504125534649808.
[ Wed Dec  3 19:08:17 2025 ] 	Top1: 84.10%
[ Wed Dec  3 19:08:17 2025 ] 	Top5: 96.15%
[ Wed Dec  3 19:11:33 2025 ] Best accuracy: 0.8415105952694979
[ Wed Dec  3 19:11:33 2025 ] Epoch number: 464
[ Wed Dec  3 19:11:33 2025 ] Model name: ./work_dir6/ntu/cs/SkateFormer_j/
[ Wed Dec  3 19:11:33 2025 ] Model total number of params: 3616083
[ Wed Dec  3 19:11:33 2025 ] Weight decay: 0.1
[ Wed Dec  3 19:11:33 2025 ] Base LR: 0.001
[ Wed Dec  3 19:11:33 2025 ] Batch Size: 32
[ Wed Dec  3 19:11:33 2025 ] Test Batch Size: 32
[ Wed Dec  3 19:11:33 2025 ] seed: 1
